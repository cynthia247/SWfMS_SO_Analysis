{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a3956d",
   "metadata": {},
   "source": [
    "# Necessary Tools and Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57e1172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas\n",
    "# ! pip install matplotlib\n",
    "# ! pip install numpy\n",
    "# ! pip install seaborn\n",
    "# ! pip install unzip\n",
    "# ! pip install gensim\n",
    "# ! pip install nltk\n",
    "# ! pip install wordcloud\n",
    "# ! pip install spacy\n",
    "# ! pip install spacy_download\n",
    "# ! pip install pyLDAvis\n",
    "# ! pip install PyStemmer\n",
    "\n",
    "# ! python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893b4ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/uji657/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/uji657/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/uji657/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 87.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: setuptools in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (59.6.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: jinja2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.8.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "## Importing PD and Others\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "## Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "## NLTK\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import nltk.stem\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['#', '`', '\"', '@'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import spacy\n",
    "spacy.cli.download('en_core_web_sm')\n",
    "\n",
    "\n",
    "\n",
    "## Visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c80025",
   "metadata": {},
   "source": [
    "# Import data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093e46bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/snakemake_posts.csv')\n",
    "# my_value = -1\n",
    "# new_df = df.loc[df[\"RatingsGPTFineTuned\"] == my_value]\n",
    "df[\"merged\"] = df[[\"Body\"]]\n",
    "#new_df.head()\n",
    "# new_df.to_csv('Dataset/ConcatenatedDatasetSO.csv')\n",
    "\n",
    "data = df.merged.values.tolist()\n",
    "print(len(df))\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed84875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Initial workflow I have a snakefile that can generate some output from '\n",
      " 'paired-end data. In this snakefile, I have a rule that \"installs\" the data '\n",
      " 'given information stored in the config file (get_raw_data). Then I have a '\n",
      " 'rule that uses that data to generate intermediate files on which the rest of '\n",
      " 'the workflow depends (run_tophat). Here are the input and output of these '\n",
      " 'rules (OPJ stands for os.path.join): rule get_raw_data: output: '\n",
      " 'OPJ(raw_data_dir, \"{lib}_1.fastq.gz\"), OPJ(raw_data_dir, '\n",
      " '\"{lib}_2.fastq.gz\"), (More details on the implementation of this rule later) '\n",
      " 'rule run_tophat: input: transcriptome = OPJ(annot_dir, \"dmel-all-r5.9.gff\"), '\n",
      " 'fq1 = OPJ(raw_data_dir, \"{lib}_1.fastq.gz\"), fq2 = OPJ(raw_data_dir, '\n",
      " '\"{lib}_2.fastq.gz\"), output: junctions = OPJ(output_dir, \"{lib}\", '\n",
      " '\"junctions.bed\"), bam = OPJ(output_dir, \"{lib}\", \"accepted_hits.bam\"), And '\n",
      " '(simplifying) my main rule would be something like that: rule all: input: '\n",
      " 'expand(OPJ(output_dir, \"{lib}\", \"junctions.bed\"), lib=LIBS), Extending the '\n",
      " 'workflow to single-end data I now have to run my workflow on data that is '\n",
      " 'single-end. I would like to avoid the final output having different name '\n",
      " 'patterns depending on whether the data is single or paired end. I can easily '\n",
      " 'make variants of the above-mentioned two rules that should work with '\n",
      " 'single-end data (get_raw_data_single_end and run_tophat_single_end), whose '\n",
      " 'input and output are as follows: rule get_raw_data_single_end: output: '\n",
      " 'OPJ(raw_data_dir, \"{lib}.fastq.gz\") rule run_tophat_single_end: input: '\n",
      " 'transcriptome = OPJ(annot_dir, \"dmel-all-r5.9.gff\"), fq = OPJ(raw_data_dir, '\n",
      " '\"{lib}.fastq.gz\"), output: junctions = OPJ(output_dir, \"{lib}\", '\n",
      " '\"junctions.bed\"), bam = OPJ(output_dir, \"{lib}\", \"accepted_hits.bam\"), How '\n",
      " 'to provide snakemake with enough information to chose the correct rule path? '\n",
      " 'The config file contains the information about whether the lib wildcard is '\n",
      " 'associated with single-end or paired-end data in the following manner: The '\n",
      " 'library names are keys in either a lib2raw or a lib2raw_single_end '\n",
      " 'dictionary (both dictionaries are read from the config file). Im not '\n",
      " 'expecting the same library name to be a key in both dictionaries. Therefore, '\n",
      " 'in a sense, it is not ambiguous whether I want the single-end or paired-end '\n",
      " 'branch of the workflow to be executed. A function lib2data (that uses these '\n",
      " 'dictionaries) is used by both get_raw_data and get_raw_data_single_end to '\n",
      " 'determine what shell command to run to \"install\" the data. Here is a '\n",
      " 'simplified version of this function (the actual one contains an extra branch '\n",
      " 'to generate a command for data from a SRR identifier): def '\n",
      " 'lib2data(wildcards): lib = wildcards.lib if lib in lib2raw: raw = '\n",
      " 'lib2raw[lib] link_1 = \"ln -s %s %s_1.fastq.gz\" % (raw.format(mate=\"1\"), lib) '\n",
      " 'link_2 = \"ln -s %s %s_2.fastq.gz\" % (raw.format(mate=\"2\"), lib) return '\n",
      " '\"%s\\\\n%s\\\\n\" % (link_1, link_2) elif lib in lib2raw_single_end: raw = '\n",
      " 'lib2raw_single_end[lib] return \"ln -s %s %s.fastq.gz\\\\n\" % (raw, lib) else: '\n",
      " 'raise ValueError(\"Procedure to get raw data for %s unknown.\" % lib) Apart '\n",
      " 'from their output, the two get_raw_data* rules are the same and work the '\n",
      " 'following way: params: shell_command = lib2data, shell: \"\"\" ( cd '\n",
      " '{raw_data_dir} {params.shell_command} ) \"\"\" Is snakemake able to determine '\n",
      " 'the correct rule path given information that is not coded in rules input and '\n",
      " 'output, but only in config files and functions? It seems that it is not the '\n",
      " 'case. Indeed, Im trying to test my new snakefile (with the added '\n",
      " '*_single_end rules), but a KeyError occurs during the execution of the '\n",
      " 'get_raw_data rule, whereas the library for which the rule is being executed '\n",
      " 'is associated with single-end data. How to achieve the desired behaviour (a '\n",
      " 'two-branch workflow able to use the information in the configuration to '\n",
      " 'chose the correct branch)? Edit: The KeyError was due to an error in '\n",
      " 'lib2data After using the correct dictionary to get the data associated with '\n",
      " 'the library name, I end up having the following error: '\n",
      " 'AmbiguousRuleException: Rules run_tophat and run_tophat_single_end are '\n",
      " 'ambiguous for the file '\n",
      " 'tophat_junction_discovery_revision_supplement/HWT3/junctions.bed. Expected '\n",
      " 'input files: run_tophat: ./HWT3_1.fastq.gz ./HWT3_2.fastq.gz '\n",
      " 'Annotations/dmel-all-r5.9.gff run_tophat_single_end: ./HWT3.fastq.gz '\n",
      " 'Annotations/dmel-all-r5.9.gff Edit 2: Adding input to the get_raw_data* '\n",
      " 'rules After reading this post on the snakemake mailing list, I tried to add '\n",
      " 'some input to my rules to avoid ambiguity. def lib2data_input(wildcards): '\n",
      " 'lib = wildcards.lib if lib in lib2raw: raw = lib2raw[lib] return '\n",
      " '[raw.format(mate=\"1\"), raw.format(mate=\"2\")] elif lib in lib2raw_single_end: '\n",
      " 'raw = lib2raw_single_end[lib] return [raw] else: raise ValueError(\"Procedure '\n",
      " 'to get raw data for %s unknown.\" % lib) rule get_raw_data: input: '\n",
      " 'lib2data_input # [same output, params and shell as before] # [same '\n",
      " 'modification for the single-end case] This results in a '\n",
      " 'MissingInputException. Strangely, the reportedly missing file does exist. Is '\n",
      " 'the trick supposed to work? (Cant reproduce this, now this results in:) '\n",
      " 'AmbiguousRuleException: Rules run_tophat_single_end and run_tophat are '\n",
      " 'ambiguous for the file '\n",
      " 'tophat_junction_discovery_revision_supplement/HTW2/junctions.bed. Expected '\n",
      " 'input files: run_tophat_single_end: ./HTW2.fastq.gz '\n",
      " 'Annotations/dmel-all-r5.9.gff run_tophat: ./HTW2_1.fastq.gz '\n",
      " './HTW2_2.fastq.gz Annotations/dmel-all-r5.9.gff My way of specifying an '\n",
      " 'input to the \"data installation\" rules is apparently not enough to guide '\n",
      " 'snakemake to the correct rule. ',\n",
      " 'Consider the following simple snakefile, which is an attempt to write a file '\n",
      " 'in a run instruction: rule all: input: \"test.txt\" rule make_test: output: '\n",
      " 'filename = \"test.txt\" run: with open(output.filename) as f: f.write(\"test\") '\n",
      " 'Running it results in the following: Provided cores: 1 Rules claiming more '\n",
      " 'threads will be scaled down. Job counts: count jobs 1 all 1 make_test 2 rule '\n",
      " 'make_test: output: test.txt Error in job make_test while creating output '\n",
      " 'file test.txt. RuleException: FileNotFoundError in line 10 of '\n",
      " '/tmp/Snakefile: [Errno 2] No such file or directory: test.txt File '\n",
      " '\"/tmp/Snakefile\", line 10, in __rule_make_test Will exit after finishing '\n",
      " 'currently running jobs. Exiting because a job execution failed. Look above '\n",
      " 'for error message Im surprised of this FileNotFoundError. Obviously, I didnt '\n",
      " 'find the correct way to tell snakemake that this is the file I want the rule '\n",
      " 'make_test to create. I also tried the following modification of the output '\n",
      " 'syntax: rule all: input: \"test.txt\" rule make_test: output: \"test.txt\" run: '\n",
      " 'with open(output[0]) as f: f.write(\"test\") The error is the same. Whats '\n",
      " 'happening? ']\n"
     ]
    }
   ],
   "source": [
    "# Remove Emails\n",
    "data = [re.sub('<[^<>]*>', '', sent) for sent in data]\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98f4b6",
   "metadata": {},
   "source": [
    "# Tokenize words and Clean-up text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b3a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['initial', 'workflow', 'have', 'snakefile', 'that', 'can', 'generate', 'some', 'output', 'from', 'paired', 'end', 'data', 'in', 'this', 'snakefile', 'have', 'rule', 'that', 'installs', 'the', 'data', 'given', 'information', 'stored', 'in', 'the', 'config', 'file', 'get_raw_data', 'then', 'have', 'rule', 'that', 'uses', 'that', 'data', 'to', 'generate', 'intermediate', 'files', 'on', 'which', 'the', 'rest', 'of', 'the', 'workflow', 'depends', 'run_tophat', 'here', 'are', 'the', 'input', 'and', 'output', 'of', 'these', 'rules', 'opj', 'stands', 'for', 'os', 'path', 'join', 'rule', 'get_raw_data', 'output', 'opj', 'raw_data_dir', 'lib', 'fastq', 'gz', 'opj', 'raw_data_dir', 'lib', 'fastq', 'gz', 'more', 'details', 'on', 'the', 'implementation', 'of', 'this', 'rule', 'later', 'rule', 'run_tophat', 'input', 'transcriptome', 'opj', 'annot_dir', 'dmel', 'all', 'gff', 'fq', 'opj', 'raw_data_dir', 'lib', 'fastq', 'gz', 'fq', 'opj', 'raw_data_dir', 'lib', 'fastq', 'gz', 'output', 'junctions', 'opj', 'output_dir', 'lib', 'junctions', 'bed', 'bam', 'opj', 'output_dir', 'lib', 'accepted_hits', 'bam', 'and', 'simplifying', 'my', 'main', 'rule', 'would', 'be', 'something', 'like', 'that', 'rule', 'all', 'input', 'expand', 'opj', 'output_dir', 'lib', 'junctions', 'bed', 'lib', 'libs', 'extending', 'the', 'workflow', 'to', 'single', 'end', 'data', 'now', 'have', 'to', 'run', 'my', 'workflow', 'on', 'data', 'that', 'is', 'single', 'end', 'would', 'like', 'to', 'avoid', 'the', 'final', 'output', 'having', 'different', 'name', 'patterns', 'depending', 'on', 'whether', 'the', 'data', 'is', 'single', 'or', 'paired', 'end', 'can', 'easily', 'make', 'variants', 'of', 'the', 'above', 'mentioned', 'two', 'rules', 'that', 'should', 'work', 'with', 'single', 'end', 'data', 'and', 'whose', 'input', 'and', 'output', 'are', 'as', 'follows', 'rule', 'output', 'opj', 'raw_data_dir', 'lib', 'fastq', 'gz', 'rule', 'input', 'transcriptome', 'opj', 'annot_dir', 'dmel', 'all', 'gff', 'fq', 'opj', 'raw_data_dir', 'lib', 'fastq', 'gz', 'output', 'junctions', 'opj', 'output_dir', 'lib', 'junctions', 'bed', 'bam', 'opj', 'output_dir', 'lib', 'accepted_hits', 'bam', 'how', 'to', 'provide', 'snakemake', 'with', 'enough', 'information', 'to', 'chose', 'the', 'correct', 'rule', 'path', 'the', 'config', 'file', 'contains', 'the', 'information', 'about', 'whether', 'the', 'lib', 'wildcard', 'is', 'associated', 'with', 'single', 'end', 'or', 'paired', 'end', 'data', 'in', 'the', 'following', 'manner', 'the', 'library', 'names', 'are', 'keys', 'in', 'either', 'lib', 'raw', 'or', 'lib', 'raw_single_end', 'dictionary', 'both', 'dictionaries', 'are', 'read', 'from', 'the', 'config', 'file', 'im', 'not', 'expecting', 'the', 'same', 'library', 'name', 'to', 'be', 'key', 'in', 'both', 'dictionaries', 'therefore', 'in', 'sense', 'it', 'is', 'not', 'ambiguous', 'whether', 'want', 'the', 'single', 'end', 'or', 'paired', 'end', 'branch', 'of', 'the', 'workflow', 'to', 'be', 'executed', 'function', 'lib', 'data', 'that', 'uses', 'these', 'dictionaries', 'is', 'used', 'by', 'both', 'get_raw_data', 'and', 'to', 'determine', 'what', 'shell', 'command', 'to', 'run', 'to', 'install', 'the', 'data', 'here', 'is', 'simplified', 'version', 'of', 'this', 'function', 'the', 'actual', 'one', 'contains', 'an', 'extra', 'branch', 'to', 'generate', 'command', 'for', 'data', 'from', 'srr', 'identifier', 'def', 'lib', 'data', 'wildcards', 'lib', 'wildcards', 'lib', 'if', 'lib', 'in', 'lib', 'raw', 'raw', 'lib', 'raw', 'lib', 'link_', 'ln', 's_', 'fastq', 'gz', 'raw', 'format', 'mate', 'lib', 'link_', 'ln', 's_', 'fastq', 'gz', 'raw', 'format', 'mate', 'lib', 'return', 'link_', 'link_', 'elif', 'lib', 'in', 'lib', 'raw_single_end', 'raw', 'lib', 'raw_single_end', 'lib', 'return', 'ln', 'fastq', 'gz', 'raw', 'lib', 'else', 'raise', 'valueerror', 'procedure', 'to', 'get', 'raw', 'data', 'for', 'unknown', 'lib', 'apart', 'from', 'their', 'output', 'the', 'two', 'get_raw_data', 'rules', 'are', 'the', 'same', 'and', 'work', 'the', 'following', 'way', 'params', 'shell_command', 'lib', 'data', 'shell', 'cd', 'raw_data_dir', 'params', 'shell_command', 'is', 'snakemake', 'able', 'to', 'determine', 'the', 'correct', 'rule', 'path', 'given', 'information', 'that', 'is', 'not', 'coded', 'in', 'rules', 'input', 'and', 'output', 'but', 'only', 'in', 'config', 'files', 'and', 'functions', 'it', 'seems', 'that', 'it', 'is', 'not', 'the', 'case', 'indeed', 'im', 'trying', 'to', 'test', 'my', 'new', 'snakefile', 'with', 'the', 'added', 'rules', 'but', 'keyerror', 'occurs', 'during', 'the', 'execution', 'of', 'the', 'get_raw_data', 'rule', 'whereas', 'the', 'library', 'for', 'which', 'the', 'rule', 'is', 'being', 'executed', 'is', 'associated', 'with', 'single', 'end', 'data', 'how', 'to', 'achieve', 'the', 'desired', 'behaviour', 'two', 'branch', 'workflow', 'able', 'to', 'use', 'the', 'information', 'in', 'the', 'configuration', 'to', 'chose', 'the', 'correct', 'branch', 'edit', 'the', 'keyerror', 'was', 'due', 'to', 'an', 'error', 'in', 'lib', 'data', 'after', 'using', 'the', 'correct', 'dictionary', 'to', 'get', 'the', 'data', 'associated', 'with', 'the', 'library', 'name', 'end', 'up', 'having', 'the', 'following', 'error', 'rules', 'run_tophat', 'and', 'are', 'ambiguous', 'for', 'the', 'file', 'hwt', 'junctions', 'bed', 'expected', 'input', 'files', 'run_tophat', 'hwt', 'fastq', 'gz', 'hwt', 'fastq', 'gz', 'annotations', 'dmel', 'all', 'gff', 'hwt', 'fastq', 'gz', 'annotations', 'dmel', 'all', 'gff', 'edit', 'adding', 'input', 'to', 'the', 'get_raw_data', 'rules', 'after', 'reading', 'this', 'post', 'on', 'the', 'snakemake', 'mailing', 'list', 'tried', 'to', 'add', 'some', 'input', 'to', 'my', 'rules', 'to', 'avoid', 'ambiguity', 'def', 'lib', 'data_input', 'wildcards', 'lib', 'wildcards', 'lib', 'if', 'lib', 'in', 'lib', 'raw', 'raw', 'lib', 'raw', 'lib', 'return', 'raw', 'format', 'mate', 'raw', 'format', 'mate', 'elif', 'lib', 'in', 'lib', 'raw_single_end', 'raw', 'lib', 'raw_single_end', 'lib', 'return', 'raw', 'else', 'raise', 'valueerror', 'procedure', 'to', 'get', 'raw', 'data', 'for', 'unknown', 'lib', 'rule', 'get_raw_data', 'input', 'lib', 'data_input', 'same', 'output', 'params', 'and', 'shell', 'as', 'before', 'same', 'modification', 'for', 'the', 'single', 'end', 'case', 'this', 'results', 'in', 'strangely', 'the', 'reportedly', 'missing', 'file', 'does', 'exist', 'is', 'the', 'trick', 'supposed', 'to', 'work', 'cant', 'reproduce', 'this', 'now', 'this', 'results', 'in', 'rules', 'and', 'run_tophat', 'are', 'ambiguous', 'for', 'the', 'file', 'htw', 'junctions', 'bed', 'expected', 'input', 'files', 'htw', 'fastq', 'gz', 'annotations', 'dmel', 'all', 'gff', 'run_tophat', 'htw', 'fastq', 'gz', 'htw', 'fastq', 'gz', 'annotations', 'dmel', 'all', 'gff', 'my', 'way', 'of', 'specifying', 'an', 'input', 'to', 'the', 'data', 'installation', 'rules', 'is', 'apparently', 'not', 'enough', 'to', 'guide', 'snakemake', 'to', 'the', 'correct', 'rule']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38592eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=50) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=50)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "#print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d485455",
   "metadata": {},
   "source": [
    "# Remove Stopwords, Make Bigrams and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c49abe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1408ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['initial', 'workflow', 'snakefile', 'generate', 'output', 'datum', 'snakefile', 'rule', 'install', 'datum', 'give', 'information', 'store', 'file', 'get_raw_data', 'rule', 'use', 'datum', 'generate', 'intermediate', 'file', 'rest', 'workflow', 'depend', 'input', 'output', 'rule', 'opj', 'stand', 'os_path', 'join', 'rule', 'output', 'detail', 'implementation', 'rule', 'later', 'rule', 'input', 'transcriptome', 'opj', 'gz', 'output', 'junction', 'opj', 'bam', 'bam', 'simplify', 'main', 'rule', 'something_like', 'rule', 'input', 'expand', 'opj', 'lib', 'extend', 'single_end', 'datum', 'run', 'workflow', 'datum', 'single_end', 'avoid', 'final', 'output', 'different', 'name', 'pattern', 'depend', 'datum', 'single', 'paired_end', 'easily', 'make', 'variant', 'mention', 'rule', 'work', 'single_end', 'datum', 'input', 'output', 'follow', 'rule', 'output', 'rule', 'input', 'transcriptome', 'opj', 'gz', 'output', 'junction', 'opj', 'bam', 'bam', 'provide', 'snakemake', 'enough', 'information', 'choose', 'correct', 'rule', 'path', 'file', 'contain', 'information', 'wildcard', 'associate', 'paired_end', 'datum', 'follow', 'manner', 'library', 'name', 'key', 'raw_single_end', 'dictionary', 'dictionary', 'read', 'file', 'm', 'expect', 'library', 'name', 'key', 'dictionary', 'therefore', 'sense', 'ambiguous', 'want', 'single_end', 'paired_end', 'branch', 'workflow', 'execute', 'function', 'datum', 'use', 'dictionary', 'use', 'get_raw_data', 'determine', 'command', 'run', 'install', 'datum', 'simplify', 'version', 'function', 'actual', 'one', 'contain', 'extra', 'branch', 'generate', 'command', 'datum', 'srr', 'identifier', 'link', 'raw', 'format', 'mate', 'link', 'raw', 'format', 'mate', 'return', 'link', 'link', 'raw_single_end', 'raw', 'return', 'fastq', 'raw', 'else', 'raise_valueerror', 'procedure', 'get', 'raw', 'data', 'unknown', 'lib', 'apart', 'output', 'get_raw_data', 'rule', 'work', 'follow', 'way', 'param', 'param', 'snakemake', 'able', 'determine', 'correct', 'rule', 'path', 'give', 'information', 'code', 'rule', 'input', 'output', 'file', 'function', 'seem', 'case', 'indeed', 'im_trye', 'test', 'new', 'snakefile', 'add', 'rule', 'occur', 'execution', 'get_raw_data', 'rule', 'library', 'rule', 'execute', 'datum', 'achieve', 'desire', 'behaviour', 'branch', 'workflow', 'able', 'use', 'information', 'configuration', 'choose', 'correct', 'branch', 'edit', 'due', 'error', 'lib', 'datum', 'use', 'correct', 'get', 'datum', 'associate', 'library', 'name', 'end', 'follow', 'error', 'rule', 'ambiguous', 'file', 'junction', 'bed', 'expect', 'input', 'file', 'annotation', 'annotation', 'add', 'input', 'get_raw_data', 'rule', 'read', 'post', 'snakemake', 'mailing', 'list', 'try', 'add', 'input', 'rule', 'avoid', 'ambiguity', 'def', 'wildcard', 'return', 'raw', 'format', 'mate', 'raw', 'format', 'mate', 'raw_single_end', 'raw', 'return', 'raw', 'else', 'raise_valueerror', 'procedure', 'get', 'raw', 'data', 'unknown', 'lib', 'rule', 'output', 'param', 'shell', 'case', 'result', 'strangely', 'reportedly', 'miss', 'file', 'exist', 'trick', 'suppose', 'work', 'reproduce', 'result', 'rule', 'ambiguous', 'file', 'htw', 'junction', 'bed', 'expect', 'input', 'file', 'fastq', 'annotation', 'fastq', 'htw', 'fastq', 'gz', 'annotation', 'way', 'specify', 'input', 'datum', 'installation', 'rule', 'apparently', 'enough', 'guide', 'snakemake', 'correct', 'rule']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98003715",
   "metadata": {},
   "source": [
    "# Create the Dictionary and Corpus needed for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd3247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 1), (2, 1), (3, 3), (4, 1), (5, 3), (6, 4), (7, 1), (8, 1), (9, 2), (10, 2), (11, 4), (12, 2), (13, 1), (14, 4), (15, 2), (16, 2), (17, 1), (18, 2), (19, 1), (20, 2), (21, 5), (22, 2), (23, 15), (24, 1), (25, 2), (26, 1), (27, 1), (28, 2), (29, 4), (30, 1), (31, 1), (32, 1), (33, 1), (34, 2), (35, 1), (36, 2), (37, 2), (38, 2), (39, 1), (40, 1), (41, 1), (42, 3), (43, 1), (44, 1), (45, 4), (46, 10), (47, 1), (48, 4), (49, 4), (50, 3), (51, 3), (52, 3), (53, 5), (54, 2), (55, 1), (56, 3), (57, 2), (58, 1), (59, 1), (60, 1), (61, 1), (62, 5), (63, 1), (64, 11), (65, 2), (66, 1), (67, 1), (68, 1), (69, 4), (70, 2), (71, 1), (72, 4), (73, 4), (74, 4), (75, 1), (76, 1), (77, 1), (78, 1), (79, 1), (80, 1), (81, 4), (82, 1), (83, 1), (84, 4), (85, 1), (86, 1), (87, 1), (88, 6), (89, 1), (90, 11), (91, 3), (92, 3), (93, 2), (94, 1), (95, 1), (96, 2), (97, 1), (98, 2), (99, 10), (100, 3), (101, 2), (102, 1), (103, 1), (104, 1), (105, 2), (106, 4), (107, 25), (108, 2), (109, 1), (110, 1), (111, 1), (112, 2), (113, 1), (114, 4), (115, 3), (116, 4), (117, 1), (118, 1), (119, 1), (120, 1), (121, 1), (122, 1), (123, 1), (124, 1), (125, 1), (126, 2), (127, 1), (128, 1), (129, 2), (130, 5), (131, 1), (132, 1), (133, 1), (134, 2), (135, 2), (136, 3), (137, 5)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be414a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('able', 2),\n",
       "  ('achieve', 1),\n",
       "  ('actual', 1),\n",
       "  ('add', 3),\n",
       "  ('ambiguity', 1),\n",
       "  ('ambiguous', 3),\n",
       "  ('annotation', 4),\n",
       "  ('apart', 1),\n",
       "  ('apparently', 1),\n",
       "  ('associate', 2),\n",
       "  ('avoid', 2),\n",
       "  ('bam', 4),\n",
       "  ('bed', 2),\n",
       "  ('behaviour', 1),\n",
       "  ('branch', 4),\n",
       "  ('case', 2),\n",
       "  ('choose', 2),\n",
       "  ('code', 1),\n",
       "  ('command', 2),\n",
       "  ('configuration', 1),\n",
       "  ('contain', 2),\n",
       "  ('correct', 5),\n",
       "  ('data', 2),\n",
       "  ('datum', 15),\n",
       "  ('def', 1),\n",
       "  ('depend', 2),\n",
       "  ('desire', 1),\n",
       "  ('detail', 1),\n",
       "  ('determine', 2),\n",
       "  ('dictionary', 4),\n",
       "  ('different', 1),\n",
       "  ('due', 1),\n",
       "  ('easily', 1),\n",
       "  ('edit', 1),\n",
       "  ('else', 2),\n",
       "  ('end', 1),\n",
       "  ('enough', 2),\n",
       "  ('error', 2),\n",
       "  ('execute', 2),\n",
       "  ('execution', 1),\n",
       "  ('exist', 1),\n",
       "  ('expand', 1),\n",
       "  ('expect', 3),\n",
       "  ('extend', 1),\n",
       "  ('extra', 1),\n",
       "  ('fastq', 4),\n",
       "  ('file', 10),\n",
       "  ('final', 1),\n",
       "  ('follow', 4),\n",
       "  ('format', 4),\n",
       "  ('function', 3),\n",
       "  ('generate', 3),\n",
       "  ('get', 3),\n",
       "  ('get_raw_data', 5),\n",
       "  ('give', 2),\n",
       "  ('guide', 1),\n",
       "  ('gz', 3),\n",
       "  ('htw', 2),\n",
       "  ('identifier', 1),\n",
       "  ('im_trye', 1),\n",
       "  ('implementation', 1),\n",
       "  ('indeed', 1),\n",
       "  ('information', 5),\n",
       "  ('initial', 1),\n",
       "  ('input', 11),\n",
       "  ('install', 2),\n",
       "  ('installation', 1),\n",
       "  ('intermediate', 1),\n",
       "  ('join', 1),\n",
       "  ('junction', 4),\n",
       "  ('key', 2),\n",
       "  ('later', 1),\n",
       "  ('lib', 4),\n",
       "  ('library', 4),\n",
       "  ('link', 4),\n",
       "  ('list', 1),\n",
       "  ('m', 1),\n",
       "  ('mailing', 1),\n",
       "  ('main', 1),\n",
       "  ('make', 1),\n",
       "  ('manner', 1),\n",
       "  ('mate', 4),\n",
       "  ('mention', 1),\n",
       "  ('miss', 1),\n",
       "  ('name', 4),\n",
       "  ('new', 1),\n",
       "  ('occur', 1),\n",
       "  ('one', 1),\n",
       "  ('opj', 6),\n",
       "  ('os_path', 1),\n",
       "  ('output', 11),\n",
       "  ('paired_end', 3),\n",
       "  ('param', 3),\n",
       "  ('path', 2),\n",
       "  ('pattern', 1),\n",
       "  ('post', 1),\n",
       "  ('procedure', 2),\n",
       "  ('provide', 1),\n",
       "  ('raise_valueerror', 2),\n",
       "  ('raw', 10),\n",
       "  ('raw_single_end', 3),\n",
       "  ('read', 2),\n",
       "  ('reportedly', 1),\n",
       "  ('reproduce', 1),\n",
       "  ('rest', 1),\n",
       "  ('result', 2),\n",
       "  ('return', 4),\n",
       "  ('rule', 25),\n",
       "  ('run', 2),\n",
       "  ('seem', 1),\n",
       "  ('sense', 1),\n",
       "  ('shell', 1),\n",
       "  ('simplify', 2),\n",
       "  ('single', 1),\n",
       "  ('single_end', 4),\n",
       "  ('snakefile', 3),\n",
       "  ('snakemake', 4),\n",
       "  ('something_like', 1),\n",
       "  ('specify', 1),\n",
       "  ('srr', 1),\n",
       "  ('stand', 1),\n",
       "  ('store', 1),\n",
       "  ('strangely', 1),\n",
       "  ('suppose', 1),\n",
       "  ('test', 1),\n",
       "  ('therefore', 1),\n",
       "  ('transcriptome', 2),\n",
       "  ('trick', 1),\n",
       "  ('try', 1),\n",
       "  ('unknown', 2),\n",
       "  ('use', 5),\n",
       "  ('variant', 1),\n",
       "  ('version', 1),\n",
       "  ('want', 1),\n",
       "  ('way', 2),\n",
       "  ('wildcard', 2),\n",
       "  ('work', 3),\n",
       "  ('workflow', 5)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a5fd366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fc885ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/540 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 16/540 [00:14<07:52,  1.11it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/Topic Modelling/TopicModellingSnakemake.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m alpha:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m     \u001b[39m# iterare through beta values\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m     \u001b[39mfor\u001b[39;00m b \u001b[39min\u001b[39;00m beta:\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m         \u001b[39m# get the coherence score for the given parameters\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         cv \u001b[39m=\u001b[39m compute_coherence_values(corpus\u001b[39m=\u001b[39;49mcorpus_sets[i], dictionary\u001b[39m=\u001b[39;49mid2word, \n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m                                       k\u001b[39m=\u001b[39;49mk, a\u001b[39m=\u001b[39;49ma, b\u001b[39m=\u001b[39;49mb)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=50'>51</a>\u001b[0m         \u001b[39m# Save the model results\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m         model_results[\u001b[39m'\u001b[39m\u001b[39mValidation_Set\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(corpus_title[i])\n",
      "\u001b[1;32m/home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/Topic Modelling/TopicModellingSnakemake.ipynb Cell 17\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute_coherence_values\u001b[39m(corpus, dictionary, k, a, b):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     lda_model \u001b[39m=\u001b[39m gensim\u001b[39m.\u001b[39;49mmodels\u001b[39m.\u001b[39;49mLdaMulticore(corpus\u001b[39m=\u001b[39;49mcorpus,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                            id2word\u001b[39m=\u001b[39;49mid2word,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                            num_topics\u001b[39m=\u001b[39;49mk, \n\u001b[1;32m      <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                            random_state\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m                                            chunksize\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m                                            passes\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m                                            alpha\u001b[39m=\u001b[39;49ma,\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                                            eta\u001b[39m=\u001b[39;49mb)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     coherence_model_lda \u001b[39m=\u001b[39m CoherenceModel(model\u001b[39m=\u001b[39mlda_model, texts\u001b[39m=\u001b[39mdata_lemmatized, dictionary\u001b[39m=\u001b[39mid2word, coherence\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mc_v\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/uji657/Downloads/Sentiment%20Analysis/SentiCR-master/SentiCR/Topic%20Modelling/TopicModellingSnakemake.ipynb#X22sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m coherence_model_lda\u001b[39m.\u001b[39mget_coherence()\n",
      "File \u001b[0;32m~/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages/gensim/models/ldamulticore.py:186\u001b[0m, in \u001b[0;36mLdaMulticore.__init__\u001b[0;34m(self, corpus, num_topics, id2word, workers, chunksize, passes, batch, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, random_state, minimum_probability, minimum_phi_value, per_word_topics, dtype)\u001b[0m\n\u001b[1;32m    183\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(alpha, \u001b[39mstr\u001b[39m) \u001b[39mand\u001b[39;00m alpha \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    184\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mauto-tuning alpha not implemented in LdaMulticore; use plain LdaModel.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 186\u001b[0m \u001b[39msuper\u001b[39;49m(LdaMulticore, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    187\u001b[0m     corpus\u001b[39m=\u001b[39;49mcorpus, num_topics\u001b[39m=\u001b[39;49mnum_topics,\n\u001b[1;32m    188\u001b[0m     id2word\u001b[39m=\u001b[39;49mid2word, chunksize\u001b[39m=\u001b[39;49mchunksize, passes\u001b[39m=\u001b[39;49mpasses, alpha\u001b[39m=\u001b[39;49malpha, eta\u001b[39m=\u001b[39;49meta,\n\u001b[1;32m    189\u001b[0m     decay\u001b[39m=\u001b[39;49mdecay, offset\u001b[39m=\u001b[39;49moffset, eval_every\u001b[39m=\u001b[39;49meval_every, iterations\u001b[39m=\u001b[39;49miterations,\n\u001b[1;32m    190\u001b[0m     gamma_threshold\u001b[39m=\u001b[39;49mgamma_threshold, random_state\u001b[39m=\u001b[39;49mrandom_state, minimum_probability\u001b[39m=\u001b[39;49mminimum_probability,\n\u001b[1;32m    191\u001b[0m     minimum_phi_value\u001b[39m=\u001b[39;49mminimum_phi_value, per_word_topics\u001b[39m=\u001b[39;49mper_word_topics, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m    192\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages/gensim/models/ldamodel.py:521\u001b[0m, in \u001b[0;36mLdaModel.__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    519\u001b[0m use_numpy \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatcher \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    520\u001b[0m start \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 521\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mupdate(corpus, chunks_as_numpy\u001b[39m=\u001b[39;49muse_numpy)\n\u001b[1;32m    522\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madd_lifecycle_event(\n\u001b[1;32m    523\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcreated\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    524\u001b[0m     msg\u001b[39m=\u001b[39m\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrained \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m in \u001b[39m\u001b[39m{\u001b[39;00mtime\u001b[39m.\u001b[39mtime()\u001b[39m \u001b[39m\u001b[39m-\u001b[39m\u001b[39m \u001b[39mstart\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39ms\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    525\u001b[0m )\n",
      "File \u001b[0;32m~/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages/gensim/models/ldamulticore.py:316\u001b[0m, in \u001b[0;36mLdaMulticore.update\u001b[0;34m(self, corpus, chunks_as_numpy)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[39m# endfor single corpus pass\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \n\u001b[1;32m    314\u001b[0m \u001b[39m# wait for all outstanding jobs to finish\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mwhile\u001b[39;00m queue_size[\u001b[39m0\u001b[39m] \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m--> 316\u001b[0m     process_result_queue(force\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m    318\u001b[0m \u001b[39mif\u001b[39;00m reallen \u001b[39m!=\u001b[39m lencorpus:\n\u001b[1;32m    319\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39minput corpus size changed during training (don\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt use generators as input)\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages/gensim/models/ldamulticore.py:283\u001b[0m, in \u001b[0;36mLdaMulticore.update.<locals>.process_result_queue\u001b[0;34m(force)\u001b[0m\n\u001b[1;32m    281\u001b[0m other\u001b[39m.\u001b[39mreset()\n\u001b[1;32m    282\u001b[0m \u001b[39mif\u001b[39;00m eval_every \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m (force \u001b[39mor\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_updates \u001b[39m/\u001b[39m updateafter) \u001b[39m%\u001b[39m eval_every \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m):\n\u001b[0;32m--> 283\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlog_perplexity(chunk, total_docs\u001b[39m=\u001b[39;49mlencorpus)\n",
      "File \u001b[0;32m~/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages/gensim/models/ldamodel.py:847\u001b[0m, in \u001b[0;36mLdaModel.log_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    845\u001b[0m corpus_words \u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(cnt \u001b[39mfor\u001b[39;00m document \u001b[39min\u001b[39;00m chunk \u001b[39mfor\u001b[39;00m _, cnt \u001b[39min\u001b[39;00m document)\n\u001b[1;32m    846\u001b[0m subsample_ratio \u001b[39m=\u001b[39m \u001b[39m1.0\u001b[39m \u001b[39m*\u001b[39m total_docs \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[0;32m--> 847\u001b[0m perwordbound \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbound(chunk, subsample_ratio\u001b[39m=\u001b[39;49msubsample_ratio) \u001b[39m/\u001b[39m (subsample_ratio \u001b[39m*\u001b[39m corpus_words)\n\u001b[1;32m    848\u001b[0m logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    849\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%.3f\u001b[39;00m\u001b[39m per-word bound, \u001b[39m\u001b[39m%.1f\u001b[39;00m\u001b[39m perplexity estimate based on a held-out corpus of \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m documents with \u001b[39m\u001b[39m%i\u001b[39;00m\u001b[39m words\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    850\u001b[0m     perwordbound, np\u001b[39m.\u001b[39mexp2(\u001b[39m-\u001b[39mperwordbound), \u001b[39mlen\u001b[39m(chunk), corpus_words\n\u001b[1;32m    851\u001b[0m )\n\u001b[1;32m    852\u001b[0m \u001b[39mreturn\u001b[39;00m perwordbound\n",
      "File \u001b[0;32m~/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages/gensim/models/ldamodel.py:1122\u001b[0m, in \u001b[0;36mLdaModel.bound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39massert\u001b[39;00m Elogthetad\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\n\u001b[1;32m   1121\u001b[0m \u001b[39m# E[log p(doc | theta, beta)]\u001b[39;00m\n\u001b[0;32m-> 1122\u001b[0m score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39msum\u001b[39;49m(cnt \u001b[39m*\u001b[39;49m logsumexp(Elogthetad \u001b[39m+\u001b[39;49m Elogbeta[:, \u001b[39mint\u001b[39;49m(\u001b[39mid\u001b[39;49m)]) \u001b[39mfor\u001b[39;49;00m \u001b[39mid\u001b[39;49m, cnt \u001b[39min\u001b[39;49;00m doc)\n\u001b[1;32m   1124\u001b[0m \u001b[39m# E[log p(theta | alpha) - log q(theta | gamma)]; assumes alpha is a vector\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m-\u001b[39m gammad) \u001b[39m*\u001b[39m Elogthetad)\n",
      "File \u001b[0;32m~/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages/gensim/models/ldamodel.py:1122\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[39massert\u001b[39;00m Elogthetad\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype\n\u001b[1;32m   1121\u001b[0m \u001b[39m# E[log p(doc | theta, beta)]\u001b[39;00m\n\u001b[0;32m-> 1122\u001b[0m score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39msum\u001b[39m(cnt \u001b[39m*\u001b[39m logsumexp(Elogthetad \u001b[39m+\u001b[39;49m Elogbeta[:, \u001b[39mint\u001b[39;49m(\u001b[39mid\u001b[39;49m)]) \u001b[39mfor\u001b[39;00m \u001b[39mid\u001b[39m, cnt \u001b[39min\u001b[39;00m doc)\n\u001b[1;32m   1124\u001b[0m \u001b[39m# E[log p(theta | alpha) - log q(theta | gamma)]; assumes alpha is a vector\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m score \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m np\u001b[39m.\u001b[39msum((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39malpha \u001b[39m-\u001b[39m gammad) \u001b[39m*\u001b[39m Elogthetad)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('../dataset/lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41468242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation_Set</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>2</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.544267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>2</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.544267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>2</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.542629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>6</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.537383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.537121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.434032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>7</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.431641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>8</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.425680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>8</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.422407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>10</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.421497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Validation_Set  Topics               Alpha                Beta  Coherence\n",
       "297    100% Corpus       2          asymmetric                0.61   0.544267\n",
       "299    100% Corpus       2          asymmetric           symmetric   0.544267\n",
       "298    100% Corpus       2          asymmetric  0.9099999999999999   0.542629\n",
       "411    100% Corpus       6           symmetric                0.31   0.537383\n",
       "391    100% Corpus       6                0.01                0.31   0.537121\n",
       "..             ...     ...                 ...                 ...        ...\n",
       "528    100% Corpus      10  0.9099999999999999  0.9099999999999999   0.434032\n",
       "423    100% Corpus       7                0.01  0.9099999999999999   0.431641\n",
       "453    100% Corpus       8                0.01  0.9099999999999999   0.425680\n",
       "473    100% Corpus       8           symmetric  0.9099999999999999   0.422407\n",
       "518    100% Corpus      10                0.31  0.9099999999999999   0.421497\n",
       "\n",
       "[268 rows x 5 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('../dataset/lda_tuning_results.csv')\n",
    "results = results.loc[272:]\n",
    "results.sort_values(by=['Coherence'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a9f15c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.622738286362022\n",
      "\n",
      "Coherence Score:  0.41145452501309315\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el3791881397142933819685381471345\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el3791881397142933819685381471345_data = {\"mdsDat\": {\"x\": [-0.1840038388912397, -0.15548746440469022, 0.11404862791420925, 0.11068319029966289, 0.11475948508205769], \"y\": [-0.08780652223936639, 0.09714322635723142, -0.02514493915877646, -0.0003477852838409305, 0.016156020324752444], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [58.59419865620376, 33.7121254003131, 3.5033486961014915, 2.1409908015639667, 2.0493364458176835]}, \"tinfo\": {\"Term\": [\"snakemake\", \"sample\", \"input\", \"log\", \"job\", \"fastq\", \"wildcard\", \"environment\", \"output\", \"error\", \"rule\", \"expand\", \"group\", \"use\", \"field\", \"fail\", \"param\", \"file\", \"site_package\", \"pattern\", \"need\", \"run\", \"cluster\", \"package\", \"conda\", \"image\", \"detect\", \"execute\", \"bam\", \"read\", \"sample\", \"expand\", \"fastq\", \"bam\", \"wildcard\", \"merge\", \"fast\", \"checkpoint\", \"join\", \"sample_name\", \"barcode\", \"filter\", \"glob_wildcard\", \"function\", \"os_path\", \"processing\", \"pair\", \"affect\", \"range\", \"def\", \"sequence\", \"determine\", \"ref\", \"alignment\", \"item\", \"input\", \"chromosome\", \"basecalle\", \"database\", \"align\", \"read\", \"folder\", \"param\", \"result\", \"datum\", \"output\", \"list\", \"txt\", \"rule\", \"trim\", \"miss\", \"file\", \"value\", \"process\", \"gz\", \"want\", \"name\", \"directory\", \"path\", \"snakefile\", \"quot\", \"run\", \"get\", \"snakemake\", \"use\", \"thread\", \"line\", \"error\", \"create\", \"follow\", \"work\", \"script\", \"environment\", \"site_package\", \"package\", \"conda\", \"reproduce_error\", \"sbatch\", \"lib_python\", \"self\", \"submit\", \"com\", \"activate\", \"instal\", \"locally\", \"profile\", \"host\", \"traceback\", \"usr_local\", \"source\", \"conda_forge\", \"cluster\", \"scheduler\", \"qc_fastqc\", \"crispr_t\", \"tb_ssd_analyse\", \"python_site\", \"mamba\", \"status\", \"env\", \"uds_alma_git\", \"install\", \"remote\", \"html\", \"project\", \"max\", \"fail\", \"log\", \"available\", \"job\", \"snakemake\", \"execute\", \"directive\", \"error\", \"core\", \"use\", \"tmp\", \"run\", \"script\", \"check\", \"fastqc\", \"file\", \"command\", \"try\", \"work\", \"line\", \"workflow\", \"rule\", \"get\", \"set\", \"thread\", \"output\", \"quot\", \"snakefile\", \"create\", \"path\", \"field\", \"transcript_name\", \"gene_transcript\", \"perl_pe\", \"gene_name\", \"prjna_rawqc\", \"detect\", \"fi\", \"cut\", \"prjna_srr\", \"table_sample\", \"app_name_size\", \"image\", \"vm_type\", \"experiment\", \"perlexpr\", \"quotation\", \"scbe_pipe\", \"sign\", \"tumor\", \"organism\", \"prepare\", \"capture\", \"entity\", \"resources_raw_dataset\", \"unit\", \"values_tolist\", \"megalodon\", \"megalodon_mapping\", \"fnmatch\", \"bed\", \"gtf_version\", \"pattern\", \"gtf\", \"gene\", \"information\", \"parse\", \"batch\", \"head\", \"machine\", \"well\", \"else\", \"dataset\", \"need\", \"group\", \"param\", \"antismash\", \"merged_read\", \"pear\", \"fastqc_premerge\", \"xdot\", \"plain\", \"dot\", \"prodigal\", \"unmap\", \"graphviz\", \"rulegraph\", \"bsstre\", \"lanenum_proj\", \"tranche\", \"tpdf\", \"lanenum\", \"binningsignal\", \"inputdirectory\", \"lanenum_bsstre\", \"gbk_file\", \"protein_file\", \"ppx_s_downsample\", \"canon\", \"cmap\", \"cmapx\", \"dot_json\", \"ep\", \"pic\", \"textiowrapper\", \"vml\", \"pdf\", \"zipfq\", \"utf\", \"extension\", \"move\", \"text_identity\", \"png\", \"pool\", \"cdirs_user\", \"pertoldi_legend\", \"lab_bereket_public\", \"po\", \"tier_ver\", \"blue_nv\", \"sfs_nfs\", \"fibers_rn\", \"group_sim\", \"sim\", \"tier_raw\", \"shadow\", \"venv\", \"ng_neb_\", \"scratch_group\", \"runtime\", \"benchmark\", \"merlin_test\", \"test_data\", \"elide\", \"prodenv\", \"prodenv_sim\", \"profit\", \"reflector\", \"srun\", \"wl\", \"neand_sqtl\", \"rmccoy_aseyedi\", \"queue\", \"cookie\", \"maximum\", \"sit\", \"array\", \"license\", \"select_job\", \"finished_job\", \"steps_done\", \"group\", \"regular\", \"export\"], \"Freq\": [1763.0, 1155.0, 1357.0, 484.0, 426.0, 431.0, 455.0, 165.0, 1399.0, 682.0, 1666.0, 307.0, 65.0, 653.0, 31.0, 154.0, 340.0, 1802.0, 98.0, 32.0, 105.0, 650.0, 105.0, 89.0, 89.0, 26.0, 23.0, 126.0, 170.0, 364.0, 1153.6531384660184, 305.5691903534754, 428.76864443447295, 168.85751011482222, 450.86540346189383, 69.47123548922173, 62.464606279313436, 53.582599292863364, 104.15439127068711, 48.1010711678356, 52.385662224754725, 47.64636211468491, 44.403613625118986, 89.96636801687727, 69.76884507652112, 46.370612113599414, 33.37018232608079, 31.523261119779953, 33.30122391266779, 44.872585798691034, 39.34049229912199, 29.032475176477192, 31.546418853696093, 34.39113145407592, 26.313626388814257, 1287.9209597822612, 28.586252389683033, 30.950133331831093, 26.613678317765164, 28.023730015561725, 339.89289227678864, 122.7331255197044, 312.37294264156947, 280.86253961840816, 271.95563313299726, 1225.4506443841901, 137.15588451329, 168.9650350769132, 1411.1333880775471, 94.85962080395102, 155.8498849023746, 1333.9490131586417, 69.73808163524325, 86.5846344179246, 131.93995620462957, 148.62699427393102, 184.3856164292897, 175.84393872080133, 230.09522870843665, 233.0192419360058, 228.48846980767297, 357.52085504675506, 218.63196850226362, 701.7330769166315, 331.4872425477, 185.51127660118146, 207.3053865344404, 317.1734948223768, 171.2070660071251, 156.38292693546762, 164.71241895562525, 169.47192741080224, 164.02624858786052, 96.89146375707264, 87.39802623809841, 86.84618152819206, 54.24683114608834, 53.82984993972483, 52.34555415613234, 39.83643419074728, 40.3211633744024, 38.25746226796027, 35.065717922769785, 32.24284619300761, 38.185091162641, 43.239372644623174, 31.466073833690157, 30.61924416000755, 26.35684260022319, 44.31411184075592, 25.573451774384452, 98.38008425869485, 28.53646040227978, 27.578956250409068, 27.044495036352384, 27.044495036352384, 23.984928504723346, 23.190198098963208, 28.884533395464192, 23.465806455336462, 21.304763562180977, 28.809966527025814, 30.0842395725218, 49.776266343343835, 47.68065763652585, 36.37529687951359, 131.495327626775, 376.2323323844586, 36.65615413413405, 312.4873960525627, 1061.25690771754, 100.30358165879535, 51.80489759420815, 364.22399338828905, 80.20332555692228, 320.96868921288075, 60.890065697206246, 291.8587493758446, 174.1746648751307, 59.204467873665756, 82.9837139469043, 467.6067564687267, 94.08289121086807, 124.44878973651223, 124.9302898567569, 131.1748263812353, 101.51020916625275, 254.4864157005552, 116.86277110879472, 70.55120518113749, 96.62965574963357, 173.1086018383408, 101.23992987797688, 94.90375921473061, 87.69003155577592, 83.29884381248124, 29.639433356865066, 15.788804447749687, 12.953506168643196, 10.118592051083498, 5.868146773775514, 5.536329783383171, 15.682674034883075, 5.463834333896483, 5.912178629716375, 4.5182285548382675, 4.200740790141247, 3.906781300226875, 16.468396406619043, 3.565574105664284, 8.791792488894068, 3.0397995044397637, 3.0397995044397637, 3.0397995044397637, 3.0397995044397637, 3.184416655884182, 3.3952958885846685, 5.908956301175698, 4.42169940357002, 2.8834867166991116, 2.818795995022992, 9.711453015341508, 3.4226537448590673, 2.262948950208492, 2.262948950208492, 2.5178382851236956, 7.428695214675687, 2.5178382851236956, 14.170229099474515, 4.439928563233132, 7.535020948232355, 6.107628453592956, 6.203080101149239, 5.629463501992066, 4.861149202468596, 5.148335878028511, 5.416843971200091, 5.331524468729124, 5.2180014917355795, 6.251132230819535, 4.355089494118273, 4.395512082900242, 7.720792568894764, 4.162678700330499, 3.1255867445145338, 2.582369678955262, 2.4064135504773216, 2.398027400276276, 3.4445970522196845, 1.9437880162930798, 1.9411795072147595, 1.8572311680445697, 1.7609349807606298, 1.7773783182416538, 1.7773783182416538, 1.6631668046192212, 1.6060999406727055, 1.576790136405724, 1.5641461368058538, 1.3766893175216424, 1.3766893175216424, 1.3542151817258417, 1.3542151817258417, 3.600623062539041, 1.2837123180255525, 1.2837123180255525, 1.2837123180255525, 1.2837123180255525, 1.2837123180255525, 1.2837123180255525, 1.2837123180255525, 1.2837123180255525, 1.8826785572752829, 1.4401965570053818, 1.3871188281197588, 2.0054749282802318, 1.9454980294825168, 1.37438374850219, 1.3597135013657173, 1.350699408185505, 8.925140505807832, 8.925140505807832, 3.97931599037486, 3.9566884741124007, 3.9566884741124007, 2.642918754146808, 2.452480374583115, 2.970437526400999, 2.970437526400999, 2.970437526400999, 2.970437526400999, 3.007727956945723, 2.3618151707721995, 2.502843073299568, 1.9727400185299047, 3.9327240028722685, 7.209898746998043, 1.8040691233358848, 1.8040691233358848, 1.993771473716345, 1.993771473716345, 1.993771473716345, 1.993771473716345, 1.993771473716345, 1.993771473716345, 1.993771473716345, 1.582493880001981, 1.582493880001981, 2.0113996230969233, 1.648575952766369, 2.7854958782987707, 3.133515168373825, 2.0579691384927616, 2.4900001289160305, 3.238311807604881, 3.1327446187856403, 3.0569583863797485, 4.560001997581984, 2.5165805699808437, 2.073246109860762], \"Total\": [1763.0, 1155.0, 1357.0, 484.0, 426.0, 431.0, 455.0, 165.0, 1399.0, 682.0, 1666.0, 307.0, 65.0, 653.0, 31.0, 154.0, 340.0, 1802.0, 98.0, 32.0, 105.0, 650.0, 105.0, 89.0, 89.0, 26.0, 23.0, 126.0, 170.0, 364.0, 1155.2979446191057, 307.18403299180306, 431.1696648696834, 170.35644482794945, 455.28379036431284, 71.19733695634766, 64.03790559993924, 55.00698217229698, 106.93983794304408, 49.476394612927194, 53.89547759361423, 49.04361994598344, 45.85913145816067, 92.98581444522502, 72.23687786907058, 48.064967342591096, 34.7714669516797, 32.91355791617375, 34.770747386138275, 46.93171698900894, 41.2446823688282, 30.48608355495227, 33.1961614814292, 36.20797981990165, 27.72657428928664, 1357.0898175573386, 30.12674916202824, 32.63353737211382, 28.112451662500085, 29.610926855186413, 364.35408022521847, 131.08447966791826, 340.3390372229895, 308.311375670098, 299.3002476333115, 1399.5409997175739, 149.06950984939672, 185.6503205308467, 1666.666339290059, 102.49836219956602, 178.38277109906437, 1802.4588777412835, 76.03265081939888, 96.60824036308158, 154.8525583674132, 178.77817951163948, 229.5381719758234, 218.7639735166993, 314.22250003282875, 328.8279505058315, 331.0617330853302, 650.3315210277732, 336.37936639911317, 1763.9003739277362, 653.5409204840705, 283.4185801431005, 339.3319559722652, 682.3284192989504, 259.8907142001292, 223.32757675503737, 290.931960839061, 344.4310788544818, 165.866658775449, 98.65420763447361, 89.27997857507289, 89.30716997173452, 55.88936099286018, 55.57046656336613, 54.11955320222981, 41.703025705300206, 42.355214361657794, 40.220258291270845, 36.90000463348913, 33.95195966185178, 40.26075891457332, 45.59225796616204, 33.31965349669664, 32.50135515967983, 27.996684688938092, 47.153927042903774, 27.25924895080378, 105.00103221196075, 30.467363845296912, 29.466137068735787, 28.94402716306417, 28.94402716306417, 25.71950684179915, 24.872426528594293, 31.023664935322607, 25.226674133431185, 22.940345840547756, 31.03293672229474, 32.46614547666064, 54.0879922477042, 52.06753840295665, 39.45390466801458, 154.089584773443, 484.20976956491205, 40.25424138355205, 426.38940597358106, 1763.9003739277362, 126.71076253192614, 59.84022161110338, 682.3284192989504, 110.05092408965268, 653.5409204840705, 79.93396213807395, 650.3315210277732, 344.4310788544818, 79.74523822217164, 131.9907100108046, 1802.4588777412835, 170.97959936343693, 275.1607029981658, 290.931960839061, 339.3319559722652, 227.34078929809286, 1666.666339290059, 336.37936639911317, 119.6400933734736, 283.4185801431005, 1399.5409997175739, 331.0617330853302, 328.8279505058315, 259.8907142001292, 314.22250003282875, 31.965889448014405, 17.952462202877637, 15.115576484863663, 12.278218212884665, 8.019838789402163, 8.21383325506683, 23.727919779278928, 8.470275105053235, 9.32671515549927, 7.162060228267675, 6.766394292756018, 6.30601823843021, 26.798502610322394, 5.959423827029856, 14.759578145248419, 5.174493598191694, 5.174493598191694, 5.174493598191694, 5.174493598191694, 5.865977582060605, 6.273885882660708, 11.021796791155026, 8.289189847048302, 5.487557546732967, 5.414595975159118, 18.678504172080846, 6.727411239964241, 4.455109826388655, 4.455109826388655, 4.985053525286975, 15.426640245324243, 4.985053525286975, 32.290524770968574, 10.030934645512035, 21.69515681025693, 22.92938905024711, 27.919305648368795, 23.56793793326056, 23.362993469885737, 29.46284729180901, 37.127645676254716, 38.68408508758922, 38.97235638979958, 105.60622548667087, 65.1076963878628, 340.3390372229895, 9.990714062975467, 6.423226438918496, 5.38066662420763, 4.876541604686853, 4.67608460764037, 4.942092729922443, 7.1106150771655665, 4.184258233635137, 4.186606209467529, 4.070406657220808, 3.918179229433453, 4.055408962248521, 4.055408962248521, 3.852420155505209, 3.779807759109796, 3.8483081730978688, 3.866485288147874, 3.6398661056233017, 3.6398661056233017, 3.5814334272333888, 3.5814334272333888, 9.766803446431755, 3.50801646157284, 3.50801646157284, 3.50801646157284, 3.50801646157284, 3.50801646157284, 3.50801646157284, 3.50801646157284, 3.50801646157284, 6.1764326284182385, 4.228358616509539, 4.023546822339704, 19.886182595521834, 21.564442839534706, 6.729988782203968, 7.00884329848859, 6.9451370440583355, 11.889505671606484, 11.889505671606484, 6.3585314212804676, 6.763420146949644, 6.763420146949644, 4.822416673112554, 4.6288099061523535, 5.723820328792771, 5.723820328792771, 5.723820328792771, 5.723820328792771, 5.986747331294177, 4.756496472724652, 5.085866825847118, 4.18972996200601, 8.823697154440895, 16.52365033151517, 4.147890590411578, 4.147890590411578, 4.66570438158247, 4.66570438158247, 4.66570438158247, 4.66570438158247, 4.66570438158247, 4.66570438158247, 4.66570438158247, 3.7947021641003977, 3.7947021641003977, 5.006863109428202, 4.176396133229675, 7.216046865100776, 9.65969274731911, 5.444569165920747, 7.180318648757066, 12.911217875455943, 13.287000327328641, 13.62012800228742, 65.1076963878628, 11.12371360577526, 7.380465009743803], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.3611, -4.6896, -4.3508, -5.2827, -4.3006, -6.1708, -6.2772, -6.4305, -5.7659, -6.5384, -6.4531, -6.5479, -6.6184, -5.9123, -6.1666, -6.5751, -6.9041, -6.961, -6.9062, -6.6079, -6.7395, -7.0433, -6.9603, -6.874, -7.1417, -3.251, -7.0588, -6.9794, -7.1303, -7.0787, -4.5831, -5.6017, -4.6676, -4.7739, -4.8061, -3.3007, -5.4906, -5.2821, -3.1596, -5.8594, -5.3629, -3.2159, -6.167, -5.9506, -5.5294, -5.4103, -5.1947, -5.2422, -4.9733, -4.9606, -4.9803, -4.5326, -5.0244, -3.8582, -4.6082, -5.1886, -5.0776, -4.6523, -5.2689, -5.3594, -5.3076, -5.2791, -4.7589, -5.2854, -5.3885, -5.3948, -5.8654, -5.8731, -5.9011, -6.1742, -6.1621, -6.2146, -6.3018, -6.3857, -6.2165, -6.0922, -6.4101, -6.4373, -6.5872, -6.0677, -6.6174, -5.2701, -6.5078, -6.5419, -6.5615, -6.5615, -6.6815, -6.7152, -6.4957, -6.7034, -6.8, -6.4983, -6.455, -5.9514, -5.9944, -6.2651, -4.98, -3.9288, -6.2574, -4.1144, -2.8918, -5.2508, -5.9115, -3.9612, -5.4744, -4.0876, -5.7499, -4.1827, -4.6989, -5.778, -5.4403, -3.7113, -5.3148, -5.0351, -5.0312, -4.9824, -5.2388, -4.3197, -5.098, -5.6026, -5.2881, -4.7051, -5.2415, -5.3061, -5.3852, -5.4365, -4.2057, -4.8355, -5.0335, -5.2805, -5.8253, -5.8835, -4.8423, -5.8967, -5.8178, -6.0867, -6.1596, -6.2321, -4.7934, -6.3235, -5.421, -6.483, -6.483, -6.483, -6.483, -6.4366, -6.3724, -5.8184, -6.1083, -6.5358, -6.5585, -5.3215, -6.3644, -6.7782, -6.7782, -6.6714, -5.5895, -6.6714, -4.9437, -6.1042, -5.5753, -5.7853, -5.7698, -5.8668, -6.0136, -5.9562, -5.9053, -5.9212, -5.9427, -5.7621, -6.1235, -6.1143, -5.0585, -5.6762, -5.9628, -6.1537, -6.2242, -6.2277, -5.8656, -6.4377, -6.4391, -6.4833, -6.5365, -6.5272, -6.5272, -6.5937, -6.6286, -6.647, -6.655, -6.7827, -6.7827, -6.7992, -6.7992, -5.8213, -6.8526, -6.8526, -6.8526, -6.8526, -6.8526, -6.8526, -6.8526, -6.8526, -6.4697, -6.7376, -6.7752, -6.4065, -6.4369, -6.7844, -6.7951, -6.8018, -4.8698, -4.8698, -5.6775, -5.6832, -5.6832, -6.0867, -6.1615, -5.9699, -5.9699, -5.9699, -5.9699, -5.9574, -6.1992, -6.1412, -6.3792, -5.6893, -5.0832, -6.4686, -6.4686, -6.3686, -6.3686, -6.3686, -6.3686, -6.3686, -6.3686, -6.3686, -6.5996, -6.5996, -6.3598, -6.5587, -6.0342, -5.9165, -6.3369, -6.1464, -5.8836, -5.9167, -5.9412, -5.5413, -6.1357, -6.3295], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5331, 0.5293, 0.529, 0.5257, 0.5248, 0.51, 0.5097, 0.5083, 0.5081, 0.5063, 0.5061, 0.5056, 0.5023, 0.5015, 0.4998, 0.4986, 0.4934, 0.4914, 0.4914, 0.4897, 0.4873, 0.4857, 0.4836, 0.4831, 0.4822, 0.4822, 0.482, 0.4816, 0.4797, 0.4794, 0.465, 0.4687, 0.4488, 0.4413, 0.4387, 0.4017, 0.4512, 0.4404, 0.3681, 0.4571, 0.3995, 0.2335, 0.4481, 0.425, 0.3744, 0.3498, 0.3155, 0.3161, 0.2229, 0.1901, 0.1637, -0.0638, 0.1037, -0.3872, -0.1443, 0.1107, 0.0417, -0.2315, 0.1171, 0.1782, -0.0344, -0.1747, 1.0762, 1.0693, 1.066, 1.0594, 1.0575, 1.0555, 1.054, 1.0415, 1.0381, 1.0373, 1.0363, 1.0357, 1.0344, 1.0343, 1.0301, 1.0277, 1.027, 1.0252, 1.0235, 1.0222, 1.0218, 1.0211, 1.0194, 1.0194, 1.0175, 1.0173, 1.0159, 1.015, 1.0133, 1.013, 1.0111, 1.0042, 0.9993, 1.0061, 0.9287, 0.835, 0.9937, 0.7765, 0.5792, 0.8536, 0.9431, 0.4596, 0.7709, 0.3763, 0.8152, 0.2861, 0.4055, 0.7895, 0.6232, -0.262, 0.4899, 0.2939, 0.242, 0.1369, 0.281, -0.792, 0.0301, 0.5592, 0.0113, -1.0027, -0.0975, -0.1554, 0.0009, -0.2404, 3.2759, 3.223, 3.1971, 3.158, 3.0391, 2.957, 2.9374, 2.913, 2.8956, 2.8908, 2.8747, 2.8727, 2.8645, 2.8378, 2.8334, 2.8195, 2.8195, 2.8195, 2.8195, 2.7406, 2.7374, 2.728, 2.723, 2.708, 2.6987, 2.6974, 2.6757, 2.6741, 2.6741, 2.6684, 2.6207, 2.6684, 2.5278, 2.5364, 2.2939, 2.0286, 1.8472, 1.9196, 1.7816, 1.607, 1.4266, 1.3697, 1.3407, 0.5245, 0.6468, -0.9979, 3.5862, 3.4101, 3.3007, 3.2082, 3.1796, 3.1208, 3.1191, 3.0772, 3.0753, 3.0592, 3.0441, 3.019, 3.019, 3.0039, 2.988, 2.9517, 2.9389, 2.8716, 2.8716, 2.8714, 2.8714, 2.846, 2.8386, 2.8386, 2.8386, 2.8386, 2.8386, 2.8386, 2.8386, 2.8386, 2.6559, 2.7669, 2.779, 1.5498, 1.4384, 2.2553, 2.204, 2.2065, 3.6009, 3.6009, 3.419, 3.3515, 3.3515, 3.2863, 3.2525, 3.2317, 3.2317, 3.2317, 3.2317, 3.1993, 3.1876, 3.1786, 3.1344, 3.0795, 3.0583, 3.0551, 3.0551, 3.0374, 3.0374, 3.0374, 3.0374, 3.0374, 3.0374, 3.0374, 3.0131, 3.0131, 2.9757, 2.9581, 2.9358, 2.7618, 2.9148, 2.8286, 2.5046, 2.4428, 2.3935, 1.2289, 2.4015, 2.6179]}, \"token.table\": {\"Topic\": [1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 4, 1, 2, 3, 1, 2, 5, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 5, 1, 2, 4, 1, 2, 5, 1, 2, 4, 1, 2, 4, 1, 2, 3, 1, 2, 5, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 4, 1, 2, 4, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 5, 1, 2, 3, 5, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 4, 1, 2, 4, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 4, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 5, 1, 2, 4, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 4, 1, 2, 3, 1, 2, 5, 1, 2, 3, 1, 2, 1, 2, 1, 2, 5, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 4, 1, 2, 3, 5, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 4, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 5, 1, 2, 4, 1, 2, 4, 1, 2, 4, 1, 2, 1, 2, 5, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 4, 1, 2, 5, 1, 2, 1, 2, 4, 1, 2, 1, 2, 5, 1, 2, 3, 1, 2, 5, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 2, 4, 1, 2, 4, 1, 2, 3, 1, 2, 3, 1, 2, 5, 1, 2, 4, 1, 2, 4, 1, 2, 4, 1, 2, 5, 1, 2, 4, 1, 2, 4, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 5, 1, 2, 5, 1, 2, 4, 1, 2, 1, 2, 5, 1, 2, 3, 4, 1, 2, 4, 1, 2, 1, 2, 1, 2, 5, 1, 2, 3, 1, 2, 3, 1, 2, 1, 2, 1, 2, 1, 2, 5, 1, 2, 5, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 5, 1, 2, 3, 1, 2, 4, 1, 2, 1, 2, 5, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 5, 1, 2, 1, 2, 5, 1, 2, 1, 2, 1, 2, 4, 1, 2, 5, 1, 2, 5, 1, 2, 3, 1, 2, 5, 1, 2, 5, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 5, 1, 2, 1, 2, 5, 1, 2, 1, 2, 3, 1, 2, 1, 2, 5, 1, 2, 4, 1, 2, 4, 1, 2, 3, 1, 2, 5, 1, 2, 5, 1, 2, 3, 1, 2, 4, 1, 2, 1, 2, 4, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 4, 1, 2, 3, 1, 2, 1, 2, 4, 1, 2, 3, 1, 2, 3, 1, 2, 5, 1, 2, 3, 1, 2, 4, 1, 2, 1, 2, 3, 1, 2, 3, 1, 2, 5, 1, 2, 3, 1, 2, 1, 2, 4, 1, 2, 4], \"Freq\": [0.02710026759976164, 0.9485093659916575, 0.9722437203993426, 0.030382616262479456, 0.9455968783731518, 0.03377131708475542, 0.9390195246770426, 0.027618221314030664, 0.10009294567901754, 0.10009294567901754, 0.8007435654321403, 0.15857867233966885, 0.15857867233966885, 0.6343146893586754, 0.3673385237749614, 0.1836692618874807, 0.3673385237749614, 0.074526308207259, 0.9191578012228611, 0.9920376077974662, 0.005870045016553054, 0.9648304889715122, 0.01855443248022139, 0.9499429879915586, 0.030643322193276087, 0.25458315517423447, 0.5091663103484689, 0.25458315517423447, 0.45376050058091383, 0.06482292865441626, 0.45376050058091383, 0.4236352052699314, 0.06051931503856163, 0.06051931503856163, 0.4236352052699314, 0.2586328216650271, 0.2586328216650271, 0.5172656433300542, 0.20736491012390382, 0.20736491012390382, 0.6220947303717115, 0.24658425557296942, 0.24658425557296942, 0.49316851114593885, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.24127810279459097, 0.12063905139729549, 0.48255620558918194, 0.0841077861115888, 0.1682155722231776, 0.7569700750042991, 0.2507986739506583, 0.739856088154442, 0.9816935572080134, 0.018179510318666915, 0.9625997097805562, 0.03319309344070884, 0.057142295400373556, 0.9333241582061014, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.024863092443566773, 0.9447975128555374, 0.4444974738679391, 0.5497731913629773, 0.022394618490687752, 0.9741659043449172, 0.03668479648154479, 0.9538047085201645, 0.23944088829205093, 0.23944088829205093, 0.47888177658410186, 0.26351437064149713, 0.7269361948730955, 0.009086702435913694, 0.009086702435913694, 0.6579688717478425, 0.33860386382345115, 0.0038477711798119447, 0.034549442424380815, 0.932834945458282, 0.10721888503374892, 0.21443777006749784, 0.6433133102024935, 0.9604285077710241, 0.03557142621374163, 0.7184579685135122, 0.15395527896718117, 0.12829606580598432, 0.9087864181563976, 0.08686928997083213, 0.003341126537339697, 0.9588398398153357, 0.02130755199589635, 0.02130755199589635, 0.21072222287123502, 0.12643333372274101, 0.6743111131879521, 0.9512537072112411, 0.032801851972801416, 0.11697817640937926, 0.8689807390411031, 0.8045200366895195, 0.19198773602818078, 0.2812696198986544, 0.1406348099493272, 0.4219044298479816, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.21432990995902515, 0.21432990995902515, 0.4286598199180503, 0.6204101750282773, 0.232653815635604, 0.12925211979755777, 0.3644608704268998, 0.1822304352134499, 0.5466913056403496, 0.0396405802330783, 0.911733345360801, 0.006028939193583228, 0.9887460277476494, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.46458566144100755, 0.533467447206709, 0.19729973603229625, 0.789198944129185, 0.996145525598218, 0.003255377534634699, 0.33876306970261616, 0.06775261394052323, 0.6097735254647091, 0.4064784530567321, 0.13549281768557736, 0.13549281768557736, 0.2709856353711547, 0.8548649253491329, 0.050286172079360765, 0.10057234415872153, 0.1427740884132206, 0.8501547991878136, 0.9681765732210147, 0.015615751180984109, 0.9949679556646474, 0.004638545247853834, 0.3636619576943769, 0.6288321351798601, 0.20506335863901953, 0.20506335863901953, 0.6151900759170587, 0.11805991984881524, 0.11805991984881524, 0.5902995992440763, 0.17470848883387527, 0.17470848883387527, 0.5241254665016258, 0.031283346631924114, 0.031283346631924114, 0.9385003989577234, 0.7401001024065949, 0.2596453132880708, 0.9787205767614039, 0.02039001201586258, 0.07526153197597238, 0.6773537877837514, 0.22578459592791714, 0.20059965152378836, 0.20059965152378836, 0.6017989545713651, 0.9383261871397819, 0.061029345505026464, 0.698525467686029, 0.2955300055594738, 0.9678895704356726, 0.021508657120792724, 0.2792178104989898, 0.2792178104989898, 0.2792178104989898, 0.5531188414515953, 0.04609323678763294, 0.3687458943010635, 0.1246907857202133, 0.1246907857202133, 0.7481447143212798, 0.06615692104111104, 0.06615692104111104, 0.8600399735344434, 0.651050634717461, 0.3478215719723422, 0.9594599505257347, 0.02180590796649397, 0.24567569882139983, 0.24567569882139983, 0.49135139764279967, 0.4454158511036815, 0.4146975165448069, 0.06143666911774917, 0.07679583639718647, 0.17470848883387527, 0.17470848883387527, 0.5241254665016258, 0.39876643018401575, 0.09969160754600394, 0.39876643018401575, 0.20059965152378836, 0.20059965152378836, 0.6017989545713651, 0.8524237596824733, 0.14207062661374556, 0.4280273421678488, 0.38522460795106395, 0.2140136710839244, 0.030012316907771612, 0.93038182414092, 0.07395356776567691, 0.9244195970709614, 0.07463103551276888, 0.2985241420510755, 0.597048284102151, 0.4361215197703765, 0.2616729118622259, 0.2616729118622259, 0.9490897237135747, 0.05010722143829432, 0.0007368709035043281, 0.2747353806380625, 0.2747353806380625, 0.2747353806380625, 0.029453380893462656, 0.942508188590805, 0.032223827507809735, 0.9344909977264823, 0.9377285390083774, 0.03606648226955298, 0.26501596525829596, 0.7317254969963569, 0.9725094221237754, 0.018702104271611068, 0.15726901917213804, 0.15726901917213804, 0.6290760766885521, 0.25985444902532456, 0.25985444902532456, 0.5197088980506491, 0.2747353806380625, 0.2747353806380625, 0.2747353806380625, 0.24658425557296942, 0.24658425557296942, 0.49316851114593885, 0.018477610047209304, 0.9608357224548838, 0.13926958522559482, 0.4178087556767845, 0.27853917045118964, 0.610022122457924, 0.3860526475458359, 0.9190343494012262, 0.07379107914900357, 0.024838081222508367, 0.9438470864553179, 0.22097860622710097, 0.7765229527232707, 0.06788210182781695, 0.7467031201059865, 0.16970525456954239, 0.04020516449612834, 0.9247187834109519, 0.05069206753625598, 0.9124572156526075, 0.1385800312406971, 0.2771600624813942, 0.4157400937220913, 0.22446135762507285, 0.22446135762507285, 0.4489227152501457, 0.22446135762507285, 0.22446135762507285, 0.4489227152501457, 0.9691373715607526, 0.014045469153054385, 0.155684998732253, 0.155684998732253, 0.622739994929012, 0.24108639758040826, 0.24108639758040826, 0.4821727951608165, 0.8745239186432744, 0.1233302962189233, 0.6028442328297363, 0.3246084330621657, 0.0927452665891902, 0.8016095903185123, 0.19168924985877467, 0.26352529309426526, 0.26352529309426526, 0.5270505861885305, 0.6060248787897242, 0.321950716857041, 0.05681483238653665, 0.19662331599361862, 0.19662331599361862, 0.5898699479808559, 0.318781698839542, 0.159390849419771, 0.478172548259313, 0.9690341286188348, 0.027686689389109564, 0.8752869692614964, 0.12361195565897051, 0.011200719533765677, 0.9744625994376138, 0.9490540058565425, 0.02875921229868311, 0.9167329218116645, 0.06757967051816757, 0.011752986177072622, 0.46562762569131205, 0.28654007734849973, 0.2149050580113748, 0.7319654066019158, 0.2641440380346044, 0.5264702299073251, 0.030968837053372063, 0.4335637187472089, 0.48571727087198696, 0.16190575695732898, 0.32381151391465796, 0.1858505776033397, 0.1858505776033397, 0.5575517328100191, 0.08144504216015708, 0.08144504216015708, 0.8144504216015708, 0.19325562608666966, 0.19325562608666966, 0.5797668782600089, 0.0841077861115888, 0.1682155722231776, 0.7569700750042991, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.2023434311431249, 0.2023434311431249, 0.4046868622862498, 0.570707580359597, 0.14267689508989925, 0.14267689508989925, 0.14785418889746305, 0.14785418889746305, 0.5914167555898522, 0.5759425587464911, 0.14398563968662279, 0.14398563968662279, 0.20477528916901552, 0.40955057833803105, 0.40955057833803105, 0.18145861676609723, 0.27218792514914586, 0.5443758502982917, 0.2434916728759096, 0.1217458364379548, 0.7304750186277288, 0.27924925737237904, 0.13962462868618952, 0.6981231434309476, 0.9005442980125604, 0.0931597549668166, 0.010351083885201843, 0.9570379955140155, 0.020805173815522077, 0.21432990995902515, 0.21432990995902515, 0.4286598199180503, 0.21432990995902515, 0.21432990995902515, 0.4286598199180503, 0.2389909857765244, 0.2389909857765244, 0.4779819715530488, 0.02193354847093089, 0.9431425842500282, 0.21432990995902515, 0.21432990995902515, 0.4286598199180503, 0.057617473228379956, 0.9218795716540793, 0.019205824409459987, 0.019205824409459987, 0.2792178104989898, 0.2792178104989898, 0.2792178104989898, 0.03888099434219351, 0.9331438642126443, 0.0339372615306613, 0.9502433228585164, 0.19972585192452025, 0.19972585192452025, 0.3994517038490405, 0.6886933076654729, 0.30507905295707355, 0.003020584682743302, 0.19325562608666966, 0.19325562608666966, 0.5797668782600089, 0.9490736461177075, 0.02875980745811235, 0.9331582064068983, 0.06586999104048694, 0.9639668736369305, 0.030123964801154077, 0.21432990995902515, 0.21432990995902515, 0.4286598199180503, 0.4494901772196003, 0.26969410633176016, 0.26969410633176016, 0.06160263162246241, 0.9240394743369362, 0.017892492993930437, 0.9661946216722437, 0.36937197330613875, 0.18468598665306937, 0.5540579599592081, 0.9114162569877994, 0.08433032982805261, 0.0032434742241558697, 0.26352529309426526, 0.26352529309426526, 0.5270505861885305, 0.8466001662942543, 0.15240002993532287, 0.0006000001178556019, 0.25522058625801924, 0.25522058625801924, 0.5104411725160385, 0.5504884638441371, 0.4490017638058325, 0.3399935364384219, 0.2266623576256146, 0.4533247152512292, 0.9988765282365896, 0.0008655775807942717, 0.970159616025428, 0.020211658667196417, 0.017995170129797556, 0.9717391870090679, 0.19325562608666966, 0.19325562608666966, 0.5797668782600089, 0.03282200603497125, 0.9518381750141661, 0.2386788669122742, 0.2386788669122742, 0.4773577338245484, 0.4906642006931104, 0.505180893021309, 0.07745202734909981, 0.6196162187927985, 0.23235608204729943, 0.02397907545286111, 0.9591630181144444, 0.9455764418609105, 0.024245549791305398, 0.40120329771192303, 0.5934465445322195, 0.008358402035665064, 0.21603825179142835, 0.21603825179142835, 0.4320765035828567, 0.16703561126970534, 0.16703561126970534, 0.501106833809116, 0.19325562608666966, 0.19325562608666966, 0.5797668782600089, 0.17470848883387527, 0.17470848883387527, 0.5241254665016258, 0.10352296146039777, 0.5176148073019888, 0.3105688843811933, 0.01013641510056142, 0.9832322647544577, 0.7085772351212216, 0.2889048812726011, 0.39798166062907114, 0.6015078944835391, 0.04241428286938365, 0.9331142231264403, 0.21432990995902515, 0.21432990995902515, 0.4286598199180503, 0.032233457977475455, 0.9347702813467882, 0.07342074904377227, 0.6607867413939504, 0.2202622471313168, 0.02360984391346284, 0.9443937565385134, 0.2955784001741023, 0.14778920008705115, 0.5911568003482046, 0.034549442424380815, 0.932834945458282, 0.24108639758040826, 0.24108639758040826, 0.4821727951608165, 0.5943546311068384, 0.1485886577767096, 0.1485886577767096, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.6562731346197804, 0.3422499680544016, 0.0035283501861278514, 0.17470848883387527, 0.17470848883387527, 0.5241254665016258, 0.14785418889746305, 0.14785418889746305, 0.5914167555898522, 0.22518588492970854, 0.7631299433729012, 0.012510326940539364, 0.26456371956745117, 0.26456371956745117, 0.5291274391349023, 0.030767947831312856, 0.9538063827706985, 0.25957708651559563, 0.25957708651559563, 0.5191541730311913, 0.05570266566776049, 0.05570266566776049, 0.8912426506841679, 0.926844077908615, 0.06829377416168741, 0.5451359818665672, 0.45064574500969556, 0.340949137977687, 0.1704745689888435, 0.5114237069665305, 0.9103135373898793, 0.08618353016708917, 0.043591321898577035, 0.9154177598701178, 0.4282998213506716, 0.05353747766883395, 0.5353747766883394, 0.23885695237794635, 0.23885695237794635, 0.4777139047558927, 0.5064717290461812, 0.49117046834992195, 0.001530126069625925, 0.03571851492813058, 0.928681388131395, 0.24853693622943776, 0.24853693622943776, 0.24853693622943776, 0.9206571025160191, 0.052608977286629666, 0.026304488643314833, 0.2972911761539095, 0.14864558807695474, 0.44593676423086426, 0.21023877674131283, 0.21023877674131283, 0.42047755348262567, 0.16780145682278055, 0.16780145682278055, 0.6712058272911222, 0.2850613761235442, 0.2850613761235442, 0.2850613761235442, 0.8334350445172715, 0.1622121898724891, 0.48481393506489007, 0.350143397546865, 0.13467053751802502, 0.9905909446921337, 0.00658929674961508, 0.002196432249871693, 0.21432990995902515, 0.21432990995902515, 0.4286598199180503, 0.5671429138418911, 0.42965372260749324, 0.003437229780859946, 0.5498353392100614, 0.44866563679541016, 0.2138541288081219, 0.2138541288081219, 0.4277082576162438, 0.4729967775654225, 0.23649838878271126, 0.23649838878271126], \"Term\": [\"activate\", \"activate\", \"affect\", \"affect\", \"align\", \"align\", \"alignment\", \"alignment\", \"antismash\", \"antismash\", \"antismash\", \"app_name_size\", \"app_name_size\", \"app_name_size\", \"array\", \"array\", \"array\", \"available\", \"available\", \"bam\", \"bam\", \"barcode\", \"barcode\", \"basecalle\", \"basecalle\", \"batch\", \"batch\", \"batch\", \"bed\", \"bed\", \"bed\", \"benchmark\", \"benchmark\", \"benchmark\", \"benchmark\", \"binningsignal\", \"binningsignal\", \"binningsignal\", \"blue_nv\", \"blue_nv\", \"blue_nv\", \"bsstre\", \"bsstre\", \"bsstre\", \"canon\", \"canon\", \"canon\", \"capture\", \"capture\", \"capture\", \"cdirs_user\", \"cdirs_user\", \"cdirs_user\", \"check\", \"check\", \"checkpoint\", \"checkpoint\", \"chromosome\", \"chromosome\", \"cluster\", \"cluster\", \"cmap\", \"cmap\", \"cmap\", \"cmapx\", \"cmapx\", \"cmapx\", \"com\", \"com\", \"command\", \"command\", \"conda\", \"conda\", \"conda_forge\", \"conda_forge\", \"cookie\", \"cookie\", \"cookie\", \"core\", \"core\", \"core\", \"core\", \"create\", \"create\", \"create\", \"crispr_t\", \"crispr_t\", \"cut\", \"cut\", \"cut\", \"database\", \"database\", \"dataset\", \"dataset\", \"dataset\", \"datum\", \"datum\", \"datum\", \"def\", \"def\", \"def\", \"detect\", \"detect\", \"detect\", \"determine\", \"determine\", \"directive\", \"directive\", \"directory\", \"directory\", \"dot\", \"dot\", \"dot\", \"dot_json\", \"dot_json\", \"dot_json\", \"elide\", \"elide\", \"elide\", \"else\", \"else\", \"else\", \"entity\", \"entity\", \"entity\", \"env\", \"env\", \"environment\", \"environment\", \"ep\", \"ep\", \"ep\", \"error\", \"error\", \"execute\", \"execute\", \"expand\", \"expand\", \"experiment\", \"experiment\", \"experiment\", \"export\", \"export\", \"export\", \"export\", \"extension\", \"extension\", \"extension\", \"fail\", \"fail\", \"fast\", \"fast\", \"fastq\", \"fastq\", \"fastqc\", \"fastqc\", \"fastqc_premerge\", \"fastqc_premerge\", \"fastqc_premerge\", \"fi\", \"fi\", \"fi\", \"fibers_rn\", \"fibers_rn\", \"fibers_rn\", \"field\", \"field\", \"field\", \"file\", \"file\", \"filter\", \"filter\", \"finished_job\", \"finished_job\", \"finished_job\", \"fnmatch\", \"fnmatch\", \"fnmatch\", \"folder\", \"folder\", \"follow\", \"follow\", \"function\", \"function\", \"gbk_file\", \"gbk_file\", \"gbk_file\", \"gene\", \"gene\", \"gene\", \"gene_name\", \"gene_name\", \"gene_name\", \"gene_transcript\", \"gene_transcript\", \"gene_transcript\", \"get\", \"get\", \"glob_wildcard\", \"glob_wildcard\", \"graphviz\", \"graphviz\", \"graphviz\", \"group\", \"group\", \"group\", \"group\", \"group_sim\", \"group_sim\", \"group_sim\", \"gtf\", \"gtf\", \"gtf\", \"gtf_version\", \"gtf_version\", \"gtf_version\", \"gz\", \"gz\", \"head\", \"head\", \"head\", \"host\", \"host\", \"html\", \"html\", \"image\", \"image\", \"image\", \"information\", \"information\", \"information\", \"input\", \"input\", \"input\", \"inputdirectory\", \"inputdirectory\", \"inputdirectory\", \"instal\", \"instal\", \"install\", \"install\", \"item\", \"item\", \"job\", \"job\", \"join\", \"join\", \"lab_bereket_public\", \"lab_bereket_public\", \"lab_bereket_public\", \"lanenum\", \"lanenum\", \"lanenum\", \"lanenum_bsstre\", \"lanenum_bsstre\", \"lanenum_bsstre\", \"lanenum_proj\", \"lanenum_proj\", \"lanenum_proj\", \"lib_python\", \"lib_python\", \"license\", \"license\", \"license\", \"line\", \"line\", \"list\", \"list\", \"locally\", \"locally\", \"log\", \"log\", \"machine\", \"machine\", \"machine\", \"mamba\", \"mamba\", \"max\", \"max\", \"maximum\", \"maximum\", \"maximum\", \"megalodon\", \"megalodon\", \"megalodon\", \"megalodon_mapping\", \"megalodon_mapping\", \"megalodon_mapping\", \"merge\", \"merge\", \"merged_read\", \"merged_read\", \"merged_read\", \"merlin_test\", \"merlin_test\", \"merlin_test\", \"miss\", \"miss\", \"move\", \"move\", \"move\", \"name\", \"name\", \"neand_sqtl\", \"neand_sqtl\", \"neand_sqtl\", \"need\", \"need\", \"need\", \"ng_neb_\", \"ng_neb_\", \"ng_neb_\", \"organism\", \"organism\", \"organism\", \"os_path\", \"os_path\", \"output\", \"output\", \"package\", \"package\", \"pair\", \"pair\", \"param\", \"param\", \"param\", \"parse\", \"parse\", \"parse\", \"path\", \"path\", \"pattern\", \"pattern\", \"pattern\", \"pdf\", \"pdf\", \"pdf\", \"pear\", \"pear\", \"pear\", \"perl_pe\", \"perl_pe\", \"perl_pe\", \"perlexpr\", \"perlexpr\", \"perlexpr\", \"pertoldi_legend\", \"pertoldi_legend\", \"pertoldi_legend\", \"pic\", \"pic\", \"pic\", \"plain\", \"plain\", \"plain\", \"png\", \"png\", \"png\", \"po\", \"po\", \"po\", \"pool\", \"pool\", \"pool\", \"ppx_s_downsample\", \"ppx_s_downsample\", \"ppx_s_downsample\", \"prepare\", \"prepare\", \"prepare\", \"prjna_rawqc\", \"prjna_rawqc\", \"prjna_rawqc\", \"prjna_srr\", \"prjna_srr\", \"prjna_srr\", \"process\", \"process\", \"process\", \"processing\", \"processing\", \"prodenv\", \"prodenv\", \"prodenv\", \"prodenv_sim\", \"prodenv_sim\", \"prodenv_sim\", \"prodigal\", \"prodigal\", \"prodigal\", \"profile\", \"profile\", \"profit\", \"profit\", \"profit\", \"project\", \"project\", \"project\", \"project\", \"protein_file\", \"protein_file\", \"protein_file\", \"python_site\", \"python_site\", \"qc_fastqc\", \"qc_fastqc\", \"queue\", \"queue\", \"queue\", \"quot\", \"quot\", \"quot\", \"quotation\", \"quotation\", \"quotation\", \"range\", \"range\", \"read\", \"read\", \"ref\", \"ref\", \"reflector\", \"reflector\", \"reflector\", \"regular\", \"regular\", \"regular\", \"remote\", \"remote\", \"reproduce_error\", \"reproduce_error\", \"resources_raw_dataset\", \"resources_raw_dataset\", \"resources_raw_dataset\", \"result\", \"result\", \"result\", \"rmccoy_aseyedi\", \"rmccoy_aseyedi\", \"rmccoy_aseyedi\", \"rule\", \"rule\", \"rule\", \"rulegraph\", \"rulegraph\", \"rulegraph\", \"run\", \"run\", \"runtime\", \"runtime\", \"runtime\", \"sample\", \"sample\", \"sample_name\", \"sample_name\", \"sbatch\", \"sbatch\", \"scbe_pipe\", \"scbe_pipe\", \"scbe_pipe\", \"scheduler\", \"scheduler\", \"scratch_group\", \"scratch_group\", \"scratch_group\", \"script\", \"script\", \"select_job\", \"select_job\", \"select_job\", \"self\", \"self\", \"sequence\", \"sequence\", \"set\", \"set\", \"set\", \"sfs_nfs\", \"sfs_nfs\", \"sfs_nfs\", \"shadow\", \"shadow\", \"shadow\", \"sign\", \"sign\", \"sign\", \"sim\", \"sim\", \"sim\", \"sit\", \"sit\", \"sit\", \"site_package\", \"site_package\", \"snakefile\", \"snakefile\", \"snakemake\", \"snakemake\", \"source\", \"source\", \"srun\", \"srun\", \"srun\", \"status\", \"status\", \"steps_done\", \"steps_done\", \"steps_done\", \"submit\", \"submit\", \"table_sample\", \"table_sample\", \"table_sample\", \"tb_ssd_analyse\", \"tb_ssd_analyse\", \"test_data\", \"test_data\", \"test_data\", \"text_identity\", \"text_identity\", \"text_identity\", \"textiowrapper\", \"textiowrapper\", \"textiowrapper\", \"thread\", \"thread\", \"thread\", \"tier_raw\", \"tier_raw\", \"tier_raw\", \"tier_ver\", \"tier_ver\", \"tier_ver\", \"tmp\", \"tmp\", \"tmp\", \"tpdf\", \"tpdf\", \"tpdf\", \"traceback\", \"traceback\", \"tranche\", \"tranche\", \"tranche\", \"transcript_name\", \"transcript_name\", \"transcript_name\", \"trim\", \"trim\", \"try\", \"try\", \"tumor\", \"tumor\", \"tumor\", \"txt\", \"txt\", \"uds_alma_git\", \"uds_alma_git\", \"unit\", \"unit\", \"unit\", \"unmap\", \"unmap\", \"unmap\", \"use\", \"use\", \"use\", \"usr_local\", \"usr_local\", \"utf\", \"utf\", \"utf\", \"value\", \"value\", \"value\", \"values_tolist\", \"values_tolist\", \"values_tolist\", \"venv\", \"venv\", \"venv\", \"vm_type\", \"vm_type\", \"vm_type\", \"vml\", \"vml\", \"vml\", \"want\", \"want\", \"well\", \"well\", \"well\", \"wildcard\", \"wildcard\", \"wildcard\", \"wl\", \"wl\", \"wl\", \"work\", \"work\", \"work\", \"workflow\", \"workflow\", \"xdot\", \"xdot\", \"xdot\", \"zipfq\", \"zipfq\", \"zipfq\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [3, 1, 4, 5, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el3791881397142933819685381471345\", ldavis_el3791881397142933819685381471345_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el3791881397142933819685381471345\", ldavis_el3791881397142933819685381471345_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el3791881397142933819685381471345\", ldavis_el3791881397142933819685381471345_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "2     -0.184004 -0.087807       1        1  58.594199\n",
       "0     -0.155487  0.097143       2        1  33.712125\n",
       "3      0.114049 -0.025145       3        1   3.503349\n",
       "4      0.110683 -0.000348       4        1   2.140991\n",
       "1      0.114759  0.016156       5        1   2.049336, topic_info=              Term         Freq        Total Category  logprob  loglift\n",
       "116      snakemake  1763.000000  1763.000000  Default  30.0000  30.0000\n",
       "213         sample  1155.000000  1155.000000  Default  29.0000  29.0000\n",
       "64           input  1357.000000  1357.000000  Default  28.0000  28.0000\n",
       "318            log   484.000000   484.000000  Default  27.0000  27.0000\n",
       "151            job   426.000000   426.000000  Default  26.0000  26.0000\n",
       "...            ...          ...          ...      ...      ...      ...\n",
       "394   finished_job     3.132745    13.287000   Topic5  -5.9167   2.4428\n",
       "406     steps_done     3.056958    13.620128   Topic5  -5.9412   2.3935\n",
       "1011         group     4.560002    65.107696   Topic5  -5.5413   1.2289\n",
       "333        regular     2.516581    11.123714   Topic5  -6.1357   2.4015\n",
       "1486        export     2.073246     7.380465   Topic5  -6.3295   2.6179\n",
       "\n",
       "[280 rows x 6 columns], token_table=      Topic      Freq      Term\n",
       "term                           \n",
       "916       1  0.027100  activate\n",
       "916       2  0.948509  activate\n",
       "1456      1  0.972244    affect\n",
       "1456      2  0.030383    affect\n",
       "411       1  0.945597     align\n",
       "...     ...       ...       ...\n",
       "4297      2  0.213854      xdot\n",
       "4297      4  0.427708      xdot\n",
       "3398      1  0.472997     zipfq\n",
       "3398      2  0.236498     zipfq\n",
       "3398      4  0.236498     zipfq\n",
       "\n",
       "[609 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[3, 1, 4, 5, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=5, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.61,\n",
    "                                           eta=0.91)\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "392209b0-cdfe-4134-8a90-7ebd77bb2098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.055*\"snakemake\" + 0.024*\"file\" + 0.020*\"log\" + 0.019*\"error\" + '\n",
      "  '0.017*\"use\" + 0.016*\"job\" + 0.015*\"run\" + 0.013*\"rule\" + 0.009*\"script\" + '\n",
      "  '0.009*\"output\"'),\n",
      " (1,\n",
      "  '0.008*\"cdirs_user\" + 0.008*\"pertoldi_legend\" + 0.006*\"benchmark\" + '\n",
      "  '0.004*\"group\" + 0.003*\"lab_bereket_public\" + 0.003*\"po\" + 0.003*\"tier_ver\" '\n",
      "  '+ 0.003*\"runtime\" + 0.003*\"select_job\" + 0.003*\"sit\"'),\n",
      " (2,\n",
      "  '0.042*\"rule\" + 0.040*\"file\" + 0.039*\"input\" + 0.037*\"output\" + '\n",
      "  '0.035*\"sample\" + 0.021*\"snakemake\" + 0.014*\"wildcard\" + 0.013*\"fastq\" + '\n",
      "  '0.011*\"run\" + 0.010*\"read\"'),\n",
      " (3,\n",
      "  '0.015*\"field\" + 0.008*\"image\" + 0.008*\"transcript_name\" + 0.008*\"detect\" + '\n",
      "  '0.007*\"pattern\" + 0.007*\"gene_transcript\" + 0.005*\"perl_pe\" + 0.005*\"unit\" '\n",
      "  '+ 0.004*\"experiment\" + 0.004*\"gene\"'),\n",
      " (4,\n",
      "  '0.006*\"antismash\" + 0.003*\"merged_read\" + 0.003*\"ppx_s_downsample\" + '\n",
      "  '0.003*\"dot\" + 0.003*\"pear\" + 0.002*\"fastqc_premerge\" + 0.002*\"xdot\" + '\n",
      "  '0.002*\"plain\" + 0.002*\"extension\" + 0.002*\"move\"')]\n",
      "<gensim.interfaces.TransformedCorpus object at 0x7f1315fb8130>\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n",
    "print(doc_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id                                              Title  \\\n",
      "0  40510347  Can snakemake avoid ambiguity when two differe...   \n",
      "1  40936470  Snakemake complains it can't find the file it ...   \n",
      "2  41121347                               snakemake LSF issues   \n",
      "3  41465787                 Using regex in snakemake wildcards   \n",
      "4  41090178                                   Snakemake + tmux   \n",
      "\n",
      "                                                Body  RatingsSentiCR  \\\n",
      "0  Initial workflow\\n\\nI have a snakefile that ca...              -1   \n",
      "1  Consider the following simple snakefile, which...              -1   \n",
      "2  I have a pipeline which works just fine in the...               1   \n",
      "3  I'm using regex in snakemake wildcards but I'v...               1   \n",
      "4  My workflow often includes PBS job submissions...               1   \n",
      "\n",
      "  RatingsGPT35  RatingsGPTFineTuned  \\\n",
      "0            1                 -1.0   \n",
      "1           -1                 -1.0   \n",
      "2           -1                 -1.0   \n",
      "3           -1                 -1.0   \n",
      "4           -1                 -1.0   \n",
      "\n",
      "                                              merged  topic  \n",
      "0  Initial workflow\\n\\nI have a snakefile that ca...      2  \n",
      "1  Consider the following simple snakefile, which...      2  \n",
      "2  I have a pipeline which works just fine in the...      0  \n",
      "3  I'm using regex in snakemake wildcards but I'v...      2  \n",
      "4  My workflow often includes PBS job submissions...      0  \n",
      "topic:  0 total data:  159\n",
      "topic:  1 total data:  0\n",
      "topic:  2 total data:  269\n",
      "topic:  3 total data:  3\n",
      "topic:  4 total data:  2\n"
     ]
    }
   ],
   "source": [
    "num_topics = 5\n",
    "topic_distributions = [lda_model[doc] for doc in corpus]\n",
    "\n",
    "# Extract the dominant topic for each document\n",
    "df['topic'] = [max(topics, key=lambda x: x[1])[0] for topics in topic_distributions]\n",
    "\n",
    "# Display the DataFrame with assigned topics\n",
    "print(df.head())\n",
    "df.to_csv('../dataset/AssignedTopicSnakeMake.csv')\n",
    "for i in range(num_topics): \n",
    "    topic_df = df[df['topic'] == i]\n",
    "    print('topic: ', i, 'total data: ', len(topic_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
