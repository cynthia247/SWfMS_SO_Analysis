{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19a3956d",
   "metadata": {},
   "source": [
    "# Necessary Tools and Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57e1172e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install pandas\n",
    "# ! pip install matplotlib\n",
    "# ! pip install numpy\n",
    "# ! pip install seaborn\n",
    "# ! pip install unzip\n",
    "# ! pip install gensim\n",
    "# ! pip install nltk\n",
    "# ! pip install wordcloud\n",
    "# ! pip install spacy\n",
    "# ! pip install spacy_download\n",
    "# ! pip install pyLDAvis\n",
    "# ! pip install PyStemmer\n",
    "\n",
    "# ! python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "893b4ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/uji657/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/uji657/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/uji657/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.8/12.8 MB 84.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: jinja2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.5.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: setuptools in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (59.6.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.8.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.3 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.14.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/uji657/Downloads/Sentiment Analysis/SentiCR-master/SentiCR/.venv/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "## Importing PD and Others\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "## Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "## NLTK\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import nltk.stem\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['#', '`', '\"', '@'])\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import spacy\n",
    "spacy.cli.download('en_core_web_sm')\n",
    "\n",
    "\n",
    "\n",
    "## Visualization\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "def FindingPostsWithNegativeSentiments():\n",
    "    df = pd.read_csv('../dataset/SO_Workflow_Data.csv')\n",
    "    my_value = -1\n",
    "    data = df.loc[df[\"RatingsGPTFineTuned\"] == my_value]\n",
    "\n",
    "    df = data[data['Body'].str.contains('rapidminer', case=False)] \n",
    "    print(len(df))\n",
    "    df.to_csv('../dataset/rapidminer_posts.csv', index=False)\n",
    "\n",
    "FindingPostsWithNegativeSentiments()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c80025",
   "metadata": {},
   "source": [
    "# Import data and Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "093e46bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../dataset/rapidminer_posts.csv')\n",
    "# my_value = -1\n",
    "# new_df = df.loc[df[\"RatingsGPTFineTuned\"] == my_value]\n",
    "df[\"merged\"] = df[[\"Title\",\"Body\"]].apply(\"-\".join, axis=1)\n",
    "#new_df.head()\n",
    "# new_df.to_csv('Dataset/ConcatenatedDatasetSO.csv')\n",
    "\n",
    "data = df.merged.values.tolist()\n",
    "print(len(df))\n",
    "#data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed84875d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RapidMiner error: Regular Attributes must be of type binomial. Market Basket '\n",
      " 'Analysis-I am attempting to learn to use RapidMiner, and my boss wants me to '\n",
      " 'perform a market basket analysis on a set of data. But when I use the given '\n",
      " 'template, I get the following error: Regular Attributes must be of type '\n",
      " 'binomial. This is given withing the FP-Growth operator. I have a customerID '\n",
      " '(only numbers), a productName(Letters) and a Product Quantity (numbers) '\n",
      " 'column. As I am a newbie with RM, I have no idea what is wrong. Any input '\n",
      " 'would be greatly appreciated. Thank you in advance. ',\n",
      " 'rapidminer some concepts-In rapidminer what is the meaning of: - training '\n",
      " 'cycles - learning rate - momentum Im trying to work with rapidminer but i '\n",
      " 'cant understand this notions. Any help would be apreciated, as newbly as '\n",
      " 'possible. ']\n"
     ]
    }
   ],
   "source": [
    "# Remove Emails\n",
    "data = [re.sub('<[^<>]*>', '', sent) for sent in data]\n",
    "# Remove new line characters\n",
    "data = [re.sub('\\s+', ' ', sent) for sent in data]\n",
    "# Remove distracting single quotes\n",
    "data = [re.sub(\"\\'\", \"\", sent) for sent in data]\n",
    "\n",
    "pprint(data[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d98f4b6",
   "metadata": {},
   "source": [
    "# Tokenize words and Clean-up text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7b3a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['rapidminer', 'error', 'regular', 'attributes', 'must', 'be', 'of', 'type', 'binomial', 'market', 'basket', 'analysis', 'am', 'attempting', 'to', 'learn', 'to', 'use', 'rapidminer', 'and', 'my', 'boss', 'wants', 'me', 'to', 'perform', 'market', 'basket', 'analysis', 'on', 'set', 'of', 'data', 'but', 'when', 'use', 'the', 'given', 'template', 'get', 'the', 'following', 'error', 'regular', 'attributes', 'must', 'be', 'of', 'type', 'binomial', 'this', 'is', 'given', 'withing', 'the', 'fp', 'growth', 'operator', 'have', 'customerid', 'only', 'numbers', 'productname', 'letters', 'and', 'product', 'quantity', 'numbers', 'column', 'as', 'am', 'newbie', 'with', 'rm', 'have', 'no', 'idea', 'what', 'is', 'wrong', 'any', 'input', 'would', 'be', 'greatly', 'appreciated', 'thank', 'you', 'in', 'advance']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38592eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=50) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=50)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "#print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d485455",
   "metadata": {},
   "source": [
    "# Remove Stopwords, Make Bigrams and Lemmatize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c49abe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1408ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['rapidminer', 'error', 'regular', 'attribute', 'type', 'binomial', 'market', 'basket', 'analysis', 'attempt', 'learn', 'use', 'rapidminer', 'boss', 'want', 'perform', 'market', 'basket', 'analysis', 'set', 'data', 'use', 'give', 'template', 'get', 'follow', 'error', 'regular', 'attribute', 'type', 'binomial', 'give', 'withe', 'fp_growth', 'operator', 'customerid', 'number', 'productname', 'letter', 'product', 'quantity', 'number', 'wrong', 'input', 'greatly', 'appreciate', 'advance']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "# python3 -m spacy download en\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98003715",
   "metadata": {},
   "source": [
    "# Create the Dictionary and Corpus needed for Topic Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfd3247d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 2), (2, 1), (3, 1), (4, 2), (5, 2), (6, 2), (7, 1), (8, 1), (9, 1), (10, 2), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 1), (17, 1), (18, 1), (19, 2), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 2), (27, 2), (28, 1), (29, 1), (30, 2), (31, 2), (32, 1), (33, 1), (34, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be414a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('advance', 1),\n",
       "  ('analysis', 2),\n",
       "  ('appreciate', 1),\n",
       "  ('attempt', 1),\n",
       "  ('attribute', 2),\n",
       "  ('basket', 2),\n",
       "  ('binomial', 2),\n",
       "  ('boss', 1),\n",
       "  ('customerid', 1),\n",
       "  ('data', 1),\n",
       "  ('error', 2),\n",
       "  ('follow', 1),\n",
       "  ('fp_growth', 1),\n",
       "  ('get', 1),\n",
       "  ('give', 2),\n",
       "  ('greatly', 1),\n",
       "  ('input', 1),\n",
       "  ('learn', 1),\n",
       "  ('letter', 1),\n",
       "  ('market', 2),\n",
       "  ('number', 2),\n",
       "  ('operator', 1),\n",
       "  ('perform', 1),\n",
       "  ('product', 1),\n",
       "  ('productname', 1),\n",
       "  ('quantity', 1),\n",
       "  ('rapidminer', 2),\n",
       "  ('regular', 2),\n",
       "  ('set', 1),\n",
       "  ('template', 1),\n",
       "  ('type', 2),\n",
       "  ('use', 2),\n",
       "  ('want', 1),\n",
       "  ('withe', 1),\n",
       "  ('wrong', 1)]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a5fd366",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supporting function\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=k, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc885ff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 540/540 [06:43<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "\n",
    "grid = {}\n",
    "grid['Validation_Set'] = {}\n",
    "\n",
    "# Topics range\n",
    "min_topics = 2\n",
    "max_topics = 11\n",
    "step_size = 1\n",
    "topics_range = range(min_topics, max_topics, step_size)\n",
    "\n",
    "# Alpha parameter\n",
    "alpha = list(np.arange(0.01, 1, 0.3))\n",
    "alpha.append('symmetric')\n",
    "alpha.append('asymmetric')\n",
    "\n",
    "# Beta parameter\n",
    "beta = list(np.arange(0.01, 1, 0.3))\n",
    "beta.append('symmetric')\n",
    "\n",
    "# Validation sets\n",
    "num_of_docs = len(corpus)\n",
    "corpus_sets = [gensim.utils.ClippedCorpus(corpus, int(num_of_docs*0.75)), \n",
    "               corpus]\n",
    "\n",
    "corpus_title = ['75% Corpus', '100% Corpus']\n",
    "\n",
    "model_results = {'Validation_Set': [],\n",
    "                 'Topics': [],\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run\n",
    "if 1 == 1:\n",
    "    pbar = tqdm.tqdm(total=(len(beta)*len(alpha)*len(topics_range)*len(corpus_title)))\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "    for i in range(len(corpus_sets)):\n",
    "        # iterate through number of topics\n",
    "        for k in topics_range:\n",
    "            # iterate through alpha values\n",
    "            for a in alpha:\n",
    "                # iterare through beta values\n",
    "                for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "                    cv = compute_coherence_values(corpus=corpus_sets[i], dictionary=id2word, \n",
    "                                                  k=k, a=a, b=b)\n",
    "                    # Save the model results\n",
    "                    model_results['Validation_Set'].append(corpus_title[i])\n",
    "                    model_results['Topics'].append(k)\n",
    "                    model_results['Alpha'].append(a)\n",
    "                    model_results['Beta'].append(b)\n",
    "                    model_results['Coherence'].append(cv)\n",
    "                    \n",
    "                    pbar.update(1)\n",
    "    pd.DataFrame(model_results).to_csv('../dataset/lda_tuning_results.csv', index=False)\n",
    "    pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41468242",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Validation_Set</th>\n",
       "      <th>Topics</th>\n",
       "      <th>Alpha</th>\n",
       "      <th>Beta</th>\n",
       "      <th>Coherence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>528</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>10</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.545106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>4</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.530929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>10</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.530743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>6</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.524255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>6</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.9099999999999999</td>\n",
       "      <td>0.520599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.333287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>0.01</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.333239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.325645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.325645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>100% Corpus</td>\n",
       "      <td>3</td>\n",
       "      <td>asymmetric</td>\n",
       "      <td>symmetric</td>\n",
       "      <td>0.325645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>268 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Validation_Set  Topics               Alpha                Beta  Coherence\n",
       "528    100% Corpus      10  0.9099999999999999  0.9099999999999999   0.545106\n",
       "358    100% Corpus       4          asymmetric  0.9099999999999999   0.530929\n",
       "523    100% Corpus      10                0.61  0.9099999999999999   0.530743\n",
       "417    100% Corpus       6          asymmetric                0.61   0.524255\n",
       "418    100% Corpus       6          asymmetric  0.9099999999999999   0.520599\n",
       "..             ...     ...                 ...                 ...        ...\n",
       "301    100% Corpus       3                0.01                0.31   0.333287\n",
       "304    100% Corpus       3                0.01           symmetric   0.333239\n",
       "326    100% Corpus       3          asymmetric                0.31   0.325645\n",
       "327    100% Corpus       3          asymmetric                0.61   0.325645\n",
       "329    100% Corpus       3          asymmetric           symmetric   0.325645\n",
       "\n",
       "[268 rows x 5 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('../dataset/lda_tuning_results.csv')\n",
    "results = results.loc[272:]\n",
    "results.sort_values(by=['Coherence'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a9f15c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -6.655919755909586\n",
      "\n",
      "Coherence Score:  0.5174818514521227\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el3800921399902444440803934118340\" style=\"background-color:white;\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el3800921399902444440803934118340_data = {\"mdsDat\": {\"x\": [-0.10839004944097202, -0.018618965313587036, 0.0068901105240768085, 0.004303350276052944, 0.014476696972222118, 0.015609540409155673, 0.01695624960488556, 0.021411485736643233, 0.023978439322955566, 0.023383141908567183], \"y\": [-0.019272980196776816, 0.046129349115816225, 0.03162665004194413, 0.027589133090876867, -0.018528313036588796, -0.029455087494998276, -0.006377676181470815, -0.008989306894683444, -0.011463126888931262, -0.011258641555187788], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [34.95584273768152, 18.792967828456653, 12.975637330526599, 12.301425257463663, 6.225812366734976, 5.066686821959218, 3.66356818441068, 2.1049882652414404, 2.0868821078516344, 1.8261890996736165]}, \"tinfo\": {\"Term\": [\"column\", \"name\", \"use\", \"java\", \"com\", \"datum\", \"rapidminer\", \"operator\", \"spark\", \"run\", \"text\", \"process\", \"class\", \"false\", \"library\", \"m\", \"load\", \"true\", \"get\", \"resource\", \"module\", \"try\", \"value\", \"memory\", \"hadoop\", \"info\", \"project\", \"document\", \"extension\", \"type\", \"java\", \"run\", \"com\", \"operator\", \"application\", \"unknown_source\", \"process\", \"execute\", \"main\", \"fail\", \"repository\", \"studio\", \"executionunit\", \"catch\", \"exampleset\", \"portspacing_port\", \"compatibility_expande\", \"to_port\", \"radoop\", \"interpreter\", \"user\", \"exit\", \"activated_true\", \"launcher\", \"true_height\", \"from_port\", \"transport\", \"sun_reflect\", \"dataframe\", \"space\", \"import\", \"rapidminer\", \"class\", \"new\", \"info\", \"value\", \"error\", \"source\", \"exception\", \"model\", \"file\", \"try\", \"name\", \"datum\", \"problem\", \"example\", \"output\", \"code\", \"result\", \"find\", \"distance\", \"correlation\", \"near\", \"jar\", \"precision\", \"connect\", \"replace\", \"project\", \"matrix\", \"weight\", \"seperate\", \"eclipse\", \"oracle\", \"tutorial\", \"develop\", \"negative\", \"show\", \"validation\", \"feature\", \"extension\", \"train\", \"ask\", \"driver\", \"object\", \"split\", \"extend\", \"exponent\", \"folder\", \"document\", \"reduce\", \"use\", \"web\", \"test\", \"file\", \"rapidminer\", \"apply\", \"m\", \"number\", \"need\", \"result\", \"help\", \"thank\", \"get\", \"try\", \"work\", \"set\", \"import\", \"text\", \"error\", \"process\", \"find\", \"operator\", \"datum\", \"column\", \"kickstarter\", \"store\", \"site\", \"link\", \"button\", \"match\", \"url\", \"discard\", \"www\", \"quote\", \"testing\", \"tumblr\", \"datum\", \"boolean\", \"meta\", \"correct\", \"different\", \"page\", \"base\", \"text\", \"review\", \"order\", \"data\", \"word\", \"precede\", \"storytelle\", \"skip\", \"tabletop\", \"ref\", \"click\", \"even\", \"label\", \"crawl\", \"first\", \"project\", \"follow\", \"use\", \"see\", \"rule\", \"model\", \"set\", \"look\", \"m\", \"create\", \"get\", \"value\", \"try\", \"rapidminer\", \"work\", \"com\", \"error\", \"also\", \"false_conf\", \"gt\", \"analysis\", \"analyze\", \"false\", \"filter\", \"write\", \"table\", \"fp_growth\", \"quite\", \"support\", \"query\", \"parameter\", \"dataset\", \"condition\", \"strike\", \"distinct\", \"binomial\", \"perform\", \"tokenize\", \"select\", \"contain\", \"stop\", \"ram\", \"word\", \"association\", \"initialization\", \"study\", \"utility\", \"confidence\", \"type\", \"different\", \"use\", \"regular\", \"want\", \"give\", \"document\", \"problem\", \"attribute\", \"need\", \"work\", \"ve\", \"m\", \"try\", \"rapidminer\", \"text\", \"result\", \"value\", \"error\", \"operator\", \"datum\", \"follow\", \"help\", \"process\", \"library\", \"jri\", \"program_file\", \"dependent\", \"rosuda\", \"r_home\", \"java_home\", \"native\", \"plugininitr\", \"path\", \"recent\", \"rjava\", \"transaction\", \"environment\", \"let\", \"stacktrace\", \"initplugin\", \"mingw\", \"anymore\", \"bit\", \"variable\", \"load\", \"property\", \"dependency\", \"console\", \"system\", \"delay\", \"warn\", \"initialized\", \"post\", \"window\", \"module\", \"help\", \"extension\", \"info\", \"check\", \"try\", \"message\", \"find\", \"rapidminer\", \"version\", \"com\", \"yarn\", \"localhost\", \"address\", \"vcore\", \"share_hadoop\", \"memory\", \"scheduler\", \"spark\", \"name\", \"mapreduce\", \"tweets_hadoop\", \"executor\", \"hadoop\", \"allocation\", \"common\", \"final\", \"hdfs\", \"dir\", \"yarn_resourcemanag\", \"eventlog\", \"submit\", \"cpu\", \"sparkrm\", \"resource\", \"service\", \"enter\", \"image\", \"core\", \"occur\", \"shufflehandl\", \"spark_job\", \"value\", \"description\", \"error\", \"m\", \"run\", \"process\", \"rapidminer\", \"information\", \"work\", \"driver\", \"configure\", \"start\", \"firebase\", \"detail\", \"webservice\", \"span\", \"neural\", \"trouble\", \"stack\", \"send\", \"service\", \"block\", \"post\", \"net\", \"underline\", \"bunch\", \"pull\", \"back\", \"anonymous\", \"locally\", \"response\", \"api\", \"route\", \"invoke\", \"publish\", \"js\", \"authentication\", \"field\", \"neuralnet\", \"adaboost\", \"usefull\", \"crossvalidation\", \"aply\", \"thing\", \"module\", \"class\", \"get\", \"function\", \"number\", \"part\", \"try\", \"m\", \"error\", \"use\", \"server\", \"text\", \"code\", \"work\", \"attribute\", \"web\", \"xml\", \"result\", \"rapidminer\", \"xpath\", \"website\", \"reviewcentre\", \"extract\", \"day\", \"appear\", \"title\", \"unfortunately\", \"struggle\", \"incorrect\", \"reviewtitle\", \"direction\", \"selling\", \"badly\", \"right\", \"many\", \"come\", \"spend\", \"specific\", \"copy\", \"review\", \"head\", \"crawling\", \"dont_know\", \"point\", \"html\", \"car\", \"s\", \"go\", \"retrieve\", \"wrong\", \"example\", \"appreciate\", \"know\", \"work\", \"datum\", \"try\", \"rapidminer\", \"good\", \"include\", \"way\", \"learn\", \"javascript\", \"extract\", \"svbutton\", \"satbutton\", \"zoomlocke\", \"showcontrol\", \"onlygoogle\", \"draggable\", \"maxzoom\", \"mapbutton\", \"lateload\", \"embed\", \"jumptogoogleid\", \"areasize\", \"showarea\", \"multimap\", \"minzoom\", \"sit\", \"lateloadid\", \"latitude\", \"bizmapwaittime\", \"hitcode\", \"lazyload\", \"false\", \"true\", \"least\", \"button\", \"head\", \"ready\", \"cluster\", \"script\", \"text\", \"type\", \"like\", \"map\", \"suggestion\", \"function\", \"rapidminer\", \"work\", \"document\", \"export\", \"view\", \"unanswered\", \"decision\", \"tree\", \"screenshot\", \"propose\", \"gigantic\", \"graph\", \"chance\", \"pdf\", \"matter\", \"inform\", \"suspect\", \"engine\", \"advise\", \"sentence\", \"current\", \"bug\", \"remain\", \"research\", \"question\", \"original\", \"issue\", \"notice\", \"forum\", \"paragraph\", \"repeat\", \"address\", \"whole\", \"good\", \"instead\", \"know\", \"cause\", \"space\"], \"Freq\": [23.0, 16.0, 45.0, 42.0, 61.0, 37.0, 155.0, 69.0, 10.0, 36.0, 16.0, 61.0, 17.0, 7.0, 6.0, 22.0, 8.0, 7.0, 17.0, 7.0, 7.0, 29.0, 28.0, 5.0, 6.0, 14.0, 11.0, 14.0, 10.0, 9.0, 38.95874410682494, 31.84887426023317, 52.71571784310466, 57.72640608055873, 17.139647148074623, 8.652145732240335, 50.2895762122346, 9.700873056624115, 7.84045950270394, 12.207245923786692, 8.65364428817442, 6.7121220906769015, 6.1130093628943545, 6.0546636354000265, 6.0098578342915445, 6.348909828271465, 5.9273235199355225, 5.437850492296916, 5.557310190481034, 4.930741578233298, 12.876926801812196, 4.908913170544122, 5.273954525384593, 4.891918859181347, 4.806406002423501, 4.802566765256562, 4.307800046999502, 4.3078353289855595, 4.298649013984424, 5.4256234271817, 15.764086074329624, 93.61444381019375, 11.406119221287684, 8.776456239270564, 9.298484791069503, 16.8872286781465, 18.343648636146494, 7.295505087754804, 6.197411301328079, 8.064182576288307, 11.712662114773135, 12.079014473937603, 8.608310649985066, 13.30468374381476, 8.503352312306834, 7.583436733595443, 6.759502084057533, 7.234759256735315, 7.327205487989924, 6.981154662144372, 4.0524556894182755, 3.6007718313340233, 3.1110063473766676, 3.5900317750716355, 2.6580962879441836, 3.6727882613011, 2.5515310796684694, 6.049276290700568, 2.22800310765995, 2.225059525591754, 2.224664186097433, 2.2144534954079336, 2.2115663191009225, 2.2095194888023575, 2.1674410405415916, 2.102010856733377, 4.362552351523457, 3.2867716908884494, 2.027433455458707, 5.209474373225015, 2.201912947281889, 2.00772500795946, 2.1942507487492784, 2.663686198710792, 3.922022108755943, 1.758701683777003, 1.7563818096610222, 1.7532662648961173, 6.7499406694803605, 1.7451021549221684, 18.831202139665233, 4.506317159300476, 5.62865303872001, 9.539344328219212, 43.891177678769516, 4.609392448290149, 8.095473147575664, 3.974914489851268, 4.644269178679303, 5.589933229079874, 4.865596400579526, 3.9275329017070844, 5.021868312358701, 6.251701093445554, 4.717362060186156, 4.4896315364763995, 5.1587551114333845, 4.033727479206873, 5.219371837231829, 5.6557038441193095, 3.8771435886600836, 5.164162577016692, 4.177896361883706, 17.58893419683662, 3.850088838753054, 4.021892064842538, 3.242180256134178, 3.079794592730297, 2.263693080549734, 2.3097023116383277, 1.906873262331537, 1.905122095414591, 1.9055944383115946, 2.4423333020564413, 1.9173649269058741, 1.5173804468077063, 14.761601626641342, 1.4419146650287904, 1.6531780819085395, 1.57771385105486, 2.631943562410408, 2.3526967163923445, 1.4908901267945527, 5.80318587683089, 1.5722912994532525, 1.4696584772830248, 3.3548653140617573, 3.6267821427624414, 1.1295509985999372, 1.1294645775992633, 1.1288720379964374, 1.1288728996215687, 1.1288973697752989, 1.4762538730134194, 1.5180930107913286, 3.903123933487662, 1.9540356924959228, 1.8689203985460467, 3.5582601979170363, 4.088113470587252, 8.413393049727828, 2.37554873812588, 2.455102586502976, 3.1980174877020575, 3.655031384318723, 2.194927295792158, 3.9212594192522143, 2.3552167975765026, 3.116474319221712, 3.7155191917894137, 3.5215491082708406, 5.7933564573325045, 2.905247607572558, 3.8421718823962023, 2.7916845536361388, 2.327664093776401, 3.2233584228181855, 3.232580391568128, 3.9537361259674206, 2.1883375041251254, 3.8792294539124095, 4.211032452208554, 3.4206724163917945, 3.127597177804566, 2.6203271423027052, 1.7981166142886793, 1.745214946083869, 1.8141689630603473, 3.064987511990844, 3.348514039738067, 1.4399110580339365, 1.4397339638211224, 1.4231848037015136, 1.4140466442976722, 1.5678263386464915, 1.5313267966207613, 1.8764826005404718, 1.4922667402062515, 1.418836029853818, 1.233403113844608, 3.472031371818372, 1.942782164777277, 1.068291758755831, 1.0682820381786515, 1.0628976552765008, 1.0518880805518227, 3.016848273119749, 2.2118562363968266, 11.237324417198952, 1.429875828221827, 2.682340013688927, 2.279454763812678, 3.7609213709739815, 3.893641720763005, 3.023351094196186, 3.132425445669429, 3.3050677975065494, 1.9332509346390896, 3.4459727099095647, 3.8963033618286596, 8.151062400982006, 2.938408279784557, 3.0092511927836907, 3.426776285376264, 3.5150423935859254, 4.135501116959104, 3.27547966754088, 2.6124490637691924, 2.470783332409465, 2.7062047658340047, 2.616192682347788, 1.662092414165358, 1.9243721533781313, 1.419864434937228, 1.1805688873197075, 1.5079617383319912, 1.2710640773985988, 1.1191230100328393, 0.9399583509147531, 1.1961083935885162, 0.8743628670965122, 0.8602107798325542, 0.8928697798411895, 1.1327638689471553, 0.6994416595974331, 0.6994323991130145, 0.6991738496953644, 0.6989004173563275, 0.6988914049205988, 1.2171277088291046, 1.0106117955663503, 1.9306621720536377, 1.3361308867760164, 0.7246503518426558, 0.7068788207802872, 1.1962886423030914, 0.7061479866572912, 0.6984259002127734, 0.5903312421793261, 0.8580782225635969, 1.4315834126031088, 1.1990509951954067, 1.8159771910642537, 1.4225815602851062, 1.6410188589446038, 1.2830296154621235, 1.754365534569714, 0.9921644971901173, 1.2851997934490311, 2.4124259753967907, 0.9659933760285382, 1.0167465357620529, 1.625398232526365, 1.631641973682981, 1.224321267860444, 1.0087158488172505, 1.0082585531506876, 1.7865680394119692, 1.2179122650562297, 2.863502025725154, 4.686799870049519, 0.8024699855039794, 0.8024271897353016, 0.8023428093989464, 1.565817909542055, 1.0103879117981833, 0.5973850583495088, 0.5973769836761734, 0.5973325056838841, 0.5972770595936475, 0.5971864213854574, 0.5971985333954605, 0.5971131437249384, 0.5969576389742871, 0.5969650407581779, 1.421825086087119, 0.60088415075047, 0.6023389377297355, 0.6062480216693028, 0.6055017872752207, 0.6015963369386543, 0.3920736702524518, 0.8019170722473362, 1.748708183966281, 0.6574025576059874, 1.0574719376175366, 0.8566075749265473, 0.8257490668631713, 0.7813957609879693, 0.8182681511736795, 0.6257377934100695, 0.6701040187626083, 0.6094419587071295, 0.6178900183953716, 0.6143782756728515, 1.069525581519417, 1.1019334395179037, 0.757067131725998, 0.9341909542653407, 0.5976954763095024, 0.6162217381668496, 0.7576595015181126, 0.44490167995213686, 0.4435564288324513, 0.7630007551861643, 0.5977746860032652, 0.5922662551191391, 0.2931735410380392, 0.29313953147050836, 0.29307243677290457, 0.2905270225598238, 0.29052765506966344, 0.290445769372733, 0.2904440907889278, 0.29044593966384363, 0.2904257966581816, 0.2904253830940557, 0.2904426798054394, 0.2904234855645368, 0.2903991582630126, 0.2878717949076628, 0.2878275192188887, 0.287804651555456, 0.28771780308901457, 0.2876588823647229, 0.2876870777071895, 0.4501376450591918, 0.7306689929868452, 1.2472855629936175, 1.095467437391182, 0.45387446453711905, 0.6194735685615903, 0.45461153311869945, 1.031382221604377, 0.8818567008975825, 0.916764529709903, 0.9870505800368157, 0.4261579806737663, 0.5842591184408588, 0.5310782749800582, 0.5693075102694785, 0.43554437803926305, 0.3882044710198214, 0.3054758817461319, 0.36931967339261046, 0.407603499146651, 0.3672632456917076, 0.27140927799362696, 0.27130072626980506, 0.3591947467408872, 0.2668204726218852, 0.2631994074055757, 0.17734333861895304, 0.17730984777034664, 0.17727505698479515, 0.1772499807817902, 0.17725305590144522, 0.17725534826336986, 0.1771990316402333, 0.1771786100501607, 0.27238314043273604, 0.2679338895820653, 0.17750619416031915, 0.17736007006543963, 0.17688051913305713, 0.17721837693842665, 0.256398696421617, 0.17799410382703665, 0.17275361071131476, 0.2700873399652038, 0.17702900547894437, 0.17774610940467656, 0.18033917609813216, 0.17834793827679563, 0.17431525431684614, 0.2537294925610666, 0.25630213766444965, 0.2419034769481538, 0.19024431821854174, 0.18695199727116962, 0.22320563122035186, 0.24056166246450594, 0.22788337743920656, 0.24296246429044024, 0.1787337260153335, 0.17874513191369026, 0.178761206402796, 0.17817929591935144, 0.4681068632845588, 0.3759732909215662, 0.1815128664117503, 0.1815110094952592, 0.18140728546588625, 0.18140427836977752, 0.1813877185548008, 0.18138260510565737, 0.1813866515206977, 0.18136307976732918, 0.18136851194094497, 0.18135985094984836, 0.1813562756927237, 0.18135228470802636, 0.18136826250440138, 0.18134280611937026, 0.18134054733289226, 0.18133702750611058, 0.18133255150591188, 0.18132373808137198, 0.18131439806857338, 0.18130236968413843, 0.18130126107727806, 0.5072526029792079, 0.47045810757470785, 0.180887736860776, 0.27709769822208963, 0.18296956196868475, 0.18326881653305463, 0.18127569383156086, 0.37216079192876944, 0.47147702814006975, 0.2950710423761074, 0.1862748456076928, 0.18408799385735017, 0.18713105040112454, 0.1870480988927977, 0.20094380686577656, 0.1856882955754592, 0.18395451759136217, 0.43681281044613507, 0.24391471239147314, 0.15875791908848358, 0.15874858168489603, 0.15872431656206656, 0.15869815970552326, 0.15870331346724367, 0.15869077466814038, 0.15868923460287335, 0.15866677632827056, 0.1586624229154291, 0.15865930640540052, 0.15865078147719008, 0.15863843670205746, 0.15789591909287673, 0.16036742068401724, 0.21124599909220892, 0.15932375361939083, 0.1595776703644813, 0.1588459817181625, 0.15884536326675605, 0.24507572757884852, 0.16000552959925984, 0.2527212421423257, 0.16186751701310045, 0.15799761190649383, 0.1386849145483898, 0.13737749614866057, 0.15657450671426432, 0.16840691304639813, 0.18165684638160526, 0.16110759787905202, 0.1618082305635686, 0.15923387201498707, 0.15963636261560304], \"Total\": [23.0, 16.0, 45.0, 42.0, 61.0, 37.0, 155.0, 69.0, 10.0, 36.0, 16.0, 61.0, 17.0, 7.0, 6.0, 22.0, 8.0, 7.0, 17.0, 7.0, 7.0, 29.0, 28.0, 5.0, 6.0, 14.0, 11.0, 14.0, 10.0, 9.0, 42.41152467162433, 36.377119636822684, 61.729859997041544, 69.34063805510296, 20.827634205328984, 10.629111362873099, 61.96050443010655, 12.196104100410667, 9.937136969104753, 15.533814527907332, 11.06749192294133, 8.701750128131637, 8.112770624008743, 8.094219981345299, 8.066994384538297, 8.570853362975804, 8.025519642432535, 7.44944670437851, 7.711548523071866, 6.881273551010585, 17.981736361321214, 6.863054930936034, 7.388060559004682, 6.858262698501112, 6.824904592049775, 6.820461443756407, 6.255285086897005, 6.255688653769484, 6.250029052973393, 7.9587588960589715, 23.64462496387762, 155.68453162146287, 17.44141856987286, 13.378284263112691, 14.296006853331798, 28.836367381236126, 32.90448712803304, 11.421930540981204, 9.288901835751936, 13.819533311453034, 24.962669612945966, 29.267476962213447, 16.731701526428047, 37.00872761355509, 17.050531119611566, 13.930665098459022, 10.881108392236925, 13.44124169000026, 17.697810412619308, 15.369979978382041, 6.172967293689954, 5.715434734774525, 5.240547321935725, 6.414191938613966, 4.781487217088024, 6.668149518027953, 4.73161061434823, 11.548174510820036, 4.334083903900323, 4.333042446623225, 4.332759602021015, 4.330573218393641, 4.326387597416505, 4.328808158719171, 4.311659109312303, 4.264516238739016, 8.910856908561561, 6.803738237776254, 4.268393474447447, 10.99706360074091, 4.703025616512518, 4.303891537121249, 4.732954932877854, 5.782025894747616, 8.625566957912485, 3.8698286835095623, 3.8653086670443275, 3.868330923777528, 14.90457937632257, 3.865769382293442, 45.18365708360675, 10.772603409276314, 13.76658326643548, 24.962669612945966, 155.68453162146287, 11.444531421707087, 22.461966062633458, 9.680969179696142, 12.91509298727539, 17.697810412619308, 15.004195141776366, 11.1094702901565, 17.837136995565672, 29.267476962213447, 18.333292061848407, 17.376138578237143, 23.64462496387762, 16.167029764645353, 32.90448712803304, 61.96050443010655, 15.369979978382041, 69.34063805510296, 37.00872761355509, 23.630016125870196, 6.033705885584293, 6.883783736772794, 6.107226415208443, 5.864431584240115, 4.678398500936252, 4.835612138309848, 4.072285137255479, 4.071085714066261, 4.072534164535141, 5.324615457509963, 4.520782096299498, 3.6792349697101634, 37.00872761355509, 3.6628844970211523, 4.203842251150576, 4.190988299550919, 7.179108792217248, 6.435985401952693, 4.121392242682911, 16.167029764645353, 4.396914783022031, 4.121127792965113, 9.526543675867305, 10.381341915700721, 3.2875424634117514, 3.2876727257008627, 3.2870829580569825, 3.2871327843482607, 3.287391747021747, 4.301286913356172, 4.480407075498711, 12.177774163576773, 5.8844164711910185, 5.64966132074084, 11.548174510820036, 14.992536311065384, 45.18365708360675, 8.331392974855738, 8.85304122580643, 13.819533311453034, 17.376138578237143, 7.4758833799839, 22.461966062633458, 8.929042255523488, 17.837136995565672, 28.836367381236126, 29.267476962213447, 155.68453162146287, 18.333292061848407, 61.729859997041544, 32.90448712803304, 8.936154981825904, 5.445049655799895, 6.065919724597051, 7.576643928103089, 4.379287721323687, 7.9634301119150965, 8.73833358454769, 7.212507935207696, 6.781950512046057, 5.779128211369808, 4.008282193990519, 4.008960295092049, 4.388605344513852, 7.500448429300126, 8.377229779168502, 3.6261280240256264, 3.626267935058095, 3.6272180565164276, 3.6191847424323935, 4.037291926929968, 4.057542140846235, 4.992127114931626, 3.9987663726007927, 4.077376388003859, 3.575650084031665, 10.381341915700721, 5.83345622211707, 3.25229739360432, 3.252630941543375, 3.249286018490967, 3.2369281282715985, 9.827089181929747, 7.179108792217248, 45.18365708360675, 4.505033089709342, 9.363394901362645, 7.7695052189848, 14.90457937632257, 17.050531119611566, 11.955669597751237, 12.91509298727539, 18.333292061848407, 6.61415285404902, 22.461966062633458, 29.267476962213447, 155.68453162146287, 16.167029764645353, 17.697810412619308, 28.836367381236126, 32.90448712803304, 69.34063805510296, 37.00872761355509, 14.992536311065384, 15.004195141776366, 61.96050443010655, 6.012915498227196, 3.968546914794865, 4.640135752269503, 3.724365428880969, 3.480855835075349, 4.554206064853651, 3.8471244667634226, 3.5295918621333713, 3.237915055423949, 4.373760806454237, 3.2610096743759427, 3.3032294778846656, 3.5941053327054098, 4.7073973822450865, 2.993791109823407, 2.9943743904654814, 2.9943354321195352, 2.993934073263003, 2.9939948219936494, 5.362487846918395, 4.516310472295468, 8.97530888011829, 6.231849141012369, 3.3854971022794316, 3.3594967524084414, 5.883007763570556, 3.6430938377690705, 3.6139555665707963, 3.083812902458677, 4.591888470912055, 7.874446998345308, 7.906615616470791, 15.004195141776366, 10.99706360074091, 14.296006853331798, 11.145057581182241, 29.267476962213447, 7.068668747851141, 15.369979978382041, 155.68453162146287, 8.278286064806617, 61.729859997041544, 3.9595980452698907, 4.568456169040347, 3.649365867218396, 3.3370558818727276, 3.336583428349767, 5.923354769773482, 4.156002421111707, 10.175698212825536, 16.731701526428047, 3.129349586126546, 3.129408661877885, 3.1292498229992582, 6.859339386299036, 4.575874282372636, 2.921374904213815, 2.921883748972253, 2.9216683047669467, 2.9217880126450444, 2.921673698389999, 2.9218557927128406, 2.9216490882785484, 2.921757371761984, 2.921938691568894, 7.481544098197347, 3.2580035412175827, 3.6659102080155397, 3.75431769678129, 3.8027038313241923, 4.141639260062502, 2.7139738846411223, 5.621911809288213, 28.836367381236126, 5.15648474188084, 32.90448712803304, 22.461966062633458, 36.377119636822684, 61.96050443010655, 155.68453162146287, 5.830603190167847, 18.333292061848407, 4.732954932877854, 7.1606735166182185, 7.391403205013404, 3.481345110815366, 4.324233134351767, 3.1612809003926783, 4.23307491883192, 3.3905407202235986, 3.809870266857746, 4.796319525059775, 2.841257422008229, 3.2580035412175827, 5.621904124372765, 4.591888470912055, 5.269940137272843, 2.6710028055988624, 2.671079694408823, 2.6712711651465137, 2.678431397002327, 2.6786216156133458, 2.6786161320281265, 2.6787213490542365, 2.6788019703614676, 2.678667077533514, 2.678679279202353, 2.678862446140896, 2.6786890214324814, 2.6787347751979693, 2.678293192299058, 2.6784816663064173, 2.67854854645551, 2.6786242189256315, 2.6786141768323195, 2.6788867563121284, 4.2780507771290575, 7.906615616470791, 17.44141856987286, 17.837136995565672, 5.432389366258441, 9.680969179696142, 6.001801917722308, 29.267476962213447, 22.461966062633458, 32.90448712803304, 45.18365708360675, 7.130122846547722, 16.167029764645353, 13.44124169000026, 18.333292061848407, 11.955669597751237, 10.772603409276314, 3.4964104304214927, 17.697810412619308, 155.68453162146287, 2.8412436592949972, 2.7377991779063673, 2.737886116620902, 4.58074424356658, 3.5669654678650806, 3.5478508481049333, 2.6298269890631416, 2.6298689240090924, 2.63011374807186, 2.6298723961922024, 2.6300592474474014, 2.63012104822636, 2.629963801263655, 2.63020745561793, 4.095811717787819, 4.065689940297108, 2.7963834923288573, 3.003062014997443, 3.003690496364857, 3.019379021714807, 4.396914783022031, 3.1100947672868764, 3.035238962093819, 5.042826002896547, 3.4000606696972824, 3.465079461722822, 3.5265004364714745, 3.926548384531913, 4.169940898985183, 6.2986862296285056, 9.552046823344172, 13.930665098459022, 5.5565432885548605, 5.0120923919531375, 18.333292061848407, 37.00872761355509, 29.267476962213447, 155.68453162146287, 4.736972729311787, 5.04915500160811, 7.395891460069114, 5.1763020290449715, 2.920056758431519, 4.58074424356658, 2.6134654423608583, 2.6134572052096936, 2.6135653629165287, 2.613640280653113, 2.6136064622219215, 2.6136295973414354, 2.613828163816715, 2.613662380569088, 2.613751903460144, 2.613712940120961, 2.6137412405631273, 2.613687565180486, 2.613933814639956, 2.613637536941785, 2.6137449723111468, 2.6137422742572753, 2.6137195100941524, 2.613891572299405, 2.6138987505699522, 2.6138526682746357, 2.6139872849916834, 7.9634301119150965, 7.405366043812775, 2.8595988455317105, 4.678398500936252, 3.1100947672868764, 3.199935664053438, 3.3632609834822595, 7.6625856682474325, 16.167029764645353, 9.827089181929747, 3.844105817303559, 3.5007444273850283, 4.947560176701539, 5.432389366258441, 155.68453162146287, 18.333292061848407, 14.90457937632257, 4.664754520356275, 3.760558438601196, 2.606014549435039, 2.606051783667978, 2.6061944557526564, 2.606131608004843, 2.606239796539465, 2.6061729254362906, 2.606380789497584, 2.606249113072617, 2.606292074240134, 2.606284875101747, 2.6063445178005376, 2.6062737161499485, 2.853160781054003, 2.988183499262777, 4.026369883041094, 3.044282230976149, 3.054528619318433, 3.0546194658207715, 3.219793873000775, 5.026344746935044, 3.4054568454127803, 5.380145088798616, 3.5345704240342064, 3.475392595869871, 3.089682376220412, 3.0970724306963624, 3.649365867218396, 4.031043084912007, 4.736972729311787, 4.26924568475913, 5.0120923919531375, 4.426735341847564, 7.9587588960589715], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.9353, -4.1368, -3.6329, -3.5421, -4.7564, -5.44, -3.68, -5.3256, -5.5385, -5.0958, -5.4399, -5.6939, -5.7874, -5.797, -5.8044, -5.7496, -5.8183, -5.9045, -5.8827, -6.0023, -5.0424, -6.0068, -5.9351, -6.0103, -6.0279, -6.0287, -6.1374, -6.1374, -6.1395, -5.9067, -4.8401, -3.0587, -5.1637, -5.4258, -5.368, -4.7713, -4.6886, -5.6106, -5.7737, -5.5104, -5.1372, -5.1064, -5.4451, -5.0097, -5.4574, -5.5719, -5.6869, -5.6189, -5.6062, -5.6546, -5.5779, -5.6961, -5.8423, -5.6991, -5.9996, -5.6763, -6.0405, -5.1773, -6.1761, -6.1775, -6.1776, -6.1822, -6.1835, -6.1845, -6.2037, -6.2343, -5.5042, -5.7873, -6.2705, -5.3268, -6.1879, -6.2802, -6.1914, -5.9975, -5.6106, -6.4127, -6.414, -6.4158, -5.0677, -6.4204, -4.0417, -5.4718, -5.2494, -4.7218, -3.1955, -5.4491, -4.8859, -5.5972, -5.4416, -5.2563, -5.395, -5.6092, -5.3634, -5.1444, -5.426, -5.4755, -5.3365, -5.5825, -5.3249, -5.2446, -5.6221, -5.3355, -5.5474, -3.7396, -5.2587, -5.2151, -5.4306, -5.482, -5.7898, -5.7697, -5.9614, -5.9623, -5.962, -5.7139, -5.9559, -6.1898, -3.9148, -6.2409, -6.1041, -6.1508, -5.6391, -5.7513, -6.2075, -4.8484, -6.1543, -6.2218, -5.3964, -5.3185, -6.485, -6.4851, -6.4856, -6.4856, -6.4856, -6.2173, -6.1894, -5.245, -5.9369, -5.9815, -5.3376, -5.1987, -4.477, -5.7416, -5.7087, -5.4443, -5.3107, -5.8207, -5.2404, -5.7502, -5.4701, -5.2943, -5.3479, -4.8501, -5.5403, -5.2608, -5.5802, -5.762, -5.383, -5.3802, -5.1788, -5.7703, -5.1978, -5.1158, -5.3236, -5.4132, -5.5902, -5.9667, -5.9966, -5.9578, -5.4334, -5.345, -6.1889, -6.189, -6.2006, -6.207, -6.1038, -6.1273, -5.9241, -6.1532, -6.2036, -6.3437, -5.3087, -5.8893, -6.4874, -6.4874, -6.4925, -6.5029, -5.4493, -5.7596, -4.1342, -6.1959, -5.5668, -5.7295, -5.2288, -5.1941, -5.4471, -5.4117, -5.358, -5.8943, -5.3163, -5.1934, -4.4553, -5.4756, -5.4518, -5.3218, -5.2964, -5.1339, -5.367, -5.5932, -5.6489, -5.5579, -4.9107, -5.3644, -5.2179, -5.5219, -5.7065, -5.4617, -5.6326, -5.7599, -5.9344, -5.6934, -6.0067, -6.023, -5.9858, -5.7478, -6.2299, -6.2299, -6.2303, -6.2307, -6.2307, -5.676, -5.8619, -5.2146, -5.5827, -6.1945, -6.2194, -5.6932, -6.2204, -6.2314, -6.3995, -6.0255, -5.5137, -5.6909, -5.2758, -5.52, -5.3771, -5.6232, -5.3103, -5.8803, -5.6215, -4.9918, -5.9071, -5.8558, -5.1807, -5.1769, -5.4641, -5.6578, -5.6582, -5.0861, -5.4693, -4.6144, -4.1217, -5.8865, -5.8866, -5.8867, -5.218, -5.6561, -6.1816, -6.1816, -6.1817, -6.1818, -6.182, -6.1819, -6.1821, -6.1823, -6.1823, -5.3145, -6.1758, -6.1734, -6.1669, -6.1681, -6.1746, -6.6027, -5.8872, -5.1076, -6.0859, -5.6106, -5.8212, -5.8579, -5.9131, -5.867, -6.1353, -6.0668, -6.1617, -6.1479, -6.1536, -5.275, -5.2451, -5.6205, -5.4103, -5.8569, -5.8263, -5.6197, -6.1521, -6.1551, -5.6127, -5.8567, -5.866, -6.5692, -6.5693, -6.5695, -6.5782, -6.5782, -6.5785, -6.5785, -6.5785, -6.5786, -6.5786, -6.5785, -6.5786, -6.5787, -6.5874, -6.5876, -6.5877, -6.588, -6.5882, -6.5881, -6.1404, -5.656, -5.1212, -5.251, -6.1321, -5.8211, -6.1305, -5.3113, -5.4679, -5.4291, -5.3552, -6.1951, -5.8796, -5.975, -5.9055, -6.1733, -6.2884, -6.5281, -6.3383, -6.2397, -5.7897, -6.0922, -6.0926, -5.812, -6.1092, -6.1229, -6.5177, -6.5179, -6.5181, -6.5183, -6.5182, -6.5182, -6.5185, -6.5187, -6.0886, -6.1051, -6.5168, -6.5176, -6.5203, -6.5184, -6.1491, -6.5141, -6.544, -6.0971, -6.5195, -6.5155, -6.501, -6.5121, -6.535, -6.1595, -6.1495, -6.2073, -6.4475, -6.465, -6.2877, -6.2128, -6.267, -6.2029, -6.5099, -6.5099, -6.5098, -6.513, -5.5385, -5.7577, -6.4859, -6.4859, -6.4864, -6.4865, -6.4865, -6.4866, -6.4865, -6.4867, -6.4866, -6.4867, -6.4867, -6.4867, -6.4866, -6.4868, -6.4868, -6.4868, -6.4868, -6.4869, -6.4869, -6.487, -6.487, -5.4582, -5.5335, -6.4893, -6.0628, -6.4779, -6.4762, -6.4872, -5.7679, -5.5313, -6.0, -6.46, -6.4718, -6.4554, -6.4558, -6.3842, -6.4631, -6.4725, -5.4742, -6.0569, -6.4864, -6.4864, -6.4866, -6.4867, -6.4867, -6.4868, -6.4868, -6.4869, -6.487, -6.487, -6.487, -6.4871, -6.4918, -6.4763, -6.2007, -6.4828, -6.4812, -6.4858, -6.4858, -6.0522, -6.4785, -6.0215, -6.467, -6.4912, -6.6215, -6.631, -6.5002, -6.4274, -6.3516, -6.4717, -6.4673, -6.4834, -6.4808], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.9662, 0.9181, 0.8932, 0.8678, 0.8562, 0.8453, 0.8424, 0.8222, 0.8141, 0.8101, 0.8051, 0.7915, 0.7681, 0.7608, 0.7567, 0.751, 0.748, 0.7363, 0.7235, 0.7178, 0.7172, 0.716, 0.714, 0.7132, 0.7005, 0.7003, 0.6781, 0.678, 0.6768, 0.6679, 0.6457, 0.5424, 0.6264, 0.6295, 0.621, 0.516, 0.4668, 0.6028, 0.6464, 0.5124, 0.2944, 0.1661, 0.3865, 0.028, 0.3554, 0.443, 0.575, 0.4317, 0.1692, 0.2619, 1.2508, 1.2097, 1.1502, 1.0913, 1.0845, 1.0753, 1.0541, 1.0251, 1.0063, 1.0052, 1.0051, 1.001, 1.0007, 0.9992, 0.9839, 0.9643, 0.9575, 0.9441, 0.9272, 0.9245, 0.9128, 0.9092, 0.903, 0.8966, 0.8836, 0.8831, 0.8829, 0.8803, 0.8796, 0.8763, 0.7965, 0.8002, 0.7773, 0.7097, 0.4056, 0.7623, 0.6512, 0.7815, 0.6489, 0.5192, 0.5455, 0.6319, 0.4042, 0.1281, 0.3142, 0.3184, 0.1492, 0.2834, -0.1695, -0.7221, 0.2944, -0.9256, -0.5097, 1.7468, 1.5928, 1.5047, 1.4089, 1.3981, 1.3161, 1.3032, 1.2834, 1.2827, 1.2826, 1.2627, 1.1844, 1.1564, 1.123, 1.1098, 1.1088, 1.0651, 1.0386, 1.0358, 1.0253, 1.0175, 1.0137, 1.011, 0.9984, 0.9904, 0.9738, 0.9737, 0.9733, 0.9733, 0.9732, 0.9727, 0.9598, 0.9043, 0.9397, 0.9359, 0.8648, 0.7426, 0.3612, 0.7873, 0.7595, 0.5785, 0.4831, 0.8166, 0.2967, 0.7094, 0.2975, -0.007, -0.0755, -1.249, 0.1999, -0.7346, -0.4249, 0.6969, 1.5712, 1.466, 1.445, 1.4017, 1.3762, 1.3654, 1.3495, 1.3215, 1.3045, 1.2938, 1.2638, 1.2121, 1.2005, 1.1785, 1.1719, 1.1717, 1.1599, 1.1557, 1.1496, 1.121, 1.117, 1.1098, 1.0398, 1.0311, 1.0002, 0.996, 0.9822, 0.982, 0.978, 0.9714, 0.9145, 0.9181, 0.704, 0.9478, 0.8453, 0.8692, 0.7185, 0.6186, 0.7206, 0.6789, 0.3822, 0.8654, 0.2208, 0.079, -0.8542, 0.3903, 0.3237, -0.0346, -0.1411, -0.724, -0.3292, 0.3482, 0.2917, -1.0355, 1.9443, 1.9061, 1.8963, 1.8121, 1.6952, 1.6712, 1.669, 1.6278, 1.5396, 1.4799, 1.4602, 1.431, 1.3839, 1.352, 1.3225, 1.3222, 1.3219, 1.3216, 1.3216, 1.2935, 1.2793, 1.2399, 1.2366, 1.2349, 1.2178, 1.1836, 1.1357, 1.1327, 1.1232, 1.0991, 1.0716, 0.8903, 0.6648, 0.7313, 0.6118, 0.6147, -0.0379, 0.8129, 0.295, -1.3907, 0.6282, -1.3297, 2.0921, 1.9529, 1.8903, 1.7861, 1.7858, 1.7839, 1.7551, 1.7145, 1.7099, 1.6216, 1.6215, 1.6215, 1.5053, 1.472, 1.3952, 1.395, 1.395, 1.3949, 1.3948, 1.3948, 1.3947, 1.3944, 1.3943, 1.322, 1.292, 1.1765, 1.1591, 1.1451, 1.0532, 1.0478, 1.0351, 0.1797, 0.9228, -0.4552, -0.2841, -0.8029, -1.3907, -2.2659, 0.7505, -0.3266, 0.9327, 0.5324, 0.495, 2.1265, 1.9396, 1.8775, 1.7957, 1.5711, 1.485, 1.4614, 1.4526, 1.3127, 1.3096, 1.2679, 1.1209, 1.0973, 1.0971, 1.0968, 1.0854, 1.0854, 1.0851, 1.085, 1.085, 1.085, 1.085, 1.085, 1.085, 1.0849, 1.0763, 1.0761, 1.076, 1.0757, 1.0755, 1.0754, 1.055, 0.9252, 0.6689, 0.5166, 0.8244, 0.5577, 0.7264, -0.0388, 0.0692, -0.2738, -0.517, 0.4895, -0.0137, 0.0756, -0.1653, -0.0056, -0.0165, 0.8691, -0.5628, -2.6386, 1.8149, 1.5496, 1.5491, 1.3151, 1.268, 1.2597, 1.1643, 1.1641, 1.1638, 1.1637, 1.1637, 1.1637, 1.1634, 1.1632, 1.1503, 1.1413, 1.1038, 1.0317, 1.0287, 1.0254, 1.0189, 1.0002, 0.9947, 0.9339, 0.9056, 0.8907, 0.8876, 0.7691, 0.6861, 0.649, 0.2427, -0.1924, 0.4864, 0.5721, -0.5475, -1.1751, -0.9945, -2.6018, 0.5836, 0.5198, 0.1382, 0.4918, 2.0388, 1.3694, 1.2024, 1.2024, 1.2018, 1.2017, 1.2016, 1.2016, 1.2016, 1.2015, 1.2015, 1.2015, 1.2014, 1.2014, 1.2014, 1.2014, 1.2013, 1.2013, 1.2013, 1.2012, 1.2011, 1.2011, 1.201, 1.1159, 1.1132, 1.1089, 1.0432, 1.0364, 1.0096, 0.9489, 0.8447, 0.3346, 0.3638, 0.8424, 0.9242, 0.5947, 0.5007, -2.7831, -0.7229, -0.5252, 1.6347, 1.2674, 1.2047, 1.2047, 1.2045, 1.2043, 1.2043, 1.2043, 1.2042, 1.2041, 1.204, 1.204, 1.2039, 1.2039, 1.1087, 1.078, 1.0553, 1.0529, 1.0511, 1.0465, 0.9938, 0.9821, 0.945, 0.9448, 0.9194, 0.9121, 0.8993, 0.8875, 0.8542, 0.8275, 0.7419, 0.7258, 0.5697, 0.6779, 0.0938]}, \"token.table\": {\"Topic\": [1, 3, 1, 1, 6, 1, 3, 1, 6, 1, 2, 3, 4, 1, 2, 3, 4, 1, 4, 1, 1, 5, 1, 1, 1, 3, 1, 2, 3, 1, 2, 3, 4, 1, 2, 4, 5, 1, 1, 2, 1, 2, 4, 1, 2, 3, 4, 1, 1, 1, 1, 2, 3, 1, 4, 1, 2, 5, 1, 1, 7, 1, 3, 1, 3, 1, 1, 3, 1, 2, 1, 2, 1, 2, 4, 1, 1, 2, 3, 4, 5, 1, 3, 4, 7, 1, 3, 1, 4, 1, 2, 4, 7, 1, 2, 3, 4, 1, 2, 3, 5, 1, 1, 6, 1, 3, 1, 4, 1, 4, 1, 2, 3, 6, 1, 2, 3, 1, 4, 5, 1, 3, 4, 1, 2, 1, 2, 6, 1, 3, 1, 2, 1, 6, 1, 2, 3, 1, 3, 1, 2, 3, 4, 1, 1, 2, 1, 2, 3, 4, 1, 1, 2, 4, 1, 2, 3, 4, 1, 3, 1, 1, 2, 5, 1, 2, 5, 1, 5, 1, 6, 1, 2, 7, 1, 2, 1, 2, 3, 4, 1, 6, 1, 1, 3, 1, 2, 1, 4, 1, 2, 3, 4, 1, 5, 1, 1, 2, 6, 1, 2, 1, 1, 1, 4, 6, 1, 2, 5, 1, 2, 3, 4, 5, 6, 7, 1, 2, 3, 4, 1, 6, 1, 2, 3, 4, 1, 2, 1, 2, 5, 1, 2, 3, 1, 1, 6, 1, 1, 2, 1, 2, 3, 5, 1, 2, 1, 2, 4, 5, 1, 3, 4, 1, 2, 3, 4, 1, 3, 4, 9, 1, 4, 1, 2, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 6, 1, 2, 4, 5, 1, 7, 1, 2, 3, 1, 2, 1, 2, 3, 4, 5, 1, 1, 2, 4, 1, 1, 2, 3, 4, 1, 2, 3, 4, 5, 7, 1, 1, 2, 3, 4, 1, 2, 3, 1, 2, 4, 1, 1, 4, 1, 2, 6, 1, 6, 1, 4, 1, 2, 3, 4, 5, 1, 1, 2, 4, 1, 2, 3, 6, 1, 2, 3, 1, 2, 4, 1, 1, 3, 5, 1, 1, 2, 3, 4, 6, 1, 4, 1, 2, 5, 1, 5, 1, 2, 3, 1, 1, 1, 2, 3, 4, 5, 1, 2, 5, 6, 1, 2, 1, 2, 5, 1, 1, 5, 1, 1, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 5, 1, 2, 5, 1, 2, 3, 1, 3, 1, 2, 5, 1, 6, 1, 1, 2, 3, 4, 1, 2, 3, 4, 6, 7, 1, 2, 1, 3, 5, 1, 2, 1, 1, 6, 1, 3, 4, 1, 2, 1, 1, 1, 2, 4, 6, 1, 2, 4, 5, 1, 3, 1, 5, 1, 1, 2, 3, 1, 5, 7, 1, 1, 2, 3, 4, 6, 1, 2, 5, 1, 2, 1, 2, 3, 4, 1, 2, 1, 3, 7, 1, 3, 7, 1, 1, 2, 3, 4, 1, 3, 1, 2, 3, 4, 7, 1, 2, 3, 1, 6, 1, 1, 2, 3, 4, 1, 2, 1, 2, 3, 1, 2, 4, 1, 2, 3, 4, 1, 2, 3, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 2, 5, 1, 1, 2, 4, 1, 5, 1, 4, 1, 3, 1, 2, 3, 5, 7, 1, 3, 1, 2, 1, 2, 3, 4, 1, 2, 3, 4, 6, 1, 2, 5, 1, 2, 3, 1, 5, 1, 1, 1, 1, 3, 4, 1, 2, 3, 1, 4, 1, 3, 4, 1, 2, 5, 1, 1, 4, 1, 2, 3, 4, 5, 6, 1, 1, 5, 1, 2, 1, 3, 1, 3, 4, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 6, 1, 1, 2, 4, 1, 3, 1, 2, 3, 1, 1, 1, 3, 1, 2, 5, 1, 5, 1, 1, 2, 3, 4, 1, 2, 4, 6, 1, 2, 3, 5, 1, 1, 6, 1, 1, 3, 1, 2, 3, 4, 1, 2, 4, 1, 1, 1, 2, 4, 1, 2, 1, 5, 1, 6, 1, 2, 3, 4, 1, 6, 1, 2, 3, 4, 1, 1, 1, 1, 1, 2, 3, 1, 3, 1, 2, 1, 2, 3, 1, 3, 7, 1, 6, 1, 6, 1, 6, 1, 4, 1, 4, 1, 2, 3, 1, 3, 7, 1, 5, 1, 2, 4, 5, 6, 1, 2, 4, 1, 2, 3, 1, 3, 1, 4, 1, 1, 1, 4, 1, 6, 1, 2, 3, 4, 1, 1, 4, 1, 1, 1, 2, 5, 1, 3, 4, 1, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 4, 7, 1, 2, 3, 4, 1, 2, 3, 4, 1, 1, 1, 2, 4, 1, 2, 3, 1, 4, 5, 1, 1, 1, 2, 3, 7, 1, 3, 1, 1, 2, 3, 4, 5, 7, 1, 3, 1, 2, 1, 6, 1, 2, 3, 4, 1, 1, 1, 1, 1, 3, 1, 2, 3, 4, 5, 7, 1, 1, 2, 3, 1, 4, 1, 2, 1, 2, 3, 4, 6, 1, 2, 4, 5, 1, 6, 1, 2, 3, 4, 1, 2, 3, 5, 1, 2, 1, 2, 3, 4, 1, 5, 1, 2, 3, 4, 1, 2, 3, 1, 7, 1, 1, 2, 1, 2, 1, 2, 5, 1, 2, 3, 4, 1, 2, 3, 4, 6, 7, 1, 2, 4, 1, 2, 3, 4, 1, 3, 1, 2, 3, 1, 1, 6, 1, 6, 1], \"Freq\": [0.6767675982170887, 0.13535351964341774, 0.37333652261904593, 0.27402020964322105, 0.27402020964322105, 0.33465146977978855, 0.33465146977978855, 0.4370749449355458, 0.2185374724677729, 0.33571485791163136, 0.11190495263721045, 0.2238099052744209, 0.11190495263721045, 0.13198455800342235, 0.13198455800342235, 0.13198455800342235, 0.5279382320136894, 0.22834763633610702, 0.45669527267221405, 0.3733263385060162, 0.3340019136486406, 0.3340019136486406, 0.3733012036963164, 0.3732893888268138, 0.28186077792254005, 0.28186077792254005, 0.8162232845269752, 0.09602626876787944, 0.04801313438393972, 0.34951190683203637, 0.4368898835400455, 0.08737797670800909, 0.08737797670800909, 0.1799680031396064, 0.1799680031396064, 0.3599360062792128, 0.1799680031396064, 0.382601200434967, 0.23234786271330427, 0.46469572542660853, 0.17142496007916924, 0.17142496007916924, 0.3428499201583385, 0.25092697447613266, 0.25092697447613266, 0.08364232482537755, 0.25092697447613266, 0.37331056783182126, 0.3733528516426405, 0.380198146676253, 0.24263645416797988, 0.24263645416797988, 0.24263645416797988, 0.27630532044294503, 0.27630532044294503, 0.18648060910285505, 0.3729612182057101, 0.18648060910285505, 0.38257028883844607, 0.5336270298516892, 0.17787567661722972, 0.2730088816104499, 0.2730088816104499, 0.32738275676170725, 0.32738275676170725, 0.37438044326914965, 0.21374835850342327, 0.42749671700684655, 0.2835672412394692, 0.2835672412394692, 0.7412696978619514, 0.12354494964365857, 0.22590010984994532, 0.22590010984994532, 0.22590010984994532, 0.3836931761373562, 0.3589034844246798, 0.26917761331850987, 0.08972587110616995, 0.08972587110616995, 0.08972587110616995, 0.6306826452178991, 0.057334785928899915, 0.11466957185779983, 0.057334785928899915, 0.2324885598528298, 0.2324885598528298, 0.2973304792316825, 0.2973304792316825, 0.5207852192113855, 0.29759155383507746, 0.07439788845876937, 0.07439788845876937, 0.16927622811144807, 0.04231905702786202, 0.7617430265015164, 0.04231905702786202, 0.858579624229507, 0.04859884665450039, 0.06479846220600052, 0.01619961555150013, 0.35760474296291517, 0.34230457671064124, 0.34230457671064124, 0.7476151411151989, 0.12460252351919981, 0.2757762531753713, 0.2757762531753713, 0.30893487911143813, 0.30893487911143813, 0.4189550037489789, 0.27930333583265265, 0.13965166791632633, 0.13965166791632633, 0.1499666432638333, 0.5998665730553332, 0.1499666432638333, 0.29766363050748434, 0.29766363050748434, 0.29766363050748434, 0.2500771254984825, 0.2500771254984825, 0.2500771254984825, 0.3311939285555698, 0.3311939285555698, 0.26297078193748685, 0.26297078193748685, 0.26297078193748685, 0.23860720396359825, 0.4772144079271965, 0.17496481832181227, 0.6998592732872491, 0.3422597679275962, 0.3422597679275962, 0.16994038489556432, 0.33988076979112863, 0.33988076979112863, 0.32946335115247843, 0.32946335115247843, 0.33598228277441583, 0.11199409425813861, 0.22398818851627722, 0.22398818851627722, 0.3733273752708133, 0.3284846555371281, 0.3284846555371281, 0.2099397292500124, 0.2099397292500124, 0.3149095938750186, 0.1049698646250062, 0.6399970249893538, 0.11937120341221641, 0.3581136102366492, 0.3581136102366492, 0.3512684936306355, 0.10808261342481093, 0.405309800343041, 0.08106196006860819, 0.2803503451348312, 0.2803503451348312, 0.38372222926150584, 0.2744919687856221, 0.2744919687856221, 0.2744919687856221, 0.295377597377563, 0.295377597377563, 0.295377597377563, 0.26850211642643834, 0.26850211642643834, 0.5817916953451011, 0.1939305651150337, 0.23125487662910366, 0.23125487662910366, 0.23125487662910366, 0.2319292816633403, 0.4638585633266806, 0.13929305557872076, 0.13929305557872076, 0.4178791667361623, 0.27858611115744153, 0.34225617863861285, 0.34225617863861285, 0.38021063732954674, 0.24563472013002277, 0.49126944026004554, 0.16199664641382538, 0.6479865856553015, 0.27569337834637875, 0.27569337834637875, 0.13418694681026705, 0.4696543138359347, 0.06709347340513352, 0.2683738936205341, 0.3966030156208485, 0.19830150781042424, 0.3826096861686876, 0.2112844965105032, 0.4225689930210064, 0.2112844965105032, 0.23091631282265548, 0.46183262564531097, 0.38259748599389826, 0.350488485135627, 0.27278354985713854, 0.27278354985713854, 0.27278354985713854, 0.4248632179521129, 0.21243160897605645, 0.21243160897605645, 0.5470378532253392, 0.1519549592292609, 0.09117297553755653, 0.1215639673834087, 0.030390991845852176, 0.030390991845852176, 0.030390991845852176, 0.2231940051761236, 0.2231940051761236, 0.4463880103522472, 0.2231940051761236, 0.3422482391136542, 0.3422482391136542, 0.5742726527023424, 0.0717840815877928, 0.0717840815877928, 0.1435681631755856, 0.7437714362985021, 0.12396190604975034, 0.6459321140532109, 0.10765535234220182, 0.10765535234220182, 0.8199339656065481, 0.08199339656065481, 0.08199339656065481, 0.7395747122744653, 0.31956540914382503, 0.31956540914382503, 0.7285385371843531, 0.2587115509108013, 0.5174231018216026, 0.2143735529139107, 0.2143735529139107, 0.2143735529139107, 0.2143735529139107, 0.25840937203791053, 0.5168187440758211, 0.2728000954543793, 0.4546668257572988, 0.09093336515145975, 0.09093336515145975, 0.21830513707558516, 0.21830513707558516, 0.21830513707558516, 0.7725082579324838, 0.0643756881610403, 0.0643756881610403, 0.0643756881610403, 0.12557402852117372, 0.12557402852117372, 0.5022961140846949, 0.12557402852117372, 0.1836530542811178, 0.5509591628433534, 0.23428018199035697, 0.46856036398071393, 0.3733721173153548, 0.4807178152843333, 0.40059817940361114, 0.04005981794036111, 0.08011963588072223, 0.04005981794036111, 0.11443829539402525, 0.11443829539402525, 0.11443829539402525, 0.457753181576101, 0.11443829539402525, 0.3422449645204883, 0.3422449645204883, 0.45543325429477055, 0.260247573882726, 0.130123786941363, 0.0650618934706815, 0.2872452940368759, 0.2872452940368759, 0.17700176050002056, 0.3540035210000411, 0.3540035210000411, 0.25850942427218027, 0.5170188485443605, 0.26679942052551586, 0.2000995653941369, 0.26679942052551586, 0.2000995653941369, 0.06669985513137897, 0.28773727641256763, 0.1730364794524905, 0.1730364794524905, 0.5191094383574715, 0.7330882288876663, 0.18408106131183857, 0.18408106131183857, 0.18408106131183857, 0.18408106131183857, 0.2803140437416052, 0.2803140437416052, 0.1681884262449631, 0.11212561749664207, 0.056062808748321036, 0.056062808748321036, 0.38370439284361507, 0.12870832463777723, 0.25741664927555447, 0.12870832463777723, 0.25741664927555447, 0.23981155230362255, 0.23981155230362255, 0.23981155230362255, 0.21110528963194716, 0.21110528963194716, 0.21110528963194716, 0.38367379165373755, 0.16485546222200104, 0.4945663866660031, 0.437359901741012, 0.14578663391367067, 0.29157326782734133, 0.34227020170921396, 0.34227020170921396, 0.3215336106534015, 0.3215336106534015, 0.26659210722091653, 0.33324013402614566, 0.06664802680522913, 0.13329605361045826, 0.13329605361045826, 0.3825770335632898, 0.2885936703751101, 0.2885936703751101, 0.2885936703751101, 0.266359983561683, 0.266359983561683, 0.266359983561683, 0.266359983561683, 0.676686562990258, 0.21146455093445563, 0.042292910186891124, 0.1980529414687228, 0.3961058829374456, 0.1980529414687228, 0.3802465858981987, 0.6295464245599797, 0.13989920545777326, 0.13989920545777326, 0.3836791311241876, 0.1715088417758048, 0.1715088417758048, 0.3430176835516096, 0.1715088417758048, 0.1715088417758048, 0.3074749566157485, 0.3074749566157485, 0.3242738880827417, 0.3242738880827417, 0.3242738880827417, 0.333963920432305, 0.333963920432305, 0.23423341588653965, 0.23423341588653965, 0.23423341588653965, 0.7266096839393485, 0.37331830195729, 0.18586859341060996, 0.18586859341060996, 0.18586859341060996, 0.18586859341060996, 0.18586859341060996, 0.15590428374615942, 0.6236171349846377, 0.15590428374615942, 0.15590428374615942, 0.919561376346679, 0.047156993658804054, 0.25993440260104134, 0.25993440260104134, 0.25993440260104134, 0.3424590967667151, 0.2519813980961065, 0.503962796192213, 0.37331694422118117, 0.3825933433963613, 0.16573562234599404, 0.6629424893839762, 0.19951747130709116, 0.19951747130709116, 0.19951747130709116, 0.19951747130709116, 0.19951747130709116, 0.24635043807700738, 0.16423362538467157, 0.32846725076934313, 0.16423362538467157, 0.3825917825927462, 0.3825965242781455, 0.38257133945319455, 0.7290476057577615, 0.3825573313770658, 0.19318810888330257, 0.38637621776660513, 0.19318810888330257, 0.3496993998170611, 0.33402464077027283, 0.33402464077027283, 0.1663086734371758, 0.1663086734371758, 0.49892602031152744, 0.26013852051072, 0.26013852051072, 0.26013852051072, 0.17051950997047488, 0.5115585299114246, 0.5570838916837482, 0.11141677833674962, 0.22283355667349924, 0.21889232664129085, 0.4377846532825817, 0.3733271027688635, 0.1337634563264353, 0.2675269126528706, 0.2675269126528706, 0.1337634563264353, 0.22259850211054039, 0.3561576033768646, 0.1780788016884323, 0.13355910126632423, 0.04451970042210807, 0.04451970042210807, 0.8050608565497843, 0.10063260706872304, 0.24596071384797316, 0.24596071384797316, 0.24596071384797316, 0.2856535290543834, 0.2856535290543834, 0.3826048870865502, 0.3195552214534722, 0.3195552214534722, 0.20679905075048508, 0.41359810150097015, 0.20679905075048508, 0.23072926647776276, 0.4614585329555255, 0.3836879113074548, 0.38258062019647027, 0.1688232494705431, 0.1688232494705431, 0.1688232494705431, 0.3376464989410862, 0.4244080614064697, 0.14146935380215656, 0.2829387076043131, 0.14146935380215656, 0.23787762248364666, 0.4757552449672933, 0.33400869074920164, 0.33400869074920164, 0.3825927971525745, 0.5788907497599752, 0.0723613437199969, 0.2170840311599907, 0.5059054586727774, 0.12647636466819434, 0.12647636466819434, 0.38260852389275796, 0.5379010607967352, 0.059766784532970574, 0.059766784532970574, 0.059766784532970574, 0.29883392266485287, 0.28331887624978136, 0.28331887624978136, 0.28331887624978136, 0.1908197633888793, 0.5724592901666379, 0.15485757647819512, 0.3871439411954878, 0.15485757647819512, 0.23228636471729266, 0.23449318610068, 0.46898637220136, 0.379510952288537, 0.1897554761442685, 0.1897554761442685, 0.2949382067689935, 0.2949382067689935, 0.2949382067689935, 0.37334584461762765, 0.6727320053151564, 0.07474800059057293, 0.07474800059057293, 0.14949600118114587, 0.28291981203719885, 0.28291981203719885, 0.2065908859822209, 0.4131817719644418, 0.10329544299111044, 0.2065908859822209, 0.10329544299111044, 0.17294976158934164, 0.5188492847680249, 0.17294976158934164, 0.48290057979840034, 0.24145028989920017, 0.38261307295279023, 0.836450336005116, 0.07210778758664793, 0.014421557517329585, 0.05768623006931834, 0.23113971586760934, 0.4622794317352187, 0.2426520239695138, 0.2426520239695138, 0.2426520239695138, 0.29364635800539374, 0.29364635800539374, 0.29364635800539374, 0.6433168154996155, 0.0919024022142308, 0.0919024022142308, 0.0919024022142308, 0.15537636236660787, 0.31075272473321575, 0.31075272473321575, 0.3236578645418217, 0.3236578645418217, 0.26665072346702634, 0.13332536173351317, 0.13332536173351317, 0.3999760852005395, 0.33323325684813715, 0.16661662842406857, 0.16661662842406857, 0.16661662842406857, 0.16661662842406857, 0.2286361884546425, 0.2286361884546425, 0.2286361884546425, 0.38368685147905024, 0.24769078335150727, 0.24769078335150727, 0.49538156670301453, 0.3088407147447749, 0.3088407147447749, 0.2941123989087621, 0.2941123989087621, 0.7000469785095935, 0.11667449641826559, 0.21777532410350048, 0.21777532410350048, 0.21777532410350048, 0.21777532410350048, 0.21777532410350048, 0.3041785805443919, 0.3041785805443919, 0.20913995052129628, 0.6274198515638888, 0.5278427948586408, 0.11729839885747574, 0.11729839885747574, 0.23459679771495148, 0.8069656704683806, 0.09683588045620567, 0.03227862681873522, 0.048417940228102835, 0.01613931340936761, 0.2155109361856272, 0.2155109361856272, 0.4310218723712544, 0.08659377281344789, 0.5195626368806874, 0.34637509125379157, 0.48139804608823494, 0.160466015362745, 0.3836945477264941, 0.37329277635758257, 0.37435360851699684, 0.22786282235427915, 0.22786282235427915, 0.4557256447085583, 0.19895173338632974, 0.3979034667726595, 0.19895173338632974, 0.24948343245374938, 0.49896686490749875, 0.18780698962768785, 0.3756139792553757, 0.18780698962768785, 0.2195772404146001, 0.2195772404146001, 0.4391544808292002, 0.7780538476868616, 0.279669424160338, 0.279669424160338, 0.6037850968300118, 0.28262281128213324, 0.03853947426574544, 0.05138596568766059, 0.012846491421915147, 0.006423245710957573, 0.3125062829335997, 0.30665349074481646, 0.30665349074481646, 0.25868071814639154, 0.5173614362927831, 0.30419252615875864, 0.30419252615875864, 0.22197395226336028, 0.22197395226336028, 0.22197395226336028, 0.32737302017136904, 0.32737302017136904, 0.32288557093098225, 0.32288557093098225, 0.21134452547037158, 0.6340335764111147, 0.8131923711951653, 0.09035470791057391, 0.31057888779321846, 0.5346489905691777, 0.13366224764229442, 0.3733124389190631, 0.3955291551212853, 0.3390249901039588, 0.1695124950519794, 0.47628979927405257, 0.1587632664246842, 0.2274321994734437, 0.2274321994734437, 0.4548643989468874, 0.3652452868398338, 0.3802195714680374, 0.2441518480102665, 0.2441518480102665, 0.3027340385205038, 0.3027340385205038, 0.3027340385205038, 0.28728566978366493, 0.28728566978366493, 0.3733200024695822, 0.11295553409206102, 0.3388666022761831, 0.22591106818412204, 0.22591106818412204, 0.8796738257310524, 0.05497961410819077, 0.027489807054095386, 0.027489807054095386, 0.25467660195895203, 0.25467660195895203, 0.25467660195895203, 0.25467660195895203, 0.3826349243471786, 0.24061583672814743, 0.24061583672814743, 0.38371047606669517, 0.6525212528088561, 0.1305042505617712, 0.24005589533899413, 0.24005589533899413, 0.24005589533899413, 0.12002794766949706, 0.20031541204328815, 0.20031541204328815, 0.4006308240865763, 0.3802333703298563, 0.3519568456747541, 0.24836267631842748, 0.24836267631842748, 0.24836267631842748, 0.230799788553593, 0.461599577107186, 0.5610001519029547, 0.14025003797573868, 0.30693643740678056, 0.30693643740678056, 0.34530111353478377, 0.23020074235652252, 0.23020074235652252, 0.11510037117826126, 0.29970777637488527, 0.29970777637488527, 0.22444530537555796, 0.4488906107511159, 0.11222265268777898, 0.11222265268777898, 0.38256515692909393, 0.38260812224324675, 0.36846338340217055, 0.38259319208668396, 0.16374044975797242, 0.16374044975797242, 0.49122134927391725, 0.3042211020409132, 0.3042211020409132, 0.6128561170009237, 0.17510174771454962, 0.6282386569689787, 0.12564773139379576, 0.12564773139379576, 0.23623489287922672, 0.23623489287922672, 0.23623489287922672, 0.5896401283243198, 0.2948200641621599, 0.5336263004061297, 0.17787543346870988, 0.3422385291263808, 0.3422385291263808, 0.3329237819975878, 0.3329237819975878, 0.3329934563475378, 0.3329934563475378, 0.23186881624811242, 0.46373763249622485, 0.11593440812405621, 0.4169863974971673, 0.20849319874858366, 0.20849319874858366, 0.3339595753904868, 0.3339595753904868, 0.2705846162800928, 0.4058769244201392, 0.1352923081400464, 0.1352923081400464, 0.1352923081400464, 0.24525574900127506, 0.24525574900127506, 0.24525574900127506, 0.1452689448475923, 0.1452689448475923, 0.5810757793903693, 0.3041665285545784, 0.3041665285545784, 0.27576561299626623, 0.27576561299626623, 0.3802116926437502, 0.8044358774874381, 0.3074434259441372, 0.3074434259441372, 0.342272452914325, 0.342272452914325, 0.20211982558778788, 0.20211982558778788, 0.20211982558778788, 0.20211982558778788, 0.6394180115709122, 0.2494412332355213, 0.4988824664710426, 0.3836895540953483, 0.3826337183539171, 0.5099432332177001, 0.16998107773923335, 0.16998107773923335, 0.14745020598776212, 0.14745020598776212, 0.4423506179632864, 0.30421649066369244, 0.30421649066369244, 0.4358379914520034, 0.4358379914520034, 0.07263966524200056, 0.2212006636680307, 0.2212006636680307, 0.4424013273360614, 0.12370856175286277, 0.24741712350572553, 0.3711256852585883, 0.18556284262929415, 0.06185428087643138, 0.18002658522540824, 0.3600531704508165, 0.18002658522540824, 0.18002658522540824, 0.23375131621768327, 0.23375131621768327, 0.23375131621768327, 0.23375131621768327, 0.38025315131328974, 0.6711907875065654, 0.24645461840882854, 0.24645461840882854, 0.4929092368176571, 0.21262907786191054, 0.4252581557238211, 0.21262907786191054, 0.2782333591896331, 0.2782333591896331, 0.2782333591896331, 0.639459264355326, 0.38370122298153875, 0.26247612909527407, 0.26247612909527407, 0.26247612909527407, 0.26247612909527407, 0.5401488564285114, 0.13503721410712785, 0.7326109739064224, 0.4100114272061414, 0.2050057136030707, 0.13667047573538046, 0.13667047573538046, 0.06833523786769023, 0.034167618933845116, 0.2717956336664131, 0.5435912673328261, 0.23101046831696162, 0.46202093663392324, 0.3195491890151296, 0.3195491890151296, 0.40703812959744806, 0.10175953239936202, 0.10175953239936202, 0.30527859719808603, 0.38372771181066173, 0.3743912203700554, 0.3802470879330192, 0.8467311793755877, 0.24556237254888078, 0.49112474509776155, 0.1106594800582016, 0.42050602422116606, 0.17705516809312255, 0.2434508561280435, 0.02213189601164032, 0.02213189601164032, 0.37332597567608405, 0.7229557668281162, 0.1112239641274025, 0.1112239641274025, 0.30775991842799355, 0.30775991842799355, 0.2939560474116188, 0.44093407111742816, 0.5895333408417431, 0.06935686362844036, 0.13871372725688072, 0.10403529544266055, 0.06935686362844036, 0.22141967566984785, 0.22141967566984785, 0.22141967566984785, 0.22141967566984785, 0.29966534436301034, 0.29966534436301034, 0.15119094191901308, 0.30238188383802617, 0.15119094191901308, 0.30238188383802617, 0.48319180669597234, 0.12079795167399308, 0.12079795167399308, 0.12079795167399308, 0.2659179524336729, 0.2659179524336729, 0.21359774110445157, 0.21359774110445157, 0.21359774110445157, 0.3203966116566774, 0.2767051175864008, 0.2767051175864008, 0.2704204098719034, 0.4056306148078551, 0.1352102049359517, 0.1352102049359517, 0.27848421463438383, 0.46414035772397305, 0.18565614308958922, 0.3163274734224931, 0.3163274734224931, 0.3652568851907954, 0.23078472281740697, 0.46156944563481395, 0.24807474862845058, 0.24807474862845058, 0.5079721789784778, 0.12699304474461945, 0.12699304474461945, 0.09632666066875246, 0.19265332133750493, 0.38530664267500986, 0.2889799820062574, 0.27272788668462894, 0.27272788668462894, 0.16363673201077739, 0.16363673201077739, 0.05454557733692579, 0.05454557733692579, 0.13864802770178214, 0.2772960554035643, 0.41594408310534636, 0.2093792081412557, 0.3140688122118836, 0.10468960407062786, 0.2093792081412557, 0.24554735690330173, 0.49109471380660347, 0.2860076126358683, 0.2860076126358683, 0.2860076126358683, 0.35195855052013797, 0.2525508873797413, 0.5051017747594826, 0.3422695698534215, 0.3422695698534215, 0.38261908968830244], \"Term\": [\"activated_true\", \"activated_true\", \"adaboost\", \"address\", \"address\", \"advise\", \"advise\", \"allocation\", \"allocation\", \"also\", \"also\", \"also\", \"also\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analyze\", \"analyze\", \"anonymous\", \"anymore\", \"anymore\", \"api\", \"aply\", \"appear\", \"appear\", \"application\", \"application\", \"application\", \"apply\", \"apply\", \"apply\", \"apply\", \"appreciate\", \"appreciate\", \"appreciate\", \"appreciate\", \"areasize\", \"ask\", \"ask\", \"association\", \"association\", \"association\", \"attribute\", \"attribute\", \"attribute\", \"attribute\", \"authentication\", \"back\", \"badly\", \"base\", \"base\", \"base\", \"binomial\", \"binomial\", \"bit\", \"bit\", \"bit\", \"bizmapwaittime\", \"block\", \"block\", \"boolean\", \"boolean\", \"bug\", \"bug\", \"bunch\", \"button\", \"button\", \"car\", \"car\", \"catch\", \"catch\", \"cause\", \"cause\", \"cause\", \"chance\", \"check\", \"check\", \"check\", \"check\", \"check\", \"class\", \"class\", \"class\", \"class\", \"click\", \"click\", \"cluster\", \"cluster\", \"code\", \"code\", \"code\", \"code\", \"column\", \"column\", \"column\", \"column\", \"com\", \"com\", \"com\", \"com\", \"come\", \"common\", \"common\", \"compatibility_expande\", \"compatibility_expande\", \"condition\", \"condition\", \"confidence\", \"confidence\", \"configure\", \"configure\", \"configure\", \"configure\", \"connect\", \"connect\", \"connect\", \"console\", \"console\", \"console\", \"contain\", \"contain\", \"contain\", \"copy\", \"copy\", \"core\", \"core\", \"core\", \"correct\", \"correct\", \"correlation\", \"correlation\", \"cpu\", \"cpu\", \"crawl\", \"crawl\", \"crawl\", \"crawling\", \"crawling\", \"create\", \"create\", \"create\", \"create\", \"crossvalidation\", \"current\", \"current\", \"data\", \"data\", \"data\", \"data\", \"dataframe\", \"dataset\", \"dataset\", \"dataset\", \"datum\", \"datum\", \"datum\", \"datum\", \"day\", \"day\", \"decision\", \"delay\", \"delay\", \"delay\", \"dependency\", \"dependency\", \"dependency\", \"dependent\", \"dependent\", \"description\", \"description\", \"detail\", \"detail\", \"detail\", \"develop\", \"develop\", \"different\", \"different\", \"different\", \"different\", \"dir\", \"dir\", \"direction\", \"discard\", \"discard\", \"distance\", \"distance\", \"distinct\", \"distinct\", \"document\", \"document\", \"document\", \"document\", \"dont_know\", \"dont_know\", \"draggable\", \"driver\", \"driver\", \"driver\", \"eclipse\", \"eclipse\", \"embed\", \"engine\", \"enter\", \"enter\", \"enter\", \"environment\", \"environment\", \"environment\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"even\", \"even\", \"even\", \"even\", \"eventlog\", \"eventlog\", \"example\", \"example\", \"example\", \"example\", \"exampleset\", \"exampleset\", \"exception\", \"exception\", \"exception\", \"execute\", \"execute\", \"execute\", \"executionunit\", \"executor\", \"executor\", \"exit\", \"exponent\", \"exponent\", \"export\", \"export\", \"export\", \"export\", \"extend\", \"extend\", \"extension\", \"extension\", \"extension\", \"extension\", \"extract\", \"extract\", \"extract\", \"fail\", \"fail\", \"fail\", \"fail\", \"false\", \"false\", \"false\", \"false\", \"false_conf\", \"false_conf\", \"feature\", \"feature\", \"field\", \"file\", \"file\", \"file\", \"file\", \"file\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"final\", \"final\", \"find\", \"find\", \"find\", \"find\", \"firebase\", \"firebase\", \"first\", \"first\", \"first\", \"folder\", \"folder\", \"follow\", \"follow\", \"follow\", \"follow\", \"follow\", \"forum\", \"fp_growth\", \"fp_growth\", \"fp_growth\", \"from_port\", \"function\", \"function\", \"function\", \"function\", \"get\", \"get\", \"get\", \"get\", \"get\", \"get\", \"gigantic\", \"give\", \"give\", \"give\", \"give\", \"go\", \"go\", \"go\", \"good\", \"good\", \"good\", \"graph\", \"gt\", \"gt\", \"hadoop\", \"hadoop\", \"hadoop\", \"hdfs\", \"hdfs\", \"head\", \"head\", \"help\", \"help\", \"help\", \"help\", \"help\", \"hitcode\", \"html\", \"html\", \"html\", \"image\", \"image\", \"image\", \"image\", \"import\", \"import\", \"import\", \"include\", \"include\", \"include\", \"incorrect\", \"info\", \"info\", \"info\", \"inform\", \"information\", \"information\", \"information\", \"information\", \"information\", \"initialization\", \"initialization\", \"initialized\", \"initialized\", \"initialized\", \"initplugin\", \"initplugin\", \"instead\", \"instead\", \"instead\", \"interpreter\", \"invoke\", \"issue\", \"issue\", \"issue\", \"issue\", \"issue\", \"jar\", \"jar\", \"jar\", \"jar\", \"java\", \"java\", \"java_home\", \"java_home\", \"java_home\", \"javascript\", \"jri\", \"jri\", \"js\", \"jumptogoogleid\", \"kickstarter\", \"kickstarter\", \"know\", \"know\", \"know\", \"know\", \"know\", \"label\", \"label\", \"label\", \"label\", \"lateload\", \"lateloadid\", \"latitude\", \"launcher\", \"lazyload\", \"learn\", \"learn\", \"learn\", \"least\", \"let\", \"let\", \"library\", \"library\", \"library\", \"like\", \"like\", \"like\", \"link\", \"link\", \"load\", \"load\", \"load\", \"localhost\", \"localhost\", \"locally\", \"look\", \"look\", \"look\", \"look\", \"m\", \"m\", \"m\", \"m\", \"m\", \"m\", \"main\", \"main\", \"many\", \"many\", \"many\", \"map\", \"map\", \"mapbutton\", \"mapreduce\", \"mapreduce\", \"match\", \"match\", \"match\", \"matrix\", \"matrix\", \"matter\", \"maxzoom\", \"memory\", \"memory\", \"memory\", \"memory\", \"message\", \"message\", \"message\", \"message\", \"meta\", \"meta\", \"mingw\", \"mingw\", \"minzoom\", \"model\", \"model\", \"model\", \"module\", \"module\", \"module\", \"multimap\", \"name\", \"name\", \"name\", \"name\", \"name\", \"native\", \"native\", \"native\", \"near\", \"near\", \"need\", \"need\", \"need\", \"need\", \"negative\", \"negative\", \"net\", \"net\", \"net\", \"neural\", \"neural\", \"neural\", \"neuralnet\", \"new\", \"new\", \"new\", \"new\", \"notice\", \"notice\", \"number\", \"number\", \"number\", \"number\", \"number\", \"object\", \"object\", \"object\", \"occur\", \"occur\", \"onlygoogle\", \"operator\", \"operator\", \"operator\", \"operator\", \"oracle\", \"oracle\", \"order\", \"order\", \"order\", \"original\", \"original\", \"original\", \"output\", \"output\", \"output\", \"output\", \"page\", \"page\", \"page\", \"paragraph\", \"paragraph\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"part\", \"part\", \"part\", \"part\", \"part\", \"path\", \"path\", \"path\", \"pdf\", \"perform\", \"perform\", \"perform\", \"plugininitr\", \"plugininitr\", \"point\", \"point\", \"portspacing_port\", \"portspacing_port\", \"post\", \"post\", \"post\", \"post\", \"post\", \"precede\", \"precede\", \"precision\", \"precision\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"program_file\", \"program_file\", \"program_file\", \"project\", \"project\", \"project\", \"property\", \"property\", \"propose\", \"publish\", \"pull\", \"query\", \"query\", \"query\", \"question\", \"question\", \"question\", \"quite\", \"quite\", \"quote\", \"quote\", \"quote\", \"r_home\", \"r_home\", \"r_home\", \"radoop\", \"ram\", \"ram\", \"rapidminer\", \"rapidminer\", \"rapidminer\", \"rapidminer\", \"rapidminer\", \"rapidminer\", \"ready\", \"recent\", \"recent\", \"reduce\", \"reduce\", \"ref\", \"ref\", \"regular\", \"regular\", \"regular\", \"remain\", \"remain\", \"repeat\", \"repeat\", \"replace\", \"replace\", \"repository\", \"repository\", \"research\", \"resource\", \"resource\", \"response\", \"result\", \"result\", \"result\", \"retrieve\", \"retrieve\", \"review\", \"review\", \"review\", \"reviewcentre\", \"reviewtitle\", \"right\", \"right\", \"rjava\", \"rjava\", \"rjava\", \"rosuda\", \"rosuda\", \"route\", \"rule\", \"rule\", \"rule\", \"rule\", \"run\", \"run\", \"run\", \"run\", \"s\", \"s\", \"s\", \"s\", \"satbutton\", \"scheduler\", \"scheduler\", \"screenshot\", \"script\", \"script\", \"see\", \"see\", \"see\", \"see\", \"select\", \"select\", \"select\", \"selling\", \"send\", \"sentence\", \"sentence\", \"sentence\", \"seperate\", \"seperate\", \"server\", \"server\", \"service\", \"service\", \"set\", \"set\", \"set\", \"set\", \"share_hadoop\", \"share_hadoop\", \"show\", \"show\", \"show\", \"show\", \"showarea\", \"showcontrol\", \"shufflehandl\", \"sit\", \"site\", \"site\", \"site\", \"skip\", \"skip\", \"source\", \"source\", \"space\", \"space\", \"space\", \"span\", \"span\", \"span\", \"spark\", \"spark\", \"spark_job\", \"spark_job\", \"sparkrm\", \"sparkrm\", \"specific\", \"specific\", \"spend\", \"spend\", \"split\", \"split\", \"split\", \"stack\", \"stack\", \"stack\", \"stacktrace\", \"stacktrace\", \"start\", \"start\", \"start\", \"start\", \"start\", \"stop\", \"stop\", \"stop\", \"store\", \"store\", \"store\", \"storytelle\", \"storytelle\", \"strike\", \"strike\", \"struggle\", \"studio\", \"study\", \"study\", \"submit\", \"submit\", \"suggestion\", \"suggestion\", \"suggestion\", \"suggestion\", \"sun_reflect\", \"support\", \"support\", \"suspect\", \"svbutton\", \"system\", \"system\", \"system\", \"table\", \"table\", \"table\", \"tabletop\", \"tabletop\", \"test\", \"test\", \"test\", \"testing\", \"testing\", \"testing\", \"text\", \"text\", \"text\", \"text\", \"text\", \"thank\", \"thank\", \"thank\", \"thank\", \"thing\", \"thing\", \"thing\", \"thing\", \"title\", \"to_port\", \"tokenize\", \"tokenize\", \"tokenize\", \"train\", \"train\", \"train\", \"transaction\", \"transaction\", \"transaction\", \"transport\", \"tree\", \"trouble\", \"trouble\", \"trouble\", \"trouble\", \"true\", \"true\", \"true_height\", \"try\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tumblr\", \"tumblr\", \"tutorial\", \"tutorial\", \"tweets_hadoop\", \"tweets_hadoop\", \"type\", \"type\", \"type\", \"type\", \"unanswered\", \"underline\", \"unfortunately\", \"unknown_source\", \"url\", \"url\", \"use\", \"use\", \"use\", \"use\", \"use\", \"use\", \"usefull\", \"user\", \"user\", \"user\", \"utility\", \"utility\", \"validation\", \"validation\", \"value\", \"value\", \"value\", \"value\", \"value\", \"variable\", \"variable\", \"variable\", \"variable\", \"vcore\", \"vcore\", \"ve\", \"ve\", \"ve\", \"ve\", \"version\", \"version\", \"version\", \"version\", \"view\", \"view\", \"want\", \"want\", \"want\", \"want\", \"warn\", \"warn\", \"way\", \"way\", \"way\", \"way\", \"web\", \"web\", \"web\", \"webservice\", \"webservice\", \"website\", \"weight\", \"weight\", \"whole\", \"whole\", \"window\", \"window\", \"window\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"write\", \"write\", \"write\", \"wrong\", \"wrong\", \"wrong\", \"wrong\", \"www\", \"www\", \"xml\", \"xml\", \"xml\", \"xpath\", \"yarn\", \"yarn\", \"yarn_resourcemanag\", \"yarn_resourcemanag\", \"zoomlocke\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [8, 10, 6, 7, 4, 3, 1, 5, 9, 2]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el3800921399902444440803934118340\", ldavis_el3800921399902444440803934118340_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el3800921399902444440803934118340\", ldavis_el3800921399902444440803934118340_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el3800921399902444440803934118340\", ldavis_el3800921399902444440803934118340_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
       "topic                                                \n",
       "7     -0.108390 -0.019273       1        1  34.955843\n",
       "9     -0.018619  0.046129       2        1  18.792968\n",
       "5      0.006890  0.031627       3        1  12.975637\n",
       "6      0.004303  0.027589       4        1  12.301425\n",
       "3      0.014477 -0.018528       5        1   6.225812\n",
       "2      0.015610 -0.029455       6        1   5.066687\n",
       "0      0.016956 -0.006378       7        1   3.663568\n",
       "4      0.021411 -0.008989       8        1   2.104988\n",
       "8      0.023978 -0.011463       9        1   2.086882\n",
       "1      0.023383 -0.011259      10        1   1.826189, topic_info=        Term       Freq      Total Category  logprob  loglift\n",
       "437   column  23.000000  23.000000  Default  30.0000  30.0000\n",
       "105     name  16.000000  16.000000  Default  29.0000  29.0000\n",
       "31       use  45.000000  45.000000  Default  28.0000  28.0000\n",
       "62      java  42.000000  42.000000  Default  27.0000  27.0000\n",
       "192      com  61.000000  61.000000  Default  26.0000  26.0000\n",
       "..       ...        ...        ...      ...      ...      ...\n",
       "133     good   0.181657   4.736973  Topic10  -6.3516   0.7419\n",
       "136  instead   0.161108   4.269246  Topic10  -6.4717   0.7258\n",
       "63      know   0.161808   5.012092  Topic10  -6.4673   0.5697\n",
       "124    cause   0.159234   4.426735  Topic10  -6.4834   0.6779\n",
       "147    space   0.159636   7.958759  Topic10  -6.4808   0.0938\n",
       "\n",
       "[493 rows x 6 columns], token_table=      Topic      Freq                Term\n",
       "term                                     \n",
       "674       1  0.676768      activated_true\n",
       "674       3  0.135354      activated_true\n",
       "153       1  0.373337            adaboost\n",
       "120       1  0.274020             address\n",
       "120       6  0.274020             address\n",
       "...     ...       ...                 ...\n",
       "1139      1  0.252551                yarn\n",
       "1139      6  0.505102                yarn\n",
       "1140      1  0.342270  yarn_resourcemanag\n",
       "1140      6  0.342270  yarn_resourcemanag\n",
       "722       1  0.382619           zoomlocke\n",
       "\n",
       "[914 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[8, 10, 6, 7, 4, 3, 1, 5, 9, 2])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=10, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.91,\n",
    "                                           eta=0.91)\n",
    "\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)\n",
    "\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "392209b0-cdfe-4134-8a90-7ebd77bb2098",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.006*\"class\" + 0.005*\"detail\" + 0.005*\"get\" + 0.005*\"firebase\" + '\n",
      "  '0.005*\"try\" + 0.005*\"use\" + 0.004*\"span\" + 0.004*\"error\" + 0.004*\"m\" + '\n",
      "  '0.004*\"block\"'),\n",
      " (1,\n",
      "  '0.004*\"export\" + 0.002*\"issue\" + 0.002*\"question\" + 0.002*\"view\" + '\n",
      "  '0.002*\"sentence\" + 0.002*\"good\" + 0.002*\"whole\" + 0.002*\"notice\" + '\n",
      "  '0.002*\"know\" + 0.002*\"instead\"'),\n",
      " (2,\n",
      "  '0.016*\"name\" + 0.010*\"spark\" + 0.006*\"memory\" + 0.006*\"value\" + '\n",
      "  '0.006*\"localhost\" + 0.006*\"yarn\" + 0.005*\"hadoop\" + 0.005*\"resource\" + '\n",
      "  '0.004*\"address\" + 0.004*\"scheduler\"'),\n",
      " (3,\n",
      "  '0.007*\"library\" + 0.007*\"rapidminer\" + 0.005*\"load\" + 0.005*\"program_file\" '\n",
      "  '+ 0.005*\"help\" + 0.005*\"try\" + 0.005*\"jri\" + 0.005*\"info\" + 0.004*\"r_home\" '\n",
      "  '+ 0.004*\"window\"'),\n",
      " (4,\n",
      "  '0.003*\"xpath\" + 0.003*\"extract\" + 0.002*\"right\" + 0.002*\"website\" + '\n",
      "  '0.002*\"reviewcentre\" + 0.002*\"dont_know\" + 0.002*\"many\" + 0.002*\"day\" + '\n",
      "  '0.002*\"appear\" + 0.002*\"review\"'),\n",
      " (5,\n",
      "  '0.024*\"column\" + 0.020*\"datum\" + 0.011*\"use\" + 0.008*\"text\" + '\n",
      "  '0.008*\"rapidminer\" + 0.006*\"follow\" + 0.005*\"store\" + 0.005*\"m\" + '\n",
      "  '0.005*\"label\" + 0.005*\"kickstarter\"'),\n",
      " (6,\n",
      "  '0.016*\"use\" + 0.012*\"rapidminer\" + 0.006*\"filter\" + 0.006*\"operator\" + '\n",
      "  '0.006*\"analysis\" + 0.006*\"try\" + 0.006*\"problem\" + 0.006*\"false\" + '\n",
      "  '0.005*\"document\" + 0.005*\"error\"'),\n",
      " (7,\n",
      "  '0.047*\"rapidminer\" + 0.029*\"operator\" + 0.026*\"com\" + 0.025*\"process\" + '\n",
      "  '0.020*\"java\" + 0.016*\"run\" + 0.009*\"error\" + 0.009*\"application\" + '\n",
      "  '0.008*\"value\" + 0.008*\"import\"'),\n",
      " (8,\n",
      "  '0.004*\"false\" + 0.004*\"text\" + 0.004*\"true\" + 0.004*\"javascript\" + '\n",
      "  '0.003*\"extract\" + 0.003*\"script\" + 0.002*\"type\" + 0.002*\"button\" + '\n",
      "  '0.002*\"rapidminer\" + 0.002*\"suggestion\"'),\n",
      " (9,\n",
      "  '0.041*\"rapidminer\" + 0.018*\"use\" + 0.009*\"file\" + 0.008*\"m\" + '\n",
      "  '0.006*\"document\" + 0.006*\"try\" + 0.006*\"project\" + 0.005*\"process\" + '\n",
      "  '0.005*\"test\" + 0.005*\"result\"')]\n",
      "<gensim.interfaces.TransformedCorpus object at 0x7f50c6c56b00>\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]\n",
    "print(doc_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Id                                              Title  \\\n",
      "0   9594503  RapidMiner error: Regular Attributes must be o...   \n",
      "1  10416219                           rapidminer some concepts   \n",
      "2  10662637  How integrate RapidMiner in a PHP web applicat...   \n",
      "3  14058589  Add a constant value to a numerical attribute ...   \n",
      "4  14421563                        Read MYSQL db in RapidMiner   \n",
      "\n",
      "                                                Body  RatingsSentiCR  \\\n",
      "0  I am attempting to learn to use RapidMiner, an...              -1   \n",
      "1  In rapidminer what is the meaning of:\\n\\n    -...               1   \n",
      "2  I've got an implementation in RapidMiner that ...               1   \n",
      "3  I am working with rapidminer , I have a datase...               0   \n",
      "4  I'm attempting to use the 'Read Database' oper...              -1   \n",
      "\n",
      "   RatingsGPT35  RatingsGPTFineTuned  \\\n",
      "0            -1                 -1.0   \n",
      "1            -1                 -1.0   \n",
      "2            -1                 -1.0   \n",
      "3            -1                 -1.0   \n",
      "4            -1                 -1.0   \n",
      "\n",
      "                                              merged  topic  \n",
      "0  RapidMiner error: Regular Attributes must be o...      6  \n",
      "1  rapidminer some concepts-In rapidminer what is...      9  \n",
      "2  How integrate RapidMiner in a PHP web applicat...      9  \n",
      "3  Add a constant value to a numerical attribute ...      7  \n",
      "4  Read MYSQL db in RapidMiner-I'm attempting to ...      7  \n",
      "topic:  0 total data:  3\n",
      "topic:  1 total data:  1\n",
      "topic:  2 total data:  1\n",
      "topic:  3 total data:  2\n",
      "topic:  4 total data:  1\n",
      "topic:  5 total data:  10\n",
      "topic:  6 total data:  13\n",
      "topic:  7 total data:  14\n",
      "topic:  8 total data:  1\n",
      "topic:  9 total data:  25\n"
     ]
    }
   ],
   "source": [
    "num_topics = 10\n",
    "topic_distributions = [lda_model[doc] for doc in corpus]\n",
    "\n",
    "# Extract the dominant topic for each document\n",
    "df['topic'] = [max(topics, key=lambda x: x[1])[0] for topics in topic_distributions]\n",
    "\n",
    "# Display the DataFrame with assigned topics\n",
    "print(df.head())\n",
    "df.to_csv('../dataset/AssignedTopicRapidMiner.csv')\n",
    "for i in range(num_topics): \n",
    "    topic_df = df[df['topic'] == i]\n",
    "    print('topic: ', i, 'total data: ', len(topic_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
